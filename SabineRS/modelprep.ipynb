{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "import rasterio\n",
    "from rasterio import windows\n",
    "from shapely.geometry import box\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Lambda, Conv2D, UpSampling2D, Cropping2D, MaxPooling2D, Dropout, BatchNormalization, Conv2DTranspose, concatenate, Flatten, Dense, UpSampling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(labelpath):\n",
    "    otsu_ims = [os.path.join(labelpath, f'otsu/{file}') for file in os.listdir(os.path.join(labelpath, f'otsu')) if file.endswith('.tif')]\n",
    "    kmeans_ims = [os.path.join(labelpath, f'kmeans/{file}') for file in os.listdir(os.path.join(labelpath, f'kmeans')) if file.endswith('.tif')]\n",
    "    gmm_ims = [os.path.join(labelpath, f'gmm/{file}') for file in os.listdir(os.path.join(labelpath, f'gmm')) if file.endswith('.tif')]\n",
    "    majority_ims = [os.path.join(labelpath, f'majority/{file}') for file in os.listdir(os.path.join(labelpath, f'majority')) if file.endswith('.tif')]\n",
    "\n",
    "    \n",
    "    otsu_ims = sorted(otsu_ims, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))\n",
    "    kmeans_ims = sorted(kmeans_ims, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))\n",
    "    gmm_ims = sorted(gmm_ims, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))\n",
    "    majority_ims = sorted(majority_ims, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))\n",
    "\n",
    "    return otsu_ims, kmeans_ims, gmm_ims, majority_ims\n",
    "\n",
    "def get_grd(grdpath):\n",
    "    orig_ims = [os.path.join(grdpath, file) for file in os.listdir(grdpath) if file.endswith('.tif')]\n",
    "    orig_ims = sorted(orig_ims, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))\n",
    "\n",
    "    return orig_ims\n",
    "\n",
    "def get_glcm(glcmpath):\n",
    "    orig_glcms = [os.path.join(glcmpath, file) for file in os.listdir(glcmpath) if file.endswith('.tif')]\n",
    "    orig_glcms = sorted(orig_glcms, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))\n",
    "\n",
    "    return orig_glcms\n",
    "def find_closest_dates(labels, backscatter_ims, glcm_ims, max_days=12):\n",
    "    closest_dates = []  # To store the closest matches for each label\n",
    "\n",
    "    # Iterate through each label\n",
    "    for label in labels:\n",
    "        label_date = datetime.strptime(label[-14:-4], '%Y-%m-%d')  # Extract date from label\n",
    "        min_diff = max_days + 1  # Initialize minimum difference as larger than max_days\n",
    "        closest_backscatter = None  # To store the closest backscatter match\n",
    "        closest_glcm = None  # To store the closest GLCM match\n",
    "\n",
    "        # Iterate through both backscatter and GLCM images\n",
    "        for backscatter, glcm in zip(backscatter_ims, glcm_ims):\n",
    "            backscatter_date = datetime.strptime(backscatter[-14:-4], '%Y-%m-%d')  # Extract date from backscatter\n",
    "            glcm_date = datetime.strptime(glcm[-14:-4], '%Y-%m-%d')  # Extract date from GLCM\n",
    "\n",
    "            # Calculate the absolute difference in days\n",
    "            day_difference = abs((backscatter_date - label_date).days)\n",
    "\n",
    "            # Check if the difference is within max_days and closer than the current minimum\n",
    "            if day_difference <= max_days and day_difference < min_diff:\n",
    "                min_diff = day_difference\n",
    "                closest_backscatter = backscatter\n",
    "                closest_glcm = glcm\n",
    "\n",
    "        # Store the closest matches for the current label\n",
    "        closest_dates.append((label, closest_backscatter, closest_glcm))\n",
    "\n",
    "    return closest_dates\n",
    "\n",
    "def stack_data(filtered_data, unlab_s1, unlab_glcm):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_unlabeled = []\n",
    "\n",
    "    for set in filtered_data:\n",
    "        with rasterio.open(set[2]) as glcm_src:\n",
    "            VV_contrast = glcm_src.read(1).astype(np.float32)\n",
    "            VV_asm = glcm_src.read(2).astype(np.float32)\n",
    "            VV_diss = glcm_src.read(3).astype(np.float32)\n",
    "            VV_idm = glcm_src.read(4).astype(np.float32)\n",
    "            VV_corr = glcm_src.read(5).astype(np.float32)\n",
    "            VV_var = glcm_src.read(6).astype(np.float32)\n",
    "            VV_ent = glcm_src.read(7).astype(np.float32)\n",
    "            VH_contrast = glcm_src.read(8).astype(np.float32)\n",
    "            VH_asm = glcm_src.read(9).astype(np.float32)\n",
    "            VH_diss = glcm_src.read(10).astype(np.float32)\n",
    "            VH_idm = glcm_src.read(11).astype(np.float32)\n",
    "            VH_corr = glcm_src.read(12).astype(np.float32)\n",
    "            VH_var = glcm_src.read(13).astype(np.float32)\n",
    "            VH_ent = glcm_src.read(14).astype(np.float32)\n",
    "\n",
    "\n",
    "            VV_contrast = (VV_contrast - VV_contrast.min()) / (VV_contrast.max() - VV_contrast.min())\n",
    "            VV_asm = (VV_asm- VV_asm.min()) / (VV_asm.max() - VV_asm.min())\n",
    "            VV_diss = (VV_diss - VV_diss.min()) / (VV_diss.max() - VV_diss.min())\n",
    "            VV_idm = (VV_idm - VV_idm.min()) / (VV_idm.max() - VV_idm.min())\n",
    "            VV_corr = (VV_corr - VV_corr.min()) / (VV_corr.max() - VV_corr.min())\n",
    "            VV_var = (VV_var - VV_var.min()) / (VV_var.max() - VV_var.min())\n",
    "            VV_ent = (VV_ent - VV_ent.min()) / (VV_ent.max() - VV_ent.min())\n",
    "            VH_contrast = (VH_contrast - VH_contrast.min()) / (VH_contrast.max() - VH_contrast.min())\n",
    "            VH_asm = (VH_asm- VH_asm.min()) / (VH_asm.max() - VH_asm.min())\n",
    "            VH_diss = (VH_diss - VH_diss.min()) / (VH_diss.max() - VH_diss.min())\n",
    "            VH_idm = (VH_idm - VH_idm.min()) / (VH_idm.max() - VH_idm.min())\n",
    "            VH_corr = (VH_corr - VH_corr.min()) / (VH_corr.max() - VH_corr.min())\n",
    "            VH_var = (VH_var - VH_var.min()) / (VH_var.max() - VH_var.min())\n",
    "            VH_ent = (VH_ent - VH_ent.min()) / (VH_ent.max() - VH_ent.min())\n",
    "    \n",
    "        with rasterio.open(set[1]) as src:\n",
    "            vv = src.read(1).astype(np.float32)\n",
    "            vh = src.read(2).astype(np.float32)\n",
    "            rvi = src.read(3).astype(np.float32)\n",
    "            sdwi = src.read(4).astype(np.float32)\n",
    "\n",
    "            # Convert from dB to linear scale\n",
    "            vv_linear = 10 ** (vv / 10)\n",
    "            vh_linear = 10 ** (vh / 10)\n",
    "\n",
    "            vv_lin_norm = (vv_linear - vv_linear.min()) / (vv_linear.max() - vv_linear.min())\n",
    "            vh_lin_norm = (vh_linear - vh_linear.min()) / (vh_linear.max() - vh_linear.min())\n",
    "            rvi_norm = (rvi - rvi.min()) / (rvi.max() - rvi.min())\n",
    "            sdwi_norm = (sdwi - sdwi.min()) / (sdwi.max() - sdwi.min())\n",
    "\n",
    "        s1_data = np.stack([vv_lin_norm, vh_lin_norm, rvi_norm, sdwi_norm, VV_contrast, VV_asm,VV_diss, VV_idm, VV_corr, VV_var, VV_ent, VH_contrast, VH_asm,VH_diss, VH_idm, VH_corr, VH_var, VH_ent], axis=-1)\n",
    "\n",
    "        with rasterio.open(set[0]) as src:\n",
    "            s2_labels = src.read(1).astype(np.int32)\n",
    "    \n",
    "        X_train.append(s1_data)\n",
    "        y_train.append(s2_labels)\n",
    "\n",
    "\n",
    "    X_unlabeled = []\n",
    "\n",
    "    for i, im in enumerate(unlab_s1):\n",
    "        with rasterio.open(im) as src:\n",
    "            vv = src.read(1).astype(np.float32)\n",
    "            vh = src.read(2).astype(np.float32)\n",
    "            rvi = src.read(3).astype(np.float32)\n",
    "            sdwi = src.read(4).astype(np.float32)\n",
    "\n",
    "            # Convert from dB to linear scale\n",
    "            vv_linear = 10 ** (vv / 10)\n",
    "            vh_linear = 10 ** (vh / 10)\n",
    "\n",
    "            vv_lin_norm = (vv_linear - vv_linear.min()) / (vv_linear.max() - vv_linear.min())\n",
    "            vh_lin_norm = (vh_linear - vh_linear.min()) / (vh_linear.max() - vh_linear.min())\n",
    "            rvi_norm = (rvi - rvi.min()) / (rvi.max() - rvi.min())\n",
    "            sdwi_norm = (sdwi - sdwi.min()) / (sdwi.max() - sdwi.min())\n",
    "\n",
    "        with rasterio.open(unlab_glcm[i]) as glcm_src:\n",
    "            VV_contrast = glcm_src.read(1).astype(np.float32)\n",
    "            VV_asm = glcm_src.read(2).astype(np.float32)\n",
    "            VV_diss = glcm_src.read(3).astype(np.float32)\n",
    "            VV_idm = glcm_src.read(4).astype(np.float32)\n",
    "            VV_corr = glcm_src.read(5).astype(np.float32)\n",
    "            VV_var = glcm_src.read(6).astype(np.float32)\n",
    "            VV_ent = glcm_src.read(7).astype(np.float32)\n",
    "            VH_contrast = glcm_src.read(8).astype(np.float32)\n",
    "            VH_asm = glcm_src.read(9).astype(np.float32)\n",
    "            VH_diss = glcm_src.read(10).astype(np.float32)\n",
    "            VH_idm = glcm_src.read(11).astype(np.float32)\n",
    "            VH_corr = glcm_src.read(12).astype(np.float32)\n",
    "            VH_var = glcm_src.read(13).astype(np.float32)\n",
    "            VH_ent = glcm_src.read(14).astype(np.float32)\n",
    "\n",
    "\n",
    "            VV_contrast = (VV_contrast - VV_contrast.min()) / (VV_contrast.max() - VV_contrast.min())\n",
    "            VV_asm = (VV_asm- VV_asm.min()) / (VV_asm.max() - VV_asm.min())\n",
    "            VV_diss = (VV_diss - VV_diss.min()) / (VV_diss.max() - VV_diss.min())\n",
    "            VV_idm = (VV_idm - VV_idm.min()) / (VV_idm.max() - VV_idm.min())\n",
    "            VV_corr = (VV_corr - VV_corr.min()) / (VV_corr.max() - VV_corr.min())\n",
    "            VV_var = (VV_var - VV_var.min()) / (VV_var.max() - VV_var.min())\n",
    "            VV_ent = (VV_ent - VV_ent.min()) / (VV_ent.max() - VV_ent.min())\n",
    "            VH_contrast = (VH_contrast - VH_contrast.min()) / (VH_contrast.max() - VH_contrast.min())\n",
    "            VH_asm = (VH_asm- VH_asm.min()) / (VH_asm.max() - VH_asm.min())\n",
    "            VH_diss = (VH_diss - VH_diss.min()) / (VH_diss.max() - VH_diss.min())\n",
    "            VH_idm = (VH_idm - VH_idm.min()) / (VH_idm.max() - VH_idm.min())\n",
    "            VH_corr = (VH_corr - VH_corr.min()) / (VH_corr.max() - VH_corr.min())\n",
    "            VH_var = (VH_var - VH_var.min()) / (VH_var.max() - VH_var.min())\n",
    "            VH_ent = (VH_ent - VH_ent.min()) / (VH_ent.max() - VH_ent.min())\n",
    "\n",
    "        s1_unlab_data = np.stack([vv_lin_norm, vh_lin_norm, rvi_norm, sdwi_norm, VV_contrast, VV_asm,VV_diss, VV_idm, VV_corr, VV_var, VV_ent, VH_contrast, VH_asm,VH_diss, VH_idm, VH_corr, VH_var, VH_ent], axis=-1)\n",
    "\n",
    "        X_unlabeled.append(s1_unlab_data)\n",
    "\n",
    "\n",
    "    return X_train, y_train, X_unlabeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Imagery for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### WSL #########################\n",
    "# labels = get_labels('/mnt/d/SabineRS/s2classifications')\n",
    "# backscatter_ims = get_grd('/mnt/d/SabineRS/GRD/3_ratio')\n",
    "# glcm_ims = get_glcm('/mnt/d/SabineRS/GRD/2_registered/glcm')\n",
    "\n",
    "###################### Linux #########################\n",
    "otsu_ims, kmeans_ims, gmm_ims, majority_ims = get_labels('/home/wcc/Desktop/SabineRS/MSI/s2classifications')\n",
    "backscatter_ims = get_grd('/home/wcc/Desktop/SabineRS/GRD/3_ratio')\n",
    "glcm_ims = get_glcm('/home/wcc/Desktop/SabineRS/GRD/2_registered/glcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair the Sentinel-1 backscatter and glcm  with labels according to date\n",
    "labeledPairs = find_closest_dates(majority_ims, backscatter_ims, glcm_ims)\n",
    "\n",
    "# Filter out tuples that contain any None entries\n",
    "# no close matches between S2 labels and S1 images\n",
    "filtered_data = [entry for entry in labeledPairs if None not in entry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1matches = [set[1] for set in filtered_data]\n",
    "glcmmatches = [set[2] for set in filtered_data]\n",
    "s1_X = [i for i in backscatter_ims if i not in s1matches]   # unlabeled S1 data for model training\n",
    "glcm_X = [i for i in glcm_ims if i not in glcmmatches]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_unlabeled = stack_data(filtered_data, s1_X, glcm_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 18 # 4 bands from GRD and 14 from GLCM \n",
    "num_classes = 3\n",
    "img_height, img_width = X_train[0].shape[:2]  # Assuming all images have the same dimensions\n",
    "\n",
    "\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom NN\n",
    "- name could be BUNet -- Beneficial Use Network given the focus on sediment enrichment in wetlands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved model with batch normalization, dropout, and skip connections\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(798, 693, 18)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(3, (1, 1), activation='softmax', padding='same')  # Output layer for 3 classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "hist = model.fit(\n",
    "    np.array(X_train_split),\n",
    "    np.array(y_train_split),\n",
    "    epochs=20,\n",
    "    batch_size=5,\n",
    "    validation_split=0.2,\n",
    "    callbacks = [tf.keras.callbacks.TensorBoard(log_dir = '/home/wcc/Desktop/SabineRS/modellogs')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color = 'red', label = 'loss')\n",
    "plt.plot(hist.history['val_loss'], color = 'blue', label = 'val_loss')\n",
    "plt.suptitle('CNN Training Loss', fontsize = 20)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color = 'red', label = 'accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color = 'blue', label = 'val_accuracy')\n",
    "plt.suptitle('CNN Training accuracy', fontsize = 20)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet\n",
    "- transfer learning from MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet\n",
    "- transfer learngin from EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check accuracy, precision, recall, F1 scores\n",
    "- compare shallow NN with ResNet and UNet results, prove mine is better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the validation data\n",
    "y_pred = model.predict(np.array(X_val_split))  # shape: (num_samples, height, width, num_classes)\n",
    "\n",
    "# Convert predictions to class labels by taking the argmax along the class dimension\n",
    "y_pred_labels = np.argmax(y_pred, axis=-1)  # shape: (num_samples, height, width)\n",
    "\n",
    "# Flatten the arrays for metric calculations\n",
    "y_val_flat = np.array(y_val_split).flatten()  # True labels\n",
    "y_pred_flat = y_pred_labels.flatten()  # Predicted labels\n",
    "\n",
    "# Calculate metrics for each class\n",
    "print(\"Accuracy:\", accuracy_score(y_val_flat, y_pred_flat))\n",
    "print(\"Precision, Recall, F1 Score per class:\\n\", classification_report(y_val_flat, y_pred_flat, target_names=['open water', 'subaqueous land', 'subaerial land']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample index to display (for example, the first sample in validation data)\n",
    "i = -1\n",
    "true_labels = y_val_split[i]          # True labels for the sample\n",
    "predicted_labels = y_pred_labels[i]  # Predicted labels for the sample\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Display the ground truth\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(true_labels, cmap='viridis')\n",
    "plt.title('Ground Truth')\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the model predictions\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(predicted_labels, cmap='viridis')\n",
    "plt.title('Predicted Labels')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Morphological Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morphological operators if needed\n",
    "\n",
    "cleaned_ims = {\"otsu\": [],\n",
    "               \"kmeans\": [], \n",
    "               \"gmm\": []\n",
    "               }\n",
    "\n",
    "for i, (method, entry) in enumerate(zip(classification_methods, [relabeled_images['otsu'], relabeled_images[\"kmeans\"], relabeled_images['gmm']])):\n",
    "    for j, im in enumerate(entry):\n",
    "        # Define a square kernel; adjust the size as needed\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "        # apply morphological functions to eliminate isolated pixels from each class\n",
    "        subaqueous = (im == 0).astype(np.uint8)\n",
    "        subaerial = (im == 1).astype(np.uint8)\n",
    "\n",
    "        ######## KMeans\n",
    "        # Apply opening to remove small isolated pixels\n",
    "        subaerial_cleaned = cv2.morphologyEx(subaerial, cv2.MORPH_OPEN, kernel)\n",
    "        subaqueous_cleaned = cv2.morphologyEx(subaqueous, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Apply closing to fill small holes\n",
    "        subaerial_cleaned = cv2.morphologyEx(subaerial_cleaned, cv2.MORPH_CLOSE, kernel)\n",
    "        subaqueous_cleaned = cv2.morphologyEx(subaqueous_cleaned, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Reconstruct the classified image\n",
    "        cleaned_classified_image = (subaqueous_cleaned * i +\n",
    "                                    subaqueous_cleaned * 1)      \n",
    "\n",
    "        # Add the processed relabeled image to the dictionary\n",
    "        cleaned_ims[method].append(cleaned_classified_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check resulting classes again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground truthing\n",
    "- get water extent maps from various sources to serve as ground truth data for confirming the classification results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://global-surface-water.appspot.com/download\n",
    "2. USGS LandCover\n",
    "3. Copernicus Water and Wetness Product?\n",
    "4. Chesapeake Conservancy High-Resolution Land Cover Dataset\n",
    "5. RAMSAR Wetlands Sites\n",
    "6. MODIS Land Cover Type Product (MCD12Q1)\n",
    "7. Sentinel-2 Labeled Datasets for Wetland Classification\n",
    "8. OSM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
