{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import rasterio\n",
    "import os\n",
    "from osgeo import gdal, osr\n",
    "from shapely.geometry import box\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "from shapely.geometry import box\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import copy\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.filters import threshold_otsu\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "%matplotlib widget \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(labelpath):\n",
    "    otsu_ims = [os.path.join(labelpath, f'otsu/{file}') for file in os.listdir(os.path.join(labelpath, f'otsu')) if file.endswith('.tif')]\n",
    "    kmeans_ims = [os.path.join(labelpath, f'kmeans/{file}') for file in os.listdir(os.path.join(labelpath, f'kmeans')) if file.endswith('.tif')]\n",
    "    gmm_ims = [os.path.join(labelpath, f'gmm/{file}') for file in os.listdir(os.path.join(labelpath, f'gmm')) if file.endswith('.tif')]\n",
    "    majority_ims = [os.path.join(labelpath, f'majority/{file}') for file in os.listdir(os.path.join(labelpath, f'majority')) if file.endswith('.tif')]\n",
    "\n",
    "    \n",
    "    otsu_ims = sorted(otsu_ims, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))\n",
    "    kmeans_ims = sorted(kmeans_ims, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))\n",
    "    gmm_ims = sorted(gmm_ims, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))\n",
    "    majority_ims = sorted(majority_ims, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))\n",
    "\n",
    "    return otsu_ims, kmeans_ims, gmm_ims, majority_ims\n",
    "\n",
    "def get_grd(grdpath):\n",
    "    orig_ims = [os.path.join(grdpath, file) for file in os.listdir(grdpath) if file.endswith('.tif')]\n",
    "    orig_ims = sorted(orig_ims, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))\n",
    "\n",
    "    return orig_ims\n",
    "\n",
    "def get_glcm(glcmpath):\n",
    "    orig_glcms = [os.path.join(glcmpath, file) for file in os.listdir(glcmpath) if file.endswith('.tif')]\n",
    "    orig_glcms = sorted(orig_glcms, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))\n",
    "\n",
    "    return orig_glcms\n",
    "\n",
    "# Clip each Sentinel-1 image\n",
    "def clip_sentinel1_image(s1_path, output_path, s2_bounds):\n",
    "    with rasterio.open(s1_path) as src:\n",
    "        # Calculate the window corresponding to the bounding box (extent)\n",
    "        window = rasterio.windows.from_bounds(*s2_bounds, transform=src.transform)\n",
    "        \n",
    "        # Read and clip the Sentinel-1 image\n",
    "        clipped_image = src.read(window=window)\n",
    "        \n",
    "        # Create metadata for the clipped image\n",
    "        out_meta = src.meta.copy()\n",
    "        out_meta.update({\n",
    "            'height': window.height,\n",
    "            'width': window.width,\n",
    "            'transform': src.window_transform(window)\n",
    "        })\n",
    "        \n",
    "        # Write the clipped image to a new file\n",
    "        with rasterio.open(output_path, 'w', **out_meta) as dst:\n",
    "            dst.write(clipped_image)\n",
    "\n",
    "def export_s1images(coll, s2_bounds, type):\n",
    "    \"\"\"\n",
    "    type = str\n",
    "        'original' or fitlertype used in sentinel_one_two.ipynb\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    for s1_path in enumerate(coll):\n",
    "        output_path = os.path.join(s1_path[:16], f'Clipped/{type}/{s1_path[-17:]}')\n",
    "        clip_sentinel1_image(s1_path, output_path, s2_bounds)\n",
    "\n",
    "def plot_vv_vh_with_bbox(image_path, bbox):\n",
    "    # Open the image using rasterio (assuming VV and VH are the first two bands)\n",
    "    with rasterio.open(image_path) as src:\n",
    "        # Read the VV and VH bands\n",
    "        vv = src.read(1)  # VV is in the first band\n",
    "        vh = src.read(2)  # VH is in the second band\n",
    "\n",
    "        # Get the extent of the image (top-left and bottom-right coordinates)\n",
    "        transform = src.transform\n",
    "        height, width = vv.shape\n",
    "        top_left = rasterio.transform.xy(transform, 0, 0, offset='center')\n",
    "        bottom_right = rasterio.transform.xy(transform, height - 1, width - 1, offset='center')\n",
    "\n",
    "    # Extract easting and northing from the corners\n",
    "    min_easting, max_northing = top_left\n",
    "    max_easting, min_northing = bottom_right\n",
    "\n",
    "    # Prepare the bounding box as a shapely geometry\n",
    "    bbox_geom = box(*bbox)  # Ensure bbox is an iterable [min_x, min_y, max_x, max_y]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 6))  # Two subplots for VV and VH bands\n",
    "\n",
    "    # VV raster visualization with bounding box\n",
    "    ax[0].imshow(vv, cmap='gray', extent=[min_easting, max_easting, min_northing, max_northing])\n",
    "    x, y = bbox_geom.exterior.xy  # Extract coordinates for plotting the bounding box\n",
    "    ax[0].plot(x, y, color='red', linewidth=2, label=\"Sentinel-2 Coverage\")\n",
    "    ax[0].set_title('VV Band with Bounding Box')\n",
    "    ax[0].set_xlabel('Easting (meters)')\n",
    "    ax[0].set_ylabel('Northing (meters)')\n",
    "    ax[0].xaxis.set_major_locator(mticker.MaxNLocator(5))  # Reduce x-axis ticks\n",
    "    ax[0].yaxis.set_major_locator(mticker.MaxNLocator(5))  \n",
    "    ax[0].legend(loc='lower right')\n",
    "\n",
    "    # VH raster visualization with bounding box\n",
    "    ax[1].imshow(vh, cmap='gray', extent=[min_easting, max_easting, min_northing, max_northing])\n",
    "    ax[1].plot(x, y, color='red', linewidth=2, label=\"Sentinel-2 Coverage\")\n",
    "    ax[1].set_title('VH Band with Bounding Box')\n",
    "    ax[1].set_xlabel('Easting (meters)')\n",
    "    ax[1].set_ylabel('Northing (meters)')\n",
    "    ax[1].xaxis.set_major_locator(mticker.MaxNLocator(5))  # Reduce x-axis ticks\n",
    "    ax[1].yaxis.set_major_locator(mticker.MaxNLocator(5))  \n",
    "    ax[1].legend(loc='lower right')\n",
    "\n",
    "    # Show the plot with layout adjustments\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def get_EPSG(im):\n",
    "    src = gdal.Open(im)\n",
    "    wkt_projection = src.GetProjection()\n",
    "    spatial_ref = osr.SpatialReference()\n",
    "    spatial_ref.ImportFromWkt(wkt_projection)\n",
    "    epsg_code = spatial_ref.GetAttrValue('AUTHORITY', 1)\n",
    "    print(epsg_code)\n",
    "\n",
    "    return epsg_code \n",
    "\n",
    "def reproject_raster(input_raster, output_raster, target_crs='EPSG:32615'):\n",
    "\n",
    "    # Reproject using gdal.Warp\n",
    "    warp_options = gdal.WarpOptions(dstSRS=target_crs)\n",
    "    gdal.Warp(output_raster, input_raster, options=warp_options)\n",
    "\n",
    "def clip_raster_by_bbox(input_raster, output_raster, bbox):\n",
    "    # Define the output bounds (min_x, min_y, max_x, max_y)\n",
    "    min_x, min_y, max_x, max_y = bbox\n",
    "\n",
    "    # Use gdal.Translate to clip the raster by the bounding box\n",
    "    options = gdal.TranslateOptions(projWin=[min_x, max_y, max_x, min_y])  # Note the order: projWin=[min_x, max_y, max_x, min_y]\n",
    "    \n",
    "    # Perform the clipping operation\n",
    "    gdal.Translate(output_raster, input_raster, options=options)\n",
    "\n",
    "\n",
    "def perform_pca(image_path, output_pca_path):\n",
    "    dataset = gdal.Open(image_path)\n",
    "\n",
    "    # Read all bands as separate arrays\n",
    "    bands = [dataset.GetRasterBand(1).ReadAsArray(),  dataset.GetRasterBand(2).ReadAsArray()]\n",
    "\n",
    "    # Convert the list of bands into a 3D NumPy array (bands, rows, cols)\n",
    "    bands_array = np.stack(bands, axis=0)\n",
    "\n",
    "    # Reshape the bands array into (pixels, bands) for PCA\n",
    "    pixels, bands_count = bands_array.shape[1] * bands_array.shape[2], bands_array.shape[0]\n",
    "    flattened_image = bands_array.reshape(bands_count, -1).T  # Shape: (pixels, bands)\n",
    "\n",
    "    # Convert to float32 for OpenCV PCA\n",
    "    flattened_image = flattened_image.astype(np.float32)\n",
    "\n",
    "    # Perform PCA using OpenCV (reduce to 1 principal component)\n",
    "    mean, eigenvectors = cv2.PCACompute(flattened_image, mean=None, maxComponents=1)\n",
    "    pca_result = cv2.PCAProject(flattened_image, mean, eigenvectors)\n",
    "\n",
    "    # Reshape the PCA result back to the original image dimensions\n",
    "    pca_image = pca_result.reshape(bands_array.shape[1], bands_array.shape[2])\n",
    "    # pca_image = np.nan_to_num(pca_image, nan=0.0, posinf=255.0, neginf=0.0)\n",
    "\n",
    "    # Normalize the PCA image to 0-255 for OpenCV processing\n",
    "    pca_image_normalized = cv2.normalize(pca_image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "    # Save the PCA-reduced image\n",
    "    output = gdal.GetDriverByName('GTiff').Create(output_pca_path, dataset.RasterXSize, dataset.RasterYSize, 1, gdal.GDT_Float32)\n",
    "    output.SetProjection(dataset.GetProjection())\n",
    "    output.SetGeoTransform(dataset.GetGeoTransform())\n",
    "    output.GetRasterBand(1).WriteArray(pca_image_normalized)\n",
    "    output.FlushCache()  # Ensure data is written to disk\n",
    "    output = None\n",
    "\n",
    "def register_images(reference_image, target_image, fill_value):\n",
    "    # Define warp mode: use affine transformation (can also use cv2.MOTION_EUCLIDEAN)\n",
    "    warp_mode = cv2.MOTION_TRANSLATION\n",
    "\n",
    "    # Initialize the transformation matrix (2x3 affine transformation matrix)\n",
    "    warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "\n",
    "    # Define criteria for the ECC algorithm\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 5000, 1e-6)\n",
    "\n",
    "    # Create binary masks where NaNs are located\n",
    "    reference_mask = np.isnan(reference_image).astype(np.uint8)\n",
    "    target_mask = np.isnan(target_image).astype(np.uint8)\n",
    "\n",
    "    # Replace NaN values with the specified fill_value\n",
    "    reference_image = np.nan_to_num(reference_image, nan=fill_value)\n",
    "    target_image = np.nan_to_num(target_image, nan=fill_value)\n",
    "\n",
    "    # Apply masks to the images to ignore NaN areas\n",
    "    reference_image *= (1 - reference_mask)\n",
    "    target_image *= (1 - target_mask)\n",
    "\n",
    "    # Perform the ECC algorithm to find the transformation matrix\n",
    "    try:\n",
    "        cc, warp_matrix = cv2.findTransformECC(reference_image, target_image, warp_matrix, warp_mode, criteria)\n",
    "    except cv2.error as e:\n",
    "        print(f\"Error in ECC: {e}\")\n",
    "        return None\n",
    "\n",
    "    return warp_matrix\n",
    "\n",
    "def apply_transformation_to_all_bands(target_bands, warp_matrix, image_shape, output_dtype=np.float32):\n",
    "    transformed_bands = []\n",
    "    \n",
    "    for band in target_bands:\n",
    "        # Apply the transformation to the band\n",
    "        transformed_band = cv2.warpAffine(band.astype(np.float32), warp_matrix, (image_shape[1], image_shape[0]), \n",
    "                                          flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "        \n",
    "        # Handle NaN or infinite values by replacing them with valid values (e.g., 0)\n",
    "        # transformed_band = np.nan_to_num(transformed_band, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        \n",
    "        # Convert to the desired output data type\n",
    "        transformed_band = transformed_band.astype(output_dtype)\n",
    "        \n",
    "        transformed_bands.append(transformed_band)\n",
    "    \n",
    "    return transformed_bands\n",
    "\n",
    "def save_multiband_image_as_tiff(output_path, transformed_bands, reference_dataset, gdal_dtype=gdal.GDT_Float32):\n",
    "    # Create an output GeoTIFF file with the same dimensions and the same number of bands\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    out_dataset = driver.Create(output_path, reference_dataset.RasterXSize, reference_dataset.RasterYSize, len(transformed_bands), gdal_dtype)\n",
    "\n",
    "    # Set the projection and geotransform from the reference dataset\n",
    "    out_dataset.SetProjection(reference_dataset.GetProjection())\n",
    "    out_dataset.SetGeoTransform(reference_dataset.GetGeoTransform())\n",
    "\n",
    "    # Write each transformed band to the output file\n",
    "    for i, transformed_band in enumerate(transformed_bands):\n",
    "        out_dataset.GetRasterBand(i + 1).WriteArray(transformed_band)\n",
    "\n",
    "    # Flush data to disk\n",
    "    out_dataset.FlushCache()\n",
    "    out_dataset = None\n",
    "\n",
    "def sar_ratio(impathlist, outpath):\n",
    "    for im in impathlist:\n",
    "        testds = gdal.Open(im)\n",
    "\n",
    "        vv_dB = testds.GetRasterBand(1).ReadAsArray()  #.astype(float)\n",
    "        vh_dB = testds.GetRasterBand(2).ReadAsArray()    #.astype(float)\n",
    "\n",
    "        # Convert from dB to linear scale\n",
    "        vv_linear = 10 ** (vv_dB / 10)\n",
    "        vh_linear = 10 ** (vh_dB / 10)\n",
    "\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            ratio1 = (4 * vh_linear)/(vh_linear + vv_linear) # sentinel-1 radar veg index\n",
    "            ratio1[ratio1 == np.inf] = np.nan\n",
    "            ratio2 = np.log(10 * vv_linear * vh_linear) # sentinel-1 dual-polarization water index\n",
    "            ratio2[ratio2 == np.inf] = np.nan\n",
    "\n",
    "\n",
    "        save_multiband_image_as_tiff(os.path.join(outpath, im[-14:]), [vv_dB, vh_dB, ratio1, ratio2], testds)\n",
    "\n",
    "def get_grd_avg(grd_avg_path, combined_ims):\n",
    "    # Open all the combined .vrt files and read their bands\n",
    "    all_bands = []\n",
    "    \n",
    "    # Loop over each file to read its bands\n",
    "    for f in combined_ims:\n",
    "        ds = gdal.Open(f)\n",
    "        bands = [ds.GetRasterBand(i+1).ReadAsArray() for i in range(ds.RasterCount)]\n",
    "        all_bands.append(bands)\n",
    "    \n",
    "    # Stack the bands across all images (axis=0 for stacking across different images)\n",
    "    stacked_bands = [np.stack([image_bands[i] for image_bands in all_bands], axis=0) for i in range(len(all_bands[0]))]\n",
    "    \n",
    "    # Compute the mean for each band across the stacked images (axis=0 is across images)\n",
    "    mean_bands = [np.mean(stacked_band, axis=0) for stacked_band in stacked_bands]\n",
    "\n",
    "    # Create a new GeoTIFF with the averaged bands\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    \n",
    "    # Use the first file for spatial reference (CRS and geotransform)\n",
    "    ds = gdal.Open(combined_ims[0])\n",
    "    \n",
    "    # Create an output file with the same dimensions and number of bands as the input\n",
    "    result = driver.Create(grd_avg_path, ds.RasterXSize, ds.RasterYSize, len(mean_bands), gdal.GDT_Float32)\n",
    "\n",
    "    # Copy projection and geotransform from the original dataset\n",
    "    result.SetProjection(ds.GetProjection())\n",
    "    result.SetGeoTransform(ds.GetGeoTransform())\n",
    "\n",
    "    # Write each averaged band to the output file\n",
    "    for i, meanband in enumerate(mean_bands):\n",
    "        result.GetRasterBand(i+1).WriteArray(meanband)\n",
    "\n",
    "    # Close the result dataset to flush the data to disk\n",
    "    result = None\n",
    "\n",
    "    return grd_avg_path\n",
    "\n",
    "def perform_pca(image_path, output_pca_path):\n",
    "    # Load the Sentinel-2 multi-band image using GDAL\n",
    "    dataset = gdal.Open(image_path)\n",
    "\n",
    "    # Read all bands as separate arrays\n",
    "    bands = [dataset.GetRasterBand(i + 1).ReadAsArray() for i in range(dataset.RasterCount)]\n",
    "\n",
    "    # Convert the list of bands into a 3D NumPy array (bands, rows, cols)\n",
    "    bands_array = np.stack(bands, axis=0)\n",
    "\n",
    "    # Reshape the bands array into (pixels, bands) for PCA\n",
    "    pixels, bands_count = bands_array.shape[1] * bands_array.shape[2], bands_array.shape[0]\n",
    "    flattened_image = bands_array.reshape(bands_count, -1).T  # Shape: (pixels, bands)\n",
    "\n",
    "    # Convert to float32 for OpenCV PCA\n",
    "    flattened_image = flattened_image.astype(np.float32)\n",
    "\n",
    "    # Perform PCA using OpenCV (reduce to 1 principal component)\n",
    "    mean, eigenvectors = cv2.PCACompute(flattened_image, mean=None, maxComponents=1)\n",
    "    pca_result = cv2.PCAProject(flattened_image, mean, eigenvectors)\n",
    "\n",
    "    # Reshape the PCA result back to the original image dimensions\n",
    "    pca_image = pca_result.reshape(bands_array.shape[1], bands_array.shape[2])\n",
    "    # pca_image = np.nan_to_num(pca_image, nan=0.0, posinf=255.0, neginf=0.0)\n",
    "\n",
    "    # Normalize the PCA image to 0-255 for OpenCV processing\n",
    "    pca_image_normalized = cv2.normalize(pca_image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "    # Save the PCA-reduced image\n",
    "    output = gdal.GetDriverByName('GTiff').Create(output_pca_path, dataset.RasterXSize, dataset.RasterYSize, 1, gdal.GDT_Float32)\n",
    "    output.SetProjection(dataset.GetProjection())\n",
    "    output.SetGeoTransform(dataset.GetGeoTransform())\n",
    "    output.GetRasterBand(1).WriteArray(pca_image_normalized)\n",
    "    output.FlushCache()  # Ensure data is written to disk\n",
    "    output = None\n",
    "\n",
    "def plot_class_with_grd(grd_path, otsu_class, kmeans_class, gmm_class): \n",
    "\n",
    "    with rasterio.open(grd_path) as rat_src:\n",
    "        vv = rat_src.read(1) #vv\n",
    "        vh = rat_src.read(2) #vh\n",
    "        rvi = rat_src.read(3) #RVI\n",
    "        sdwi = rat_src.read(4)   #SDWI\n",
    "\n",
    "        rvi = min_max_scale(rvi, np.nanmin(rvi), np.nanmax(rvi))\n",
    "        vh = min_max_scale(vh, np.nanmin(vh), np.nanmax(vh))\n",
    "        vv = min_max_scale(vv, np.nanmin(vv), np.nanmax(vv))\n",
    "        sdwi = min_max_scale(sdwi, np.nanmin(sdwi), np.nanmax(sdwi))\n",
    "\n",
    "\n",
    "        transform = rat_src.transform\n",
    "        height, width = vv.shape[:2]\n",
    "        top_left = rasterio.transform.xy(transform, 0, 0, offset='center')\n",
    "        bottom_right = rasterio.transform.xy(transform, height-1, width-1, offset='center')\n",
    "\n",
    "    # Extract easting and northing from the corners\n",
    "    min_easting, max_northing = top_left\n",
    "    max_easting, min_northing = bottom_right\n",
    "\n",
    "    # Define a custom colormap for the classifications\n",
    "    cmap = ListedColormap(['blue', 'green', 'red'])  # Blue for class 0, Green for class 1, Red for class 2\n",
    "\n",
    "    fig, ax = plt.subplots(1, 5, figsize=(30, 6))  # 5 subplots for RGB, Otsu, K-Means, GMM, and Majority Vote\n",
    "\n",
    "    # VV image visualization\n",
    "    ax[0].imshow(vv, extent=[min_easting, max_easting, min_northing, max_northing])\n",
    "    ax[0].set_title(f'{grd_path[-14:-4]} VV')\n",
    "    ax[0].set_xlabel('Easting (meters)')\n",
    "    ax[0].set_ylabel('Northing (meters)')\n",
    "    ax[0].xaxis.set_major_locator(mticker.MaxNLocator(5))  # Reduce x-axis ticks\n",
    "\n",
    "    # VH visualization\n",
    "    ax[1].imshow(vh, extent=[min_easting, max_easting, min_northing, max_northing])\n",
    "    ax[1].set_title(f'{grd_path[-14:-4]} VH')\n",
    "    ax[1].set_xlabel('Easting (meters)')\n",
    "    ax[1].set_ylabel('Northing (meters)')\n",
    "    ax[1].xaxis.set_major_locator(mticker.MaxNLocator(5))  # Reduce x-axis ticks\n",
    "\n",
    "    # Custom legends for classification plots\n",
    "    red_patch = mpatches.Patch(color='red', label='Subaerial Land')\n",
    "    green_patch = mpatches.Patch(color='green', label='Subaqueous Land')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='Open Water')\n",
    "\n",
    "    # Otsu classification visualization\n",
    "    ax[2].imshow(otsu_class, cmap=cmap, extent=[min_easting, max_easting, min_northing, max_northing])\n",
    "    ax[2].set_title('Otsu')\n",
    "    ax[2].set_xlabel('Easting (meters)')\n",
    "    ax[2].legend(handles=[blue_patch, green_patch, red_patch], loc='lower right', title=\"Classification\")\n",
    "    ax[2].xaxis.set_major_locator(mticker.MaxNLocator(5))  # Reduce x-axis ticks\n",
    "\n",
    "    # K-Means classification visualization\n",
    "    ax[3].imshow(kmeans_class, cmap=cmap, extent=[min_easting, max_easting, min_northing, max_northing])\n",
    "    ax[3].set_title('KMeans')\n",
    "    ax[3].set_xlabel('Easting (meters)')\n",
    "    ax[3].legend(handles=[blue_patch, green_patch, red_patch], loc='lower right', title=\"Classification\")\n",
    "    ax[3].xaxis.set_major_locator(mticker.MaxNLocator(5))  # Reduce x-axis ticks\n",
    "\n",
    "    # GMM classification visualization\n",
    "    ax[4].imshow(gmm_class, cmap=cmap, extent=[min_easting, max_easting, min_northing, max_northing])\n",
    "    ax[4].set_title('GMM')\n",
    "    ax[4].set_xlabel('Easting (meters)')\n",
    "    ax[4].legend(handles=[blue_patch, green_patch, red_patch], loc='lower right', title=\"Classification\")\n",
    "    ax[4].xaxis.set_major_locator(mticker.MaxNLocator(5))  # Reduce x-axis ticks\n",
    "    \n",
    "\n",
    "\n",
    "    # Show the plot with layout adjustments\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def min_max_scale(band, band_min, band_max):\n",
    "    \"\"\"Normalize band to [0, 1] range.\"\"\"\n",
    "    return (band - band_min) / (band_max - band_min)\n",
    "\n",
    "def kmeans_land_water(image_path1, n_clusters):\n",
    "    # Read the first image\n",
    "    with rasterio.open(image_path1) as src1:\n",
    "        img1 = src1.read()  # Read all bands\n",
    "        height, width = img1.shape[1], img1.shape[2]\n",
    "\n",
    "    img1 = min_max_scale(img1, np.nanmin(img1), np.nanmax(img1))\n",
    "\n",
    "    # Reshape to (num_pixels, num_bands)\n",
    "    img_flat = img1.reshape((img1.shape[0], height * width)).T\n",
    "\n",
    "    # Remove rows with NaN values\n",
    "    mask = ~np.isnan(img_flat).any(axis=1)\n",
    "    img_no_nan = img_flat[mask]\n",
    "\n",
    "    # Apply K-Means clustering only on non-NaN pixels\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(img_no_nan)\n",
    "\n",
    "    # Initialize an output array filled with NaNs\n",
    "    classified_img = np.full((height * width), np.nan)\n",
    "\n",
    "    # Set the labels to the non-NaN pixels\n",
    "    classified_img[mask] = kmeans.labels_\n",
    "\n",
    "    # Reshape the classified image back to (height, width)\n",
    "    classified_img = classified_img.reshape((height, width))\n",
    "    return classified_img\n",
    "\n",
    "def gmm_land_water(image_path1, n_components):\n",
    "    # Read the first image\n",
    "    with rasterio.open(image_path1) as src1:\n",
    "        img1 = src1.read()  # Read all bands\n",
    "        height, width = img1.shape[1], img1.shape[2]\n",
    "    \n",
    "\n",
    "    img1 = min_max_scale(img1, np.nanmin(img1), np.nanmax(img1))\n",
    "\n",
    "    # Reshape to (num_pixels, num_bands)\n",
    "    img_flat = img1.reshape((img1.shape[0], height * width)).T\n",
    "\n",
    "    # Remove rows with NaN values\n",
    "    mask = ~np.isnan(img_flat).any(axis=1)\n",
    "    img_no_nan = img_flat[mask]\n",
    "\n",
    "    # Apply Gaussian Mixture Model only on non-NaN pixels\n",
    "    gmm = GaussianMixture(n_components=n_components, random_state=42).fit(img_no_nan)\n",
    "\n",
    "    # Predict labels for the non-NaN pixels\n",
    "    gmm_labels = np.full((height * width), np.nan)  # Initialize with NaN\n",
    "    gmm_labels[mask] = gmm.predict(img_no_nan)\n",
    "\n",
    "    # Reshape the labels back to (height, width)\n",
    "    gmm_labels = gmm_labels.reshape((height, width))\n",
    "\n",
    "    return gmm_labels\n",
    "\n",
    "\n",
    "def process_image_pca_otsu(imagepath):\n",
    "    # Step 1: Read and normalize the bands\n",
    "    with rasterio.open(imagepath) as src:\n",
    "        vv = src.read(1)  # VV band\n",
    "        vh = src.read(2)  # VH band\n",
    "        rvi = src.read(3)  # RVI\n",
    "        sdwi = src.read(4)  # SDWI\n",
    "\n",
    "    # Convert VV and VH from dB to linear scale\n",
    "    vv = 10 ** (vv / 10)\n",
    "    vh = 10 ** (vh / 10)\n",
    "\n",
    "    # Normalize each band to [0, 1]\n",
    "    vv = min_max_scale(vv, np.nanmin(vv), np.nanmax(vv))\n",
    "    vh = min_max_scale(vh, np.nanmin(vh), np.nanmax(vh))\n",
    "    rvi = min_max_scale(rvi, np.nanmin(rvi), np.nanmax(rvi))\n",
    "    sdwi = min_max_scale(sdwi, np.nanmin(sdwi), np.nanmax(sdwi))\n",
    "\n",
    "    # Stack the bands and reshape for PCA\n",
    "    bands_stack = np.stack([vv, vh, rvi, sdwi], axis=-1)\n",
    "    n_rows, n_cols, n_bands = bands_stack.shape\n",
    "    pixels_2d = bands_stack.reshape(-1, n_bands)\n",
    "\n",
    "    # Remove NaN or invalid values\n",
    "    valid_mask = np.all(np.isfinite(pixels_2d), axis=1)\n",
    "    valid_pixels = pixels_2d[valid_mask]\n",
    "\n",
    "    # Apply PCA and reshape the first component back to 2D\n",
    "    pca = PCA(n_components=1)\n",
    "    pca_band = pca.fit_transform(valid_pixels)\n",
    "    pca_2d = np.full((n_rows * n_cols), np.nan)\n",
    "    pca_2d[valid_mask] = pca_band.flatten()\n",
    "    pca_2d = pca_2d.reshape(n_rows, n_cols)\n",
    "\n",
    "    # Step 2: Apply Bimodal Otsu Thresholding for Two Classes\n",
    "    pca_valid = pca_2d[~np.isnan(pca_2d)]\n",
    "    threshold = threshold_otsu(pca_valid)\n",
    "    classified_image = (pca_2d > threshold).astype(int)  # 0 for subaqueous, 1 for subaerial\n",
    "\n",
    "    return pca_2d, classified_image\n",
    "    \n",
    "def plot_majvote_with_grd(grd_path, majority_vote):\n",
    "    \n",
    "    with rasterio.open(grd_path) as rat_src:\n",
    "        vv = rat_src.read(1) #vv\n",
    "        vh = rat_src.read(2) #vh\n",
    "        rvi = rat_src.read(3) #RVI\n",
    "        sdwi = rat_src.read(4)   #SDWI\n",
    "\n",
    "        rvi = min_max_scale(rvi, np.nanmin(rvi), np.nanmax(rvi))\n",
    "        vh = min_max_scale(vh, np.nanmin(vh), np.nanmax(vh))\n",
    "        vv = min_max_scale(vv, np.nanmin(vv), np.nanmax(vv))\n",
    "        sdwi = min_max_scale(sdwi, np.nanmin(sdwi), np.nanmax(sdwi))\n",
    "\n",
    "\n",
    "        transform = rat_src.transform\n",
    "        height, width = vv.shape[:2]\n",
    "        top_left = rasterio.transform.xy(transform, 0, 0, offset='center')\n",
    "        bottom_right = rasterio.transform.xy(transform, height-1, width-1, offset='center')\n",
    "\n",
    "    # Extract easting and northing from the corners\n",
    "    min_easting, max_northing = top_left\n",
    "    max_easting, min_northing = bottom_right\n",
    "\n",
    "    # Define a custom colormap for the classifications\n",
    "    cmap = ListedColormap(['blue', 'green', 'red'])  # Blue for class 0, Green for class 1, Red for class 2\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 6))  # 5 subplots for grd, Otsu, K-Means, GMM, and Majority Vote\n",
    "\n",
    "    # VV image visualization\n",
    "    ax[0].imshow(vv, extent=[min_easting, max_easting, min_northing, max_northing])\n",
    "    ax[0].set_title(f'{grd_path[-14:-4]} VV')\n",
    "    ax[0].set_xlabel('Easting (meters)')\n",
    "    ax[0].set_ylabel('Northing (meters)')\n",
    "    ax[0].xaxis.set_major_locator(mticker.MaxNLocator(5))  # Reduce x-axis ticks\n",
    "\n",
    "    # VH visualization\n",
    "    ax[1].imshow(vh, extent=[min_easting, max_easting, min_northing, max_northing])\n",
    "    ax[1].set_title(f'{grd_path[-14:-4]} VH')\n",
    "    ax[1].set_xlabel('Easting (meters)')\n",
    "    ax[1].set_ylabel('Northing (meters)')\n",
    "    ax[1].xaxis.set_major_locator(mticker.MaxNLocator(5))  # Reduce x-axis ticks\n",
    "\n",
    "    # Custom legends for classification plots\n",
    "    red_patch = mpatches.Patch(color='red', label='Subaerial Land')\n",
    "    green_patch = mpatches.Patch(color='green', label='Subaqueous Land')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='Open Water')\n",
    "    \n",
    "    # Majority vote classification visualization\n",
    "    ax[2].imshow(majority_vote, cmap=cmap, extent=[min_easting, max_easting, min_northing, max_northing])\n",
    "    ax[2].set_title('Majority Vote')\n",
    "    ax[2].set_xlabel('Easting (meters)')\n",
    "    ax[2].legend(handles=[blue_patch, green_patch, red_patch], loc='lower right', title=\"Classification\")\n",
    "    ax[2].xaxis.set_major_locator(mticker.MaxNLocator(5))  # Reduce x-axis ticks\n",
    "\n",
    "    # Show the plot with layout adjustments\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def calculate_mean_vh_for_classes(ratio_im_path, labels_list):\n",
    "    # Read the vh band image\n",
    "    with rasterio.open(ratio_im_path) as src:\n",
    "        vh = src.read(2)  # Assuming the vh band is in second position\n",
    "\n",
    "    # Initialize lists to store mean vh for each class\n",
    "    mean_vh_class0 = [] # subaqueous\n",
    "    mean_vh_class1 = [] # subaerial \n",
    "\n",
    "    # Iterate through each set of labels\n",
    "    for labels in labels_list:\n",
    "        # Create masks for each class\n",
    "        class0_mask = (labels == 0) # subaqueous\n",
    "        class1_mask = (labels == 1) # subaerial\n",
    "\n",
    "        # Calculate the mean vh for each class, ignoring NaNs\n",
    "        mean_vh_0 = np.nanmean(vh[class0_mask])\n",
    "        mean_vh_1 = np.nanmean(vh[class1_mask])\n",
    "\n",
    "        # Append the mean values to the lists\n",
    "        mean_vh_class0.append(mean_vh_0)\n",
    "        mean_vh_class1.append(mean_vh_1)\n",
    "\n",
    "    return mean_vh_class0, mean_vh_class1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get original Sentienl-1 GRD VV+VH (dB) and GLCM texture data downloaded from Google Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### WSL #########################\n",
    "work_dir = '/mnt/d/SabineRS'\n",
    "\n",
    "############### linux #########################\n",
    "# work_dir = '/home/wcc/Desktop/SabineRS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the directory for where your images are located\n",
    "\n",
    "############### WSL #########################\n",
    "orig_ims = get_grd('/mnt/d/SabineRS/GRD/0_initial/backscatter')\n",
    "orig_glcms = get_glcm('/mnt/d/SabineRS/GRD/0_initial/glcm')\n",
    "\n",
    "############### Linux #########################\n",
    "# orig_ims = get_grd('/home/wcc/Desktop/SabineRS/GRD/0_initial/backscatter')\n",
    "# orig_glcms = get_glcm('/home/wcc/Desktop/SabineRS/GRD/0_initial/glcm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Clip all images to same extent of first image in time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the CRS\n",
    "orig_epsg = get_EPSG(orig_ims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a bbox for plotting\n",
    "\n",
    "src = gdal.Open(orig_ims[0])\n",
    "geo_transform = src.GetGeoTransform()\n",
    "coords = [geo_transform[0], \n",
    "           geo_transform[0] + (src.RasterXSize * geo_transform[1]), \n",
    "           geo_transform[3] + (src.RasterYSize * geo_transform[5]), \n",
    "           geo_transform[3]\n",
    "            ]\n",
    "bbox = [coords[0], coords[2], coords[1], coords[3]]\n",
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i , im in enumerate(orig_ims):\n",
    "    clip_raster_by_bbox(im, os.path.join(work_dir, f'GRD/1_clipped/backscatter/{im[-17:]}'), bbox)\n",
    "\n",
    "    clip_raster_by_bbox(orig_glcms[i], os.path.join(work_dir, f'GRD/1_clipped/{orig_glcms[i][-22:]}'), bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the reprojected and clipped data\n",
    "clip_orig = get_grd(os.path.join(work_dir, f'GRD/1_clipped/backscatter'))\n",
    "clip_orig_glcms = get_glcm(os.path.join(work_dir, f'GRD/1_clipped/glcm'))\n",
    "\n",
    "clip_orig = sorted(clip_orig, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))\n",
    "clip_orig_glcms = sorted(clip_orig_glcms, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate VV/VH ratio bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vv, vh, sentinel-1 radar veg index, and sentinel-1 dual-pol water index\n",
    "\n",
    "sar_ratio(clip_orig, f'/mnt/d/SabineRS/GRD/3_ratio')\n",
    "# sar_ratio(clip_orig, f'/home/wcc/Desktop/SabineRS/GRD/3_ratio')\n",
    "ratio_ims = [os.path.join('/mnt/d/SabineRS/GRD/3_ratio', file) for file in os.listdir('/mnt/d/SabineRS/GRD/3_ratio') if file.endswith('.tif')]\n",
    "# ratio_ims = [os.path.join('/home/wcc/Desktop/SabineRS/GRD/3_ratio', file) for file in os.listdir('/home/wcc/Desktop/SabineRS/GRD/3_ratio') if file.endswith('.tif')]\n",
    "ratio_ims = sorted(ratio_ims, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Apply unsupervised classification methods to classify (hopefully) classify subaerial land, subaqeuous land, and open water from SAR iamagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otsuclasses = []\n",
    "kmeansclasses = []\n",
    "gmmclasses = []\n",
    "\n",
    "\n",
    "for i, im in enumerate(ratio_ims):\n",
    "    km = kmeans_land_water(im, 2)\n",
    "    gmm = gmm_land_water(im, 2)\n",
    "    kmeansclasses.append(km)\n",
    "    gmmclasses.append(gmm)\n",
    "    \n",
    "    pca_2d, binary_mask = process_image_pca_otsu(im)\n",
    "    otsuclasses.append(binary_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct the classes based on VH backscatter values\n",
    "# class 0=open water will ahve the lowest mean VH backscatter\n",
    "# class 2=Subaerial land will have the highest mean VH backscatter\n",
    "# class 1=Subaqueuous land will be in the middle\n",
    "\n",
    "# Extracting the mean VH backscatter for each class\n",
    "vh_means_otsu = []\n",
    "vh_means_kmeans = []\n",
    "vh_means_gmm = []\n",
    "\n",
    "for i, vh_im in enumerate(ratio_ims):\n",
    "    # Calculate mean vh for current vh image and K-means/GMM labels\n",
    "    mean_vh_otsu_0, mean_vh_otsu_1 = calculate_mean_vh_for_classes(vh_im, [otsuclasses[i]])\n",
    "    mean_vh_km_0, mean_vh_km_1 = calculate_mean_vh_for_classes(vh_im, [kmeansclasses[i]])\n",
    "    mean_vh_gmm_0, mean_vh_gmm_1 = calculate_mean_vh_for_classes(vh_im, [gmmclasses[i]])\n",
    "    \n",
    "    # Store the results\n",
    "    vh_means_otsu.append((mean_vh_otsu_0[0], mean_vh_otsu_1[0]))\n",
    "    vh_means_kmeans.append((mean_vh_km_0[0], mean_vh_km_1[0]))\n",
    "    vh_means_gmm.append((mean_vh_gmm_0[0], mean_vh_gmm_1[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the relabeled images\n",
    "relabeled_images = {\"otsu\": [], \"kmeans\": [], \"gmm\": []}\n",
    "\n",
    "# Relabeling each image in the time series\n",
    "# List of classifier methods for looping\n",
    "classification_methods = [\"otsu\", \"kmeans\", \"gmm\"]\n",
    "\n",
    "for i, (method, entry) in enumerate(zip(classification_methods, [[vh_means_otsu, otsuclasses], [vh_means_kmeans, kmeansclasses], [vh_means_gmm, gmmclasses]])):\n",
    "    for j in range(len(entry[0])):\n",
    "        labelsort = np.argsort(entry[0][j])\n",
    "\n",
    "        # Create a relabel map to remap the classes to [0, 1]\n",
    "        relabel_map = {labelsort[idx]: float(idx) for idx in range(len(labelsort))}\n",
    "\n",
    "        # Copy the classified image to avoid overwriting the original\n",
    "        image_copy = copy.deepcopy(entry[1][j]).astype(float)  # Ensure image_copy is float type to support np.nan\n",
    "\n",
    "        # Replace None values with np.nan for consistency\n",
    "        image_copy = np.where(image_copy == None, np.nan, image_copy)  # Convert None to np.nan\n",
    "\n",
    "        # Apply the relabel map directly, preserving np.nan values\n",
    "        relabeled_image = image_copy.copy()\n",
    "        for original_label, new_label in relabel_map.items():\n",
    "            relabeled_image = np.where(image_copy == original_label, new_label, relabeled_image)\n",
    "\n",
    "        # Add the processed relabeled image to the dictionary\n",
    "        relabeled_images[method].append(relabeled_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_ims = {\"otsu\": [],\n",
    "               \"kmeans\": [], \n",
    "               \"gmm\": []\n",
    "               }\n",
    "\n",
    "for i, (method, entry) in enumerate(zip(classification_methods, [relabeled_images['otsu'], relabeled_images[\"kmeans\"], relabeled_images['gmm']])):\n",
    "    for j, im in enumerate(entry):\n",
    "        # Define a square kernel; adjust the size as needed\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "        # apply morphological functions to eliminate isolated pixels from each class\n",
    "        subaqueous = (im == 0).astype(np.uint8)\n",
    "        subaerial = (im == 1).astype(np.uint8)\n",
    "\n",
    "        ######## KMeans\n",
    "        # Apply opening to remove small isolated pixels\n",
    "        subaerial_cleaned = cv2.morphologyEx(subaerial, cv2.MORPH_OPEN, kernel)\n",
    "        subaqueous_cleaned = cv2.morphologyEx(subaqueous, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Apply closing to fill small holes\n",
    "        subaerial_cleaned = cv2.morphologyEx(subaerial_cleaned, cv2.MORPH_CLOSE, kernel)\n",
    "        subaqueous_cleaned = cv2.morphologyEx(subaqueous_cleaned, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Reconstruct the classified image\n",
    "        cleaned_classified_image = (subaqueous_cleaned * i +\n",
    "                                    subaqueous_cleaned * 1)      \n",
    "\n",
    "        # Add the processed relabeled image to the dictionary\n",
    "        cleaned_ims[method].append(cleaned_classified_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, im in enumerate([ratio_ims[0], ratio_ims[69], ratio_ims[137]]):\n",
    "    plot_class_with_grd(\n",
    "        im,\n",
    "        cleaned_ims['otsu'][i], \n",
    "        cleaned_ims['kmeans'][i],\n",
    "        cleaned_ims['gmm'][i]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Use majority voting via the mode of the three classes for each time stamp.\n",
    "- Final classification will be the where the pixel is the same class in 2/3 of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the majority vote result for each image\n",
    "majority_vote_images = []\n",
    "\n",
    "# Loop through each image, applying majority voting across the methods for each pixel\n",
    "for j in range(len(otsuclasses)):  # Assuming all methods have the same number of images\n",
    "    # Stack the three classification arrays for image `j` across the method dimension (0)\n",
    "    # Shape will be (methods, height, width) -> (3, height, width)\n",
    "    stacked_classes = np.stack([otsuclasses[j], kmeansclasses[j], gmmclasses[j]], axis=0)\n",
    "    \n",
    "    # Apply majority voting along the first axis (methods)\n",
    "    majority_vote = mode(stacked_classes, axis=0, nan_policy='omit')[0].squeeze()\n",
    "    \n",
    "    # Store the result in the majority vote list\n",
    "    majority_vote_images.append(majority_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, im in enumerate([ratio_ims[0], ratio_ims[69], ratio_ims[137]]):\n",
    "    plot_majvote_with_grd(\n",
    "        im,\n",
    "        majority_vote_images[i]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
