{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will serve as the interactive notebook for leveraging the SNAP Graph Processing Tool using the subprocess library. \n",
    "- Allows for easier bulk processing of many interferograms, which is needed for non-zero closure phase correction (InSAR triplets)\n",
    "- Allows for easier bulk processing of custom GRD-like products (will produce both calibrate and uncalibrated backscatter data for classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os\n",
    "from time import perf_counter\n",
    "import subprocess\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_dir(cwd, project_name):\n",
    "    work_dir = os.path.join(cwd, project_name)\n",
    "    os.makedirs(work_dir, exist_ok=True)\n",
    "    data_dir = os.path.join(work_dir,'0_initial')\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    return work_dir, data_dir\n",
    "\n",
    "def get_triplets(slc_list):\n",
    "    \"\"\"\n",
    "    this program will generate a dictionary with keys triplet_n, where n is the triplet stack\n",
    "    each triplet_n contains 4 sets. Each set contains (path/to/ref.xml, path/to/sec.xml)\n",
    "    \n",
    "    slc_zips = list of directories containing the topsApp, reference, and secondary .xml files    \n",
    "    created an returned using the project_dir fucntion\n",
    "    \"\"\"\n",
    "    \n",
    "    triplet_dict={}\n",
    "    \n",
    "    for i in range(len(slc_list) - 2):\n",
    "        triplet_dict[f'triplet_{i+1}'] = ((slc_list[i],slc_list[i+1]), (slc_list[i+1],slc_list[i+2]), (slc_list[i+2], slc_list[i]))\n",
    "        if i == 0:\n",
    "            test_triplet = ((slc_list[i],slc_list[i+1]), (slc_list[i+1],slc_list[i+2]), (slc_list[i+2], slc_list[i]), (slc_list[i], slc_list[i+2]))\n",
    "        else:\n",
    "            continue\n",
    "    return triplet_dict, test_triplet\n",
    "\n",
    "def split_SLC(sourcefile,subswath, polarization, outfile):\n",
    "    split_cmd = [\n",
    "        GPT_PATH,\n",
    "        \"TOPSAR-Split\", # operation name\n",
    "        f\"-Ssource={sourcefile[6:]}\", # SLC file\n",
    "        f\"-Psubswath={subswath}\", #1, 2, 3\n",
    "        f\"-PselectedPolarisations={polarization}\", # bands being processed\n",
    "        \"-t\", outfile, # keep separate, output file location\n",
    "        \"-q\", str(MAX_CORES),\n",
    "        \"-c\", MAX_MEM\n",
    "    ]\n",
    "\n",
    "    # Run the command\n",
    "    try:\n",
    "        result = subprocess.run(split_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(\"Command executed successfully!\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Command failed with error code {e.returncode}\")\n",
    "        print(f\"Error message: {e.stderr}\")\n",
    "\n",
    "def orbit_SLC(sourcefile, orbittype, outfile):\n",
    "    orbit_cmd = [\n",
    "        GPT_PATH,\n",
    "        \"Apply-Orbit-File\", # operation name\n",
    "        f\"-Ssource={sourcefile}\",\n",
    "        f\"-PorbitType={orbittype}\",\n",
    "        \"-t\", outfile, # keep separate, output file location\n",
    "        \"-q\", str(MAX_CORES),\n",
    "        \"-c\", MAX_MEM\n",
    "    ]\n",
    "\n",
    "    # Run the command\n",
    "    try:\n",
    "        result = subprocess.run(orbit_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(\"Command executed successfully!\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Command failed with error code {e.returncode}\")\n",
    "        print(f\"Error message: {e.stderr}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps?\n",
    "\n",
    "1. split, orbit, coreg, ESD\n",
    "2. interferogram (topo phase removal, deburst, filter, subset)\n",
    "4. snaphu export unwrap import\n",
    "5. geocode, displacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish needed paths for notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish working directory, where your SLCs were stored\n",
    "# will also be where the processing steps for the interferograms and GRD-like products are stored\n",
    "work_dir, data_dir = project_dir('/mnt/d/SabineRS', 'Sentinel-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get your path to the SNAP GPT install\n",
    "# typically found in your 'esa-snap' install file in the 'bin' subdirectory\n",
    "# Linux example: ~/esa-snap/bin/gpt\n",
    "# WSL example: /mnt/c/Program Files/bin/gpt\n",
    "\n",
    "# Define paths and parameters\n",
    "GPT_PATH = '/mnt/c/Program Files/esa-snap/bin/gpt.exe'  # Path to SNAP's gpt executable\n",
    "INPUT_DIR = data_dir  # Directory containing Sentinel-1 SLCs\n",
    "OUTPUT_DIR = os.path.join(work_dir, 'test')  # Directory to save interferograms\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "MAX_CORES = 12  # Adjust based on system capacity\n",
    "MAX_MEM = '24G'  # Maximum memory for SNAP in bytes\n",
    "TILE_SIZE = 4096  # Tile size for SNAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Sentinel-1 SLC Files:\n",
      "1: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20170402T001815_20170402T001842_015958_01A507_82BB.zip\n",
      "2: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20170414T001816_20170414T001843_016133_01AA58_ED18.zip\n",
      "3: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20170508T001817_20170508T001844_016483_01B503_49B5.zip\n",
      "4: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20170520T001818_20170520T001845_016658_01BA5D_60AB.zip\n",
      "5: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20170601T001818_20170601T001845_016833_01BFC6_9708.zip\n",
      "6: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20170613T001819_20170613T001846_017008_01C531_BB6E.zip\n",
      "7: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20170625T001820_20170625T001847_017183_01CA88_4D5B.zip\n",
      "8: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20170731T001822_20170731T001849_017708_01DA7E_0990.zip\n",
      "9: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20170905T001823_20170905T001850_018233_01EA6C_8418.zip\n",
      "10: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20170917T001824_20170917T001851_018408_01EFE0_4FED.zip\n",
      "11: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20170929T001824_20170929T001851_018583_01F536_AAA8.zip\n",
      "12: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20171011T001824_20171011T001851_018758_01FA8C_8F54.zip\n",
      "13: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20171116T001824_20171116T001851_019283_020AB6_D178.zip\n",
      "14: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20171128T001824_20171128T001851_019458_021038_E706.zip\n",
      "15: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20171210T001823_20171210T001850_019633_0215B1_65DC.zip\n",
      "16: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20171222T001823_20171222T001850_019808_021B17_3485.zip\n",
      "17: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20180115T001822_20180115T001849_020158_022621_B3FE.zip\n",
      "18: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20180127T001822_20180127T001849_020333_022BAC_9CBB.zip\n",
      "19: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20180208T001821_20180208T001848_020508_023144_A39F.zip\n",
      "20: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20180220T001821_20180220T001848_020683_0236D8_9211.zip\n",
      "21: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20180328T001822_20180328T001849_021208_024782_46FD.zip\n",
      "\n",
      "Selected Master: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20170402T001815_20170402T001842_015958_01A507_82BB.zip\n",
      "Selected Slave: /mnt/d/SabineRS/Sentinel-1/0_initial/S1A_IW_SLC__1SDV_20170414T001816_20170414T001843_016133_01AA58_ED18.zip\n"
     ]
    }
   ],
   "source": [
    "# List all Sentinel-1 SLC files\n",
    "slc_files = sorted([os.path.join(INPUT_DIR, f) for f in os.listdir(INPUT_DIR) if f.endswith(\".zip\")])\n",
    "print(\"Available Sentinel-1 SLC Files:\")\n",
    "for i, file in enumerate(slc_files):\n",
    "    print(f\"{i + 1}: {file}\")\n",
    "\n",
    "# Select SLC pairs (e.g., manually choose indices for master and slave)\n",
    "master_index = 0  # Update this to the index of the desired master file\n",
    "slave_index = 1   # Update this to the index of the desired slave file\n",
    "\n",
    "master_file = slc_files[master_index]\n",
    "slave_file = slc_files[slave_index]\n",
    "\n",
    "print(f\"\\nSelected Master: {master_file}\")\n",
    "print(f\"Selected Slave: {slave_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Form triplet dictionaries needed for non-zero closure phase InSAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_dict, example_triplet = get_triplets(sorted([os.path.join(INPUT_DIR, f) for f in os.listdir(INPUT_DIR) if f.endswith(\".zip\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TOPSAR-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command executed successfully!\n",
      "Command executed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Example TOPSAR-Split cell, use this to build more cells for the other steps needed\n",
    "# may make two notebooks; one for interferograms and the other for the custom backscatter products\n",
    "os.chdir('/mnt/d')\n",
    "os.makedirs(os.path.join(os.getcwd(), 'SabineRS/Sentinel-1/1_split'), exist_ok=True)\n",
    "\n",
    "subswath = 'IW3'\n",
    "polarization = 'VV,VH'\n",
    "\n",
    "for i, slc in enumerate(example_triplet[0]):\n",
    "    if i == 0:\n",
    "        split_file = '/SabineRS/Sentinel-1/1_split/m_testIW3.dim'\n",
    "    else:\n",
    "        split_file = '/SabineRS/Sentinel-1/1_split/s_testIW3.dim'\n",
    "    \n",
    "    split_SLC(master_file, subswath, polarization, split_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Apply Orbit Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command executed successfully!\n",
      "Command executed successfully!\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(os.path.join(os.getcwd(), 'SabineRS/Sentinel-1/2_orbit'), exist_ok=True)\n",
    "\n",
    "orbit = 'Sentinel Precise (Auto Download)'\n",
    "\n",
    "for i , file in enumerate(['/SabineRS/Sentinel-1/1_split/m_testIW3.dim', '/SabineRS/Sentinel-1/1_split/s_testIW3.dim']):\n",
    "    if i == 0:\n",
    "        orbit_file = '/SabineRS/Sentinel-1/2_orbit/m_testIW3.dim'\n",
    "    else:\n",
    "        orbit_file = '/SabineRS/Sentinel-1/2_orbit/s_testIW3.dim'\n",
    "\n",
    "    orbit_SLC(split_file, orbit, orbit_file)\n",
    "\n",
    "\n",
    "shutil.rmtree(os.path.join(os.getcwd(), 'SabineRS/Sentinel-1/1_split'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Back-Geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode_SLC(sourcefile, orbittype, outfile):\n",
    "    geocode_cmd = [\n",
    "        GPT_PATH,\n",
    "        \"Apply-Orbit-File\", # operation name\n",
    "        f\"-Ssource={sourcefile}\",\n",
    "        f\"-PorbitType={orbittype}\",\n",
    "        \"-t\", outfile, # keep separate, output file location\n",
    "        \"-q\", str(MAX_CORES),\n",
    "        \"-c\", MAX_MEM\n",
    "    ]\n",
    "\n",
    "    # Run the command\n",
    "    try:\n",
    "        result = subprocess.run(geocode_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(\"Command executed successfully!\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Command failed with error code {e.returncode}\")\n",
    "        print(f\"Error message: {e.stderr}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(os.getcwd(), 'SabineRS/Sentinel-1/3_backgeocode'), exist_ok=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ESD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Interferogram formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. TOPSAR-Deburst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Topographic Phase Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Goldstein Phase Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. SNAPHU Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
