{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will serve as the interactive notebook for leveraging the SNAP Graph Processing Tool using the subprocess library. \n",
    "- Allows for easier bulk processing of many interferograms, which is needed for non-zero closure phase correction (InSAR triplets)\n",
    "- Allows for easier bulk processing of custom GRD-like products (will produce both calibrate and uncalibrated backscatter data for classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os\n",
    "from time import perf_counter\n",
    "import subprocess\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_dir(cwd, project_name):\n",
    "    work_dir = os.path.join(cwd, project_name)\n",
    "    os.makedirs(work_dir, exist_ok=True)\n",
    "    data_dir = os.path.join(work_dir,'0_initial')\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    return work_dir, data_dir\n",
    "\n",
    "def get_triplets(slc_list):\n",
    "    \"\"\"\n",
    "    this program will generate a dictionary with keys triplet_n, where n is the triplet stack\n",
    "    each triplet_n contains 4 sets. Each set contains (path/to/ref.xml, path/to/sec.xml)\n",
    "    \n",
    "    slc_zips = list of directories containing the topsApp, reference, and secondary .xml files    \n",
    "    created an returned using the project_dir fucntion\n",
    "    \"\"\"\n",
    "    \n",
    "    triplet_dict={}\n",
    "    \n",
    "    for i in range(len(slc_list) - 2):\n",
    "        triplet_dict[f'triplet_{i+1}'] = ((slc_list[i],slc_list[i+1]), (slc_list[i+1],slc_list[i+2]), (slc_list[i+2], slc_list[i]))\n",
    "        if i == 0:\n",
    "            test_triplet = ((slc_list[i],slc_list[i+1]), (slc_list[i+1],slc_list[i+2]), (slc_list[i+2], slc_list[i]), (slc_list[i], slc_list[i+2]))\n",
    "        else:\n",
    "            continue\n",
    "    return triplet_dict, test_triplet\n",
    "\n",
    "def get_sourcebands_tiepointgrids(phasefilter_data_path, polarisation):\n",
    "    individual_date = os.listdir(phasefilter_data_path)[0][11:-4]\n",
    "\n",
    "    sourcebands = f\"i_ifg_{polarisation}_{individual_date},q_ifg_{polarisation}_{individual_date},Intensity_ifg_{polarisation}_{individual_date}_db,Phase_ifg_{polarisation}_{individual_date},coh_{subswath}_{polarisation}_{individual_date},elevation\"\n",
    "    \n",
    "    tiepointgrids = [f[:-4] for f in os.listdir(os.path.join(phasefilter_file[:-4]+'.data', 'tie_point_grids')) if f.endswith('.img')]\n",
    "    tiepointgrids_formatted  = ','.join(tiepointgrids)\n",
    "\n",
    "    return sourcebands, tiepointgrids_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNAP GPT subprocess functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_SLC(sourcefile, subswath, polarization, outfile):\n",
    "    split_cmd = [\n",
    "        GPT_PATH,\n",
    "        \"TOPSAR-Split\", # operation name\n",
    "        f\"-Ssource={sourcefile[6:]}\", # SLC file\n",
    "        f\"-Psubswath={subswath}\", #1, 2, 3\n",
    "        f\"-PselectedPolarisations={polarization}\", # bands being processed\n",
    "        \"-t\", outfile, # keep separate, output file location\n",
    "        \"-q\", str(MAX_CORES),\n",
    "        \"-c\", MAX_MEM\n",
    "    ]\n",
    "\n",
    "    # Run the command\n",
    "    try:\n",
    "        result = subprocess.run(split_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(\"Command executed successfully!\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Command failed with error code {e.returncode}\")\n",
    "        print(f\"Error message: {e.stderr}\")\n",
    "\n",
    "def orbit_SLC(sourcefile, orbittype, outfile):\n",
    "    orbit_cmd = [\n",
    "        GPT_PATH,\n",
    "        \"Apply-Orbit-File\", # operation name\n",
    "        f\"-Ssource={sourcefile}\",\n",
    "        f\"-PorbitType={orbittype}\",\n",
    "        \"-t\", outfile, # keep separate, output file location\n",
    "        \"-q\", str(MAX_CORES),\n",
    "        \"-c\", MAX_MEM\n",
    "    ]\n",
    "\n",
    "    # Run the command\n",
    "    try:\n",
    "        result = subprocess.run(orbit_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(\"Command executed successfully!\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Command failed with error code {e.returncode}\")\n",
    "        print(f\"Error message: {e.stderr}\")\n",
    "\n",
    "def geocode_SLC(m_file, s_file, demname, resamplemethod, reramp, maskelev, derampdemod, offset, resampletype, outfile):\n",
    "    geocode_cmd = [\n",
    "        GPT_PATH,\n",
    "        \"Back-Geocoding\", # operation name\n",
    "        f\"-Ssource1={m_file}\",\n",
    "        f\"-Ssource2={s_file}\",\n",
    "        f\"-PdemName={demname}\",\n",
    "        f\"-PdemResamplingMethod={resamplemethod}\",\n",
    "        f\"-PdisableReramp={reramp}\",\n",
    "        f\"-PmaskOutAreaWithoutElevation={maskelev}\",\n",
    "        f\"-PoutputDerampDemodPhase={derampdemod}\",\n",
    "        f\"-PoutputRangeAzimuthOffset={offset}\",\n",
    "        f\"-PresamplingType={resampletype}\",\n",
    "        \"-t\", outfile, # keep separate, output file location\n",
    "        \"-q\", str(MAX_CORES),\n",
    "        \"-c\", MAX_MEM\n",
    "    ]\n",
    "\n",
    "    # Run the command\n",
    "    try:\n",
    "        result = subprocess.run(geocode_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(\"Command executed successfully!\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Command failed with error code {e.returncode}\")\n",
    "        print(f\"Error message: {e.stderr}\")\n",
    "\n",
    "def esd_SLC(source_file, cohthresh, writetgt, estimator, winaccazimuth, winaccrange, winheight, winoversampling, winwidth, integrationmethod, maxtempbaseline, blocksperlap, tempbaselinetype, usrazimuthshift, ovrazimuthshift, usrrangeshift, ovrrangeshift, shiftweightfunction, xcorrthersh, outfile):\n",
    "    esd_cmd = [\n",
    "        GPT_PATH,\n",
    "        \"Enhanced-Spectral-Diversity\", # operation name\n",
    "        f\"-Ssource={source_file}\",\n",
    "        f\"-PcohThreshold={cohthresh}\",\n",
    "        f\"-PdoNotWriteTargetBands={writetgt}\",\n",
    "        f\"-PesdEstimator={estimator}\",\n",
    "        f\"-PfineWinAccAzimuth={winaccazimuth}\",\n",
    "        f\"-PfineWinAccRange={winaccrange}\",\n",
    "        f\"-PfineWinHeightStr={winheight}\",\n",
    "        f\"-PfineWinOversampling={winoversampling}\",\n",
    "        f\"-PfineWinWidthStr={winwidth}\",\n",
    "        f\"-PintegrationMethod={integrationmethod}\",\n",
    "        f\"-PmaxTemporalBaseline={maxtempbaseline}\",\n",
    "        f\"-PnumBlocksPerOverlap={blocksperlap}\",\n",
    "        f\"-PoverallAzimuthShift={ovrazimuthshift}\",\n",
    "        f\"-PoverallRangeShift={ovrrangeshift}\",\n",
    "        f\"-PtemporalBaselineType={tempbaselinetype}\",\n",
    "        f\"-PuseSuppliedAzimuthShift={usrazimuthshift}\",\n",
    "        f\"-PuseSuppliedRangeShift={usrrangeshift}\",\n",
    "        f\"-PweightFunc={shiftweightfunction}\",\n",
    "        f\"-PxCorrThreshold={xcorrthersh}\",\n",
    "        \"-t\", outfile, # keep separate, output file location\n",
    "        \"-q\", str(MAX_CORES),\n",
    "        \"-c\", MAX_MEM\n",
    "    ]\n",
    "\n",
    "    # Run the command\n",
    "    try:\n",
    "        result = subprocess.run(esd_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(\"Command executed successfully!\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Command failed with error code {e.returncode}\")\n",
    "        print(f\"Error message: {e.stderr}\")\n",
    "\n",
    "def ifgram_SLC(source_file, azicohwin, rgcohwin, demname, eDEMEGM, eDEMfile, eDEMnoval, includecohband, orbitdegree, outputelevationband, outputFEphase, outputLatLon, outputTopophase, cohsquarepixels, FEphasepoints, FEphasepoly, removeFEphase, removeTopophase, demsimulaton, outfile):\n",
    "    if eDEMfile == 'None':\n",
    "        ifgram_cmd = [\n",
    "            GPT_PATH,\n",
    "            \"Interferogram\", # operation name\n",
    "            f\"-SsourceProduct={source_file}\",\n",
    "            f\"-PcohWinAz={azicohwin}\",\n",
    "            f\"-PcohWinRg={rgcohwin}\",\n",
    "            f\"-PdemName={demname}\",\n",
    "            f\"-PexternalDEMApplyEGM={eDEMEGM}\",\n",
    "            f\"-PincludeCoherence={includecohband}\",\n",
    "            f\"-PorbitDegree={orbitdegree}\",\n",
    "            f\"-PoutputElevation={outputelevationband}\",\n",
    "            f\"-PoutputFlatEarthPhase={outputFEphase}\",\n",
    "            f\"-PoutputLatLon={outputLatLon}\",\n",
    "            f\"-PoutputTopoPhase={outputTopophase}\",\n",
    "            f\"-PsquarePixel={cohsquarepixels}\",\n",
    "            f\"-PsrpNumberPoints={FEphasepoints}\",\n",
    "            f\"-PsrpPolynomialDegree={FEphasepoly}\",\n",
    "            f\"-PsubtractFlatEarthPhase={removeFEphase}\",\n",
    "            f\"-PsubtractTopographicPhase={removeTopophase}\",\n",
    "            f\"-PtileExtensionPercent={demsimulaton}\",\n",
    "            \"-t\", outfile, # keep separate, output file location\n",
    "            \"-q\", str(MAX_CORES),\n",
    "            \"-c\", MAX_MEM\n",
    "        ]\n",
    "    else:\n",
    "        ifgram_cmd = [\n",
    "            GPT_PATH,\n",
    "            \"Interferogram\", # operation name\n",
    "            f\"-SsourceProduct={source_file}\",\n",
    "            f\"-PcohWinAz={azicohwin}\",\n",
    "            f\"-PcohWinRg={rgcohwin}\",\n",
    "            f\"-PdemName={demname}\",\n",
    "            f\"-PexternalDEMApplyEGM={eDEMEGM}\",\n",
    "            f\"-PexternalDEMFile={eDEMfile}\",\n",
    "            f\"-PeternalDEMNoDataValue={eDEMnoval}\",\n",
    "            f\"-PincludeCoherence={includecohband}\",\n",
    "            f\"-PorbitDegree={orbitdegree}\",\n",
    "            f\"-PoutputElevation={outputelevationband}\",\n",
    "            f\"-PoutputFlatEarthPhase={outputFEphase}\",\n",
    "            f\"-PoutputLatLon={outputLatLon}\",\n",
    "            f\"-PoutputTopoPhase={outputTopophase}\",\n",
    "            f\"-PsquarePixel={cohsquarepixels}\",\n",
    "            f\"-PsrpNumberPoints={FEphasepoints}\",\n",
    "            f\"-PsrpPolynomialDegree={FEphasepoly}\",\n",
    "            f\"-PsubtractFlatEarthPhase={removeFEphase}\",\n",
    "            f\"-PsubtractTopographicPhase={removeTopophase}\",\n",
    "            f\"-PtileExtensionPercent={demsimulaton}\",\n",
    "            \"-t\", outfile, # keep separate, output file location\n",
    "            \"-q\", str(MAX_CORES),\n",
    "            \"-c\", MAX_MEM\n",
    "        ]\n",
    "\n",
    "    # Run the command\n",
    "    try:\n",
    "        result = subprocess.run(ifgram_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(\"Command executed successfully!\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Command failed with error code {e.returncode}\")\n",
    "        print(f\"Error message: {e.stderr}\")\n",
    "\n",
    "def deburst_SLC(source_file, bands, outfile):\n",
    "    deburst_cmd = [\n",
    "        GPT_PATH,\n",
    "        \"TOPSAR-Deburst\", # operation name\n",
    "        f\"-Ssource={source_file}\",\n",
    "        f\"-PselectedPolarisations={bands}\",\n",
    "        \"-t\", outfile, # keep separate, output file location\n",
    "        \"-q\", str(MAX_CORES),\n",
    "        \"-c\", MAX_MEM\n",
    "    ]\n",
    "\n",
    "    # Run the command\n",
    "    try:\n",
    "        result = subprocess.run(deburst_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(\"Command executed successfully!\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Command failed with error code {e.returncode}\")\n",
    "        print(f\"Error message: {e.stderr}\")\n",
    "\n",
    "def Tphase_SLC(source_file, demname, eDEMfile, eDEMnoval, orbitdegree, outputelevationband, outputLatLon, outputTopophase, demsimulaton, outfile):\n",
    "    if eDEMfile == 'None':\n",
    "        Tphase_cmd = [\n",
    "            GPT_PATH,\n",
    "            \"TopoPhaseRemoval\", # operation name\n",
    "            f\"-SsourceProduct={source_file}\",\n",
    "            f\"-PdemName={demname}\",\n",
    "            f\"-PorbitDegree={orbitdegree}\",\n",
    "            f\"-PoutputElevationBand={outputelevationband}\",\n",
    "            f\"-PoutputLatLonBands={outputLatLon}\",\n",
    "            f\"-PoutputTopoPhaseBand={outputTopophase}\",\n",
    "            f\"-PtileExtensionPercent={demsimulaton}\",\n",
    "            \"-t\", outfile, # keep separate, output file location\n",
    "            \"-q\", str(MAX_CORES),\n",
    "            \"-c\", MAX_MEM\n",
    "        ]\n",
    "    else:\n",
    "        Tphase_cmd = [\n",
    "            GPT_PATH,\n",
    "            \"TopoPhaseRemoval\", # operation name\n",
    "            f\"-SsourceProduct={source_file}\",\n",
    "            f\"-PdemName={demname}\",\n",
    "            f\"-PexternalDEMFile={eDEMfile}\",\n",
    "            f\"-PeternalDEMNoDataValue={eDEMnoval}\",\n",
    "            f\"-PorbitDegree={orbitdegree}\",\n",
    "            f\"-PoutputElevationBand={outputelevationband}\",\n",
    "            f\"-PoutputLatLonBands={outputLatLon}\",\n",
    "            f\"-PoutputTopoPhaseBand={outputTopophase}\",\n",
    "            f\"-PtileExtensionPercent={demsimulaton}\",\n",
    "            \"-t\", outfile, # keep separate, output file location\n",
    "            \"-q\", str(MAX_CORES),\n",
    "            \"-c\", MAX_MEM\n",
    "        ]\n",
    "\n",
    "    # Run the command\n",
    "    try:\n",
    "        result = subprocess.run(Tphase_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(\"Command executed successfully!\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Command failed with error code {e.returncode}\")\n",
    "        print(f\"Error message: {e.stderr}\")\n",
    "\n",
    "def phasefilter_SLC(source_file, alpha, coherence_threshold, FFTsize, use_coherence_mask, filter_window_size, outfile):\n",
    "    phasefilter_cmd = [\n",
    "        GPT_PATH,\n",
    "        \"GoldsteinPhaseFiltering\", # operation name\n",
    "        f\"-SsourceProduct={source_file}\",\n",
    "        f\"-Palpha={alpha}\",\n",
    "        f\"-PcoherenceThreshold={coherence_threshold}\",\n",
    "        f\"-PFFTSizeString={FFTsize}\",\n",
    "        f\"-PuseCoherenceMask={use_coherence_mask}\",\n",
    "        f\"-PwindowSizeString={filter_window_size}\",\n",
    "        \"-t\", outfile, # keep separate, output file location\n",
    "        \"-q\", str(MAX_CORES),\n",
    "        \"-c\", MAX_MEM\n",
    "    ]\n",
    "\n",
    "    # Run the command\n",
    "    try:\n",
    "        result = subprocess.run(phasefilter_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(\"Command executed successfully!\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Command failed with error code {e.returncode}\")\n",
    "        print(f\"Error message: {e.stderr}\")\n",
    "\n",
    "def subset_SLC(source_file, copy_metadata, use_full_swath, wkt_region, reference_band, sourcebands, X_subsample, Y_subsample, tiepointgrids, outfile):\n",
    "    subset_cmd = [\n",
    "        GPT_PATH,\n",
    "        \"Subset\", # operation name\n",
    "        f\"-Ssource={source_file}\",\n",
    "        f\"-PcopyMetadata={copy_metadata}\",\n",
    "        f\"-PfullSwath={use_full_swath}\",\n",
    "        f\"-PgeoRegion={wkt_region}\",\n",
    "        f\"-PreferenceBand={reference_band}\",\n",
    "        f\"-PsourceBands={sourcebands}\",\n",
    "        f\"-PsubSamplingX={X_subsample}\",\n",
    "        f\"-PsubSamplingY={Y_subsample}\",\n",
    "        f\"-PtiePointGrids={tiepointgrids}\",\n",
    "        \"-t\", outfile, # keep separate, output file location\n",
    "        \"-q\", str(MAX_CORES),\n",
    "        \"-c\", MAX_MEM\n",
    "    ]\n",
    "\n",
    "    # Run the command\n",
    "    try:\n",
    "        result = subprocess.run(subset_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(\"Command executed successfully!\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Command failed with error code {e.returncode}\")\n",
    "        print(f\"Error message: {e.stderr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps?\n",
    "\n",
    "1. split, orbit, coreg, ESD\n",
    "2. interferogram (topo phase removal, deburst, filter, subset)\n",
    "4. snaphu export unwrap import\n",
    "5. geocode, displacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish needed paths for notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to where the data is stored, this was established in \"get_slc.ipynb\"\n",
    "# directory to where 'ASCENDING' and 'DESCENDING' are located so we can process both tracks\n",
    "# data_dir = '/mnt/d/SabineRS/Sentinel-1'   #WSL\n",
    "data_dir = '/home/wcc/Desktop/SabineRS/Sentinel-1'  #Linux\n",
    "\n",
    "asc_dir = os.path.join(data_dir, 'ASCENDING')\n",
    "des_dir = os.path.join(data_dir, 'DESCENDING')\n",
    "\n",
    "asc_ini = os.path.join(asc_dir, '0_initial')\n",
    "des_ini = os.path.join(des_dir, '0_initial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine the tracks and frames that are stored in the asc_dir and des_dir\n",
    "- Will use this to form interferograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of ascending track initial orbits and frames found for aoi\n",
    "display([x[0] for x in os.walk(asc_ini)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of ascending track initial orbits and frames found for aoi\n",
    "display([x[0] for x in os.walk(des_ini)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose which track-orbit-frame set you want to process based on above outputs\n",
    "- will work on this later to automatically check number of trackframe pairs, report the number of epochs in each, and then automatically process in order of number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example, if I want to process ascending track 136 frame 93\n",
    "trackframe = '136/93'\n",
    "INPUT_DIR = os.path.join(asc_ini, trackframe)  # Directory containing Sentinel-1 SLCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish pre-processing compute parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get your path to the SNAP GPT install\n",
    "# typically found in your 'esa-snap' install file in the 'bin' subdirectory\n",
    "# Linux example: ~/esa-snap/bin/gpt\n",
    "# WSL example: /mnt/c/Program Files/bin/gpt\n",
    "\n",
    "# Define paths and parameters\n",
    "# GPT_PATH = '/mnt/c/Program Files/esa-snap/bin/gpt.exe'  # Path to SNAP's gpt executable, WSL example\n",
    "GPT_PATH = '/home/wcc/esa-snap/bin/gpt'\n",
    "\n",
    "MAX_CORES = 20  # Adjust based on system capacity\n",
    "MAX_MEM = '84G'  # Maximum memory for SNAP, can be K, M, G\n",
    "TILE_SIZE = 4096  # Tile size for SNAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find all SLC zips for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all Sentinel-1 SLC files\n",
    "slc_files = sorted([os.path.join(INPUT_DIR, f) for f in os.listdir(INPUT_DIR) if f.endswith(\".zip\")])\n",
    "print(\"Available Sentinel-1 SLC Files:\")\n",
    "for i, file in enumerate(slc_files):\n",
    "    print(f\"{i + 1}: {file}\")\n",
    "\n",
    "# Select SLC pairs (e.g., manually choose indices for reference and secondary)\n",
    "reference_index = 0  # Update this to the index of the desired reference file\n",
    "secondary_index = 1   # Update this to the index of the desired secondary file\n",
    "\n",
    "reference_file = slc_files[reference_index]\n",
    "secondary_file = slc_files[secondary_index]\n",
    "\n",
    "if_id = f\"{reference_file[-38:-30]}_{secondary_file[-38:-30]}\"\n",
    "\n",
    "print(f\"\\nSelected reference: {reference_file}\")\n",
    "print(f\"Selected secondary: {secondary_file}\")\n",
    "print(f\"Interferogram ID: {if_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Form triplet dictionaries needed for non-zero closure phase InSAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_dict, example_triplet = get_triplets(sorted([os.path.join(INPUT_DIR, f) for f in os.listdir(INPUT_DIR) if f.endswith(\".zip\")]))\n",
    "example_triplet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing steps below come from the MintPy documentation\n",
    "- https://github.com/insarlab/MintPy/wiki/SNAP-input-data/94265da3b2e6ae4ec420e7a8d6f5e2e937616f85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('/mnt/d')  #WSL\n",
    "os.chdir('/home')   #Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TOPSAR-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example TOPSAR-Split cell, use this to build more cells for the other steps needed\n",
    "# may make two notebooks; one for interferograms and the other for the custom backscatter products\n",
    "\n",
    "split_dir = os.path.join(asc_dir, f'1_split/{trackframe}')\n",
    "os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "subswath = 'IW3'    # 'IW1', 'IW2' or 'IW3'\n",
    "\n",
    "for i, slc in enumerate(example_triplet[0]):\n",
    "    if i == 0:\n",
    "        split_file = os.path.join(split_dir, 'm_testIW3.dim')\n",
    "    else:\n",
    "        split_file = os.path.join(split_dir, 's_testIW3.dim')\n",
    "    \n",
    "    split_SLC(slc, subswath, 'VV,VH', split_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Apply Orbit Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbit_dir = os.path.join(asc_dir, f'2_orbit/{trackframe}')\n",
    "os.makedirs(orbit_dir, exist_ok=True)\n",
    "\n",
    "orbit = 'Sentinel Precise (Auto Download)'  # can change this, refer to the GPT Apply-Orbit-File -h command\n",
    "\n",
    "for i , file in enumerate([f for f in os.listdir(split_dir) if f.endswith('.dim')]):\n",
    "    if i == 0:\n",
    "        orbit_file = os.path.join(orbit_dir, 'm_testIW3.dim')\n",
    "    else:\n",
    "        orbit_file = os.path.join(orbit_dir, 's_testIW3.dim')\n",
    "\n",
    "    orbit_SLC(split_file, orbit, orbit_file)\n",
    "\n",
    "\n",
    "shutil.rmtree(os.path.join(asc_dir, '1_split')) # removes previous split data, saving storage on your computer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Back-Geocoding\n",
    "- Pass two -Ssource, m first then s\n",
    "\n",
    "One can pass an external DEM for geocoding, but higher or finer resolution DEMs will not make a difference during geocoding. The external DEM will have an effect during terrain correction steps. Because of this, steps to include the external DEM will only be addressed during terrain correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocode_dir = os.path.join(asc_dir, f'3_geocode/{trackframe}')\n",
    "os.makedirs(geocode_dir, exist_ok=True)\n",
    "\n",
    "geocode_file = os.path.join(geocode_dir, 'testIW3.dim')\n",
    "\n",
    "geocode_SLC([os.path.join(orbit_dir,f) for f in os.listdir(orbit_dir) if f.endswith('.dim')][1],\n",
    "            [os.path.join(orbit_dir,f) for f in os.listdir(orbit_dir) if f.endswith('.dim')][0],\n",
    "            'Copernicus 30m Global DEM',\n",
    "            'CUBIC_CONVOLUTION',    # BICUBIC_INTERPOLATION default; BILINEAR_INTERPOLATION, NEAREST_NEIGHBOR are among others \n",
    "            False,                  # boolean, default is False\n",
    "            True,                   # boolean, default is True\n",
    "            False,                  # boolean, default is False\n",
    "            False,                  # boolean, default is False\n",
    "            'CUBIC_CONVOLUTION',    # BISINC_5_POINT_INTERPOLATION defult; BILINEAR_INTERPOLATION, NEAREST_NEIGHBOR are among others\n",
    "            geocode_file\n",
    "            )\n",
    "\n",
    "shutil.rmtree(os.path.join(asc_dir, '2_orbit')) # removes previous orbit-applied data, saving storage on your computer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ESD\n",
    "- only need this if you have multiple bursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esd_dir = os.path.join(asc_dir, f'4_esd/{trackframe}')\n",
    "os.makedirs(esd_dir, exist_ok=True)\n",
    "\n",
    "esd_file = os.path.join(esd_dir, 'testIW3.dim')\n",
    "\n",
    "esd_SLC(geocode_file, \n",
    "        0.2,                    # double, (0,1]\n",
    "        False,                  # boolean, False is default\n",
    "        'Periodogram',          # 'Periodogram' default, 'Average' is other choice\n",
    "        '32',                   # string, '16' default, options include '2', '4', '8', '16', '32', '64'\n",
    "        '32',                   # string, '16' default, options include '2', '4', '8', '16', '32', '64'\n",
    "        '512',                  # string, '512' default, options include '32', '64', '128', '256', '512', '1024', '2048'\n",
    "        '128',                  # string, '128' default, options include '32', '64', '128', '256'\n",
    "        '512',                  # string, '512' default, options include '32', '64', '128', '256', '512', '1024', '2048'\n",
    "        'L1 and L2',            # 'L1 and L2' default, 'L1' and 'L2' are also options\n",
    "        0,                      # integer, default 4, <1 generates network with all possible pairs\n",
    "        10,                     # integer, defaults is 10, [1, 20]\n",
    "        'Number of images',     # 'Number of images' default, can also be 'Number of days'\n",
    "        False,                  # boolean, False is default. If True need to adjust user_azimuth_shift\n",
    "        0.0,                    # double, defult is 0.0. not used if user_user_azimuth_shift=False\n",
    "        False,                  # boolean, False is default. If True need to adjust user_range_shift\n",
    "        0.0,                    # double, defult is 0.0. not used if user_user_range_shift=False\n",
    "        'Inv Quadratic',        # 'Inv Quadratic' default, other options are 'None', 'Linear', 'Quadratic'\n",
    "        0.1,                    # double, (0, *)\n",
    "        esd_file)\n",
    "\n",
    "shutil.rmtree(os.path.join(asc_dir, '3_geocode')) #removes previous back-geocoded data, saving storage on your computer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Interferogram formation\n",
    "- This (or later in Topo Phase Removal Step) is where an external DEM can be used for more accurate results\n",
    "- Keep in mind, Sentinel-1 SLC pixel resolutions are 2.7 to 3.5 m in range and 22 m in azimuth when choosing external DEM\n",
    "- EXTERNAL DEM MUST BE IN EPSG:4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_dir = os.path.join(asc_dir, f'5_interferogram/{trackframe}')\n",
    "os.makedirs(if_dir, exist_ok=True)\n",
    "\n",
    "if_file = os.path.join(if_dir, 'testIW3.dim')\n",
    "\n",
    "ifgram_SLC(esd_file, \n",
    "           10,                      # integer, default is 10. ASIMUTH 22m/pixel\n",
    "           10,                      # integer, default is 10. RANGE 2.7 to 3.5m/pixel\n",
    "           'Copernicus 30m Global DEM',                 # string, DEM name in ESA SNAP\n",
    "           False,                        # boolean, True is default \n",
    "           'None',                    # path to external DEM used for interferogram\n",
    "           0,                   # double, no data value from external DEM, default is 0\n",
    "           True,              # boolean, True is default, NEEDED FOR MINTPY\n",
    "           3,                 # integer, 3 is default, can be 1, 2, 3, 4, or 5\n",
    "           True,         # boolean, default is False, NEEDED FOR MINTPY\n",
    "           False,               # boolean, default is False\n",
    "           False,                # boolean, default is False\n",
    "           False,             # boolean, Default is False, accomplished later in workflow\n",
    "           True,             # boolean, default is True, used to make square windows/tiles for coherence estimation. if False, can change first two integers, otherwise can only change coherence window\n",
    "           601,               # integer, default is 501, number of points used for flat earth polynomial estimation, typically not used\n",
    "           6,                 # integer, default is 5, [1, 8]\n",
    "           True,               # boolean, default is True,\n",
    "           False,             # boolean, default is False. Removes topographic phase delay, will be done in a later step\n",
    "           '100',                # string of an integer, default is 100\n",
    "           if_file\n",
    "           )\n",
    "\n",
    "shutil.rmtree(os.path.join(asc_dir, '4_esd')) #removes previous esd data, saving storage on your computer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. TOPSAR-Deburst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deburst_dir = os.path.join(asc_dir, f'6_deburst/{trackframe}')\n",
    "os.makedirs(deburst_dir, exist_ok=True)\n",
    "\n",
    "deburst_file = os.path.join(deburst_dir, 'testIW3.dim')\n",
    "\n",
    "deburst_SLC(if_file, \n",
    "            'VV,VH', \n",
    "            deburst_file\n",
    "            )\n",
    "\n",
    "# shutil.rmtree(os.path.join(asc_dir, '5_interferogram')) #removes initial interferogram data, saving storage on your computer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Topographic Phase Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tphase_dir = os.path.join(asc_dir, f'7_topo/{trackframe}')\n",
    "os.makedirs(Tphase_dir, exist_ok=True)\n",
    "\n",
    "topo_file = os.path.join(Tphase_dir, 'testIW3.dim')\n",
    "\n",
    "Tphase_SLC(source_file= deburst_file,\n",
    "           demname= 'Copernicus 30m Global DEM',\n",
    "           eDEMfile= 'None',\n",
    "           eDEMnoval= 0,\n",
    "           orbitdegree= 4,\n",
    "           outputelevationband= True,   # boolean, default is False\n",
    "           outputLatLon= False,     #boolean, default is False\n",
    "           outputTopophase= False,  # boolean, default is False\n",
    "           demsimulaton= '100',   # string of an integer\n",
    "           outfile= topo_file\n",
    "           )\n",
    "\n",
    "# shutil.rmtree(os.path.join(asc_dir, '6_deburst')) #removes initial interferogram data, saving storage on your computer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Goldstein Phase Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phasefilt_dir = os.path.join(asc_dir, f'8_phasefilt/{trackframe}')\n",
    "os.makedirs(phasefilt_dir, exist_ok=True)\n",
    "\n",
    "phasefilter_file = os.path.join(phasefilt_dir, 'testIW3.dim')\n",
    "\n",
    "phasefilter_SLC(source_file= topo_file,\n",
    "                alpha= 1.0,                 # double (0, 1], adaptive filter exponent\n",
    "                coherence_threshold= 0.2,   # double, [0,1]\n",
    "                FFTsize= '32',              # string of interger, default is '64', other options are '32', '128', and '256'\n",
    "                use_coherence_mask= False,  # boolean, default is False, coherence masking\n",
    "                filter_window_size= '3',    # string of integer, default is '3', other options are '5' and '7'\n",
    "                outfile= phasefilter_file\n",
    "                )\n",
    "\n",
    "# shutil.rmtree(os.path.join(asc_dir, '7_topo')) #removes initial interferogram data, saving storage on your computer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Subset \n",
    "- subset to the aoi of the placements, make sure to include a large enough area where\n",
    "- use geemap to create an aoi in WKT-format for easy subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## interactive map for you to draw a polygon to signify your aoi\n",
    "import geemap\n",
    "## Create a map centered at a specific location\n",
    "m = geemap.Map(center=[20, 0], zoom=2, basemap='HYBRID')\n",
    "\n",
    "## Add drawing tools\n",
    "m.add_draw_control()\n",
    "\n",
    "## Display the map\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get feature you just drew\n",
    "draw_features = m.draw_features[0]\n",
    "\n",
    "# extract the vertices pf the feature\n",
    "vertices = [(coords[0], coords[1]) for i, coords in enumerate(draw_features.getInfo()['geometry']['coordinates'][0])]\n",
    "vertices.reverse()\n",
    "\n",
    "# create POLYGON string to use when searching asf for imagery\n",
    "aoi = \"POLYGON((\" + \", \".join([f'{str(northing)[:-2]} {str(easting)[:-2]}' for northing, easting in vertices[:]]) +\"))\"\n",
    "display(aoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phasefilter_file = f'/home/wcc/Desktop/SabineRS/Sentinel-1/ASCENDING/8_phasefilt/{trackframe}/testIW3.dim'\n",
    "subswath = 'IW3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcebands_formatted, tiepointgrids_formatted = get_sourcebands_tiepointgrids(\n",
    "                                        phasefilter_file[:-4]+'.data',\n",
    "                                        'VV'    # string, options include VV, VH, nad HH depending on sensor\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_dir = os.path.join(asc_dir, f'9_subset/{trackframe}')\n",
    "os.makedirs(subset_dir, exist_ok=True)\n",
    "\n",
    "subset_file = os.path.join(subset_dir, 'testIW3.dim')\n",
    "\n",
    "subset_SLC(source_file= phasefilter_file, \n",
    "           copy_metadata= True,                     # boolean, default is False \n",
    "           use_full_swath= False,                   # boolean, default is False \n",
    "           wkt_region= aoi,                         # aoi you drew earlier, can also use the aoi from 'get_slc.ipynb' \n",
    "           reference_band= 'elevation',          # referance band needed for clipping\n",
    "           sourcebands= sourcebands_formatted,      # target bands being clipped\n",
    "           X_subsample= 1,                          #\n",
    "           Y_subsample= 1,                          #\n",
    "           tiepointgrids= tiepointgrids_formatted, \n",
    "           outfile= subset_file\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Export neeeded SNAPHU bands to .tif for unwrapping\n",
    "- for now gpt SnaphuExport isn't working for some reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([GPT_PATH, 'SnaphuExport', f'-Ssource={subset_file}', f\"-PtargetFolder={snaphuexport_dir}\"], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Export to SNAPHU for unwrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snaphuexport_SLC(source_file, column_overlap, initialization_method, number_of_processors, number_of_columns, number_of_rows, row_overlap, statistal_cost_mode, cost_threshold, target_folder):\n",
    "    snaphuexport_cmd = [\n",
    "        GPT_PATH,\n",
    "        \"SnaphuExport\", # operation name\n",
    "        f\"-Ssource={source_file}\",\n",
    "        f\"-PcolOverlap={column_overlap}\",\n",
    "        f\"-PinitMethod={initialization_method}\",\n",
    "        f\"-PnumberOfProcessors={number_of_processors}\",\n",
    "        f\"-PnumberOfTileCols={number_of_columns}\",\n",
    "        f\"-PnumberOfTileRows={number_of_rows}\",\n",
    "        f\"-ProwOverlap={row_overlap}\",\n",
    "        f\"-PstatCostMode={statistal_cost_mode}\",\n",
    "        f\"-PtargetFolder={target_folder}\",\n",
    "        f\"-PtileCostThreshold={cost_threshold}\"\n",
    "    ]\n",
    "\n",
    "    # Run the command\n",
    "    try:\n",
    "        result = subprocess.run(snaphuexport_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(\"Command executed successfully!\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Command failed with error code {e.returncode}\")\n",
    "        print(f\"Error message: {e.stderr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snaphuexport_dir = os.path.join(asc_dir, f'10_snaphuexport/{trackframe}/{if_id}')\n",
    "os.makedirs(snaphuexport_dir, exist_ok=True)\n",
    "snaphuexport_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "snaphuexport_SLC(source_file= subset_file, \n",
    "                column_overlap= 0,        # integer, column overlap of neighboring tiles in pixels\n",
    "                initialization_method= 'MCF',   # string, valid options are 'MST' and 'MCF' \n",
    "                number_of_processors= 12,    # number of cores to use for exporting\n",
    "                number_of_columns= 10,      # integer, default is 10, number of columns to divide image into for parallel processing\n",
    "                number_of_rows= 10,         # integer, default is 10, number of rows to divide image into for parallel processing\n",
    "                row_overlap= 0,           # integer, row overlap of neighboring tiles in pixels \n",
    "                statistal_cost_mode= 'DEFO',    # string, coherence estimation method window in Azimuth, options include 'DEFO', 'TOPO', 'SMOOTH', and 'NOSTATCOSTS'\n",
    "                cost_threshold= 500,          # integer, cost threshold to determine the size of the coherence estimation window\n",
    "                target_folder= snaphuexport_dir\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
