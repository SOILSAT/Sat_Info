{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will serve as the interactive notebook for leveraging the SNAP Graph Processing Tool using the subprocess library. \n",
    "- Allows for easier bulk processing of many interferograms, which is needed for non-zero closure phase correction (InSAR triplets)\n",
    "- Allows for easier bulk processing of custom GRD-like products (will produce both calibrate and uncalibrated backscatter data for classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os\n",
    "from time import perf_counter\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_dir(cwd, project_name):\n",
    "    work_dir = os.path.join(cwd, project_name)\n",
    "    os.makedirs(work_dir, exist_ok=True)\n",
    "    data_dir = os.path.join(work_dir,'0_initial')\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    return work_dir, data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def bytes2snap(mem_bytes):\n",
    "    \"\"\"Convert memory size in bytes to SNAP-readable format (e.g., MB).\"\"\"\n",
    "    return f\"{int(mem_bytes / (1024 * 1024))}M\"\n",
    "\n",
    "def run_command(command):\n",
    "    \"\"\"Run a shell command and print the output.\"\"\"\n",
    "    try:\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"Command executed successfully: {' '.join(command)}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running command: {e}\")\n",
    "        \n",
    "def process_interferogram_individual(master, slave, output_dir):\n",
    "    \"\"\"Process two SLCs into an interferogram without a graph file.\"\"\"\n",
    "    coregistered_output = os.path.join(output_dir, f\"{os.path.basename(master)}_{os.path.basename(slave)}_coregistered.dim\")\n",
    "    interferogram_output = os.path.join(output_dir, f\"{os.path.basename(master)}_{os.path.basename(slave)}_interferogram.dim\")\n",
    "\n",
    "    # Step 1: Coregistration\n",
    "    coregistration_cmd = [\n",
    "        GPT_PATH,\n",
    "        \"Back-Geocoding\",\n",
    "        \"-q\", str(MAX_CORES),\n",
    "        \"-J-Xms2G\",\n",
    "        f\"-J-Xmx{bytes2snap(MAX_MEM)}\",\n",
    "        f\"-J-Dsnap.jai.defaultTileSize={TILE_SIZE}\",\n",
    "        f\"-J-Dsnap.dataio.reader.tileWidth={TILE_SIZE}\",\n",
    "        f\"-J-Dsnap.dataio.reader.tileHeight={TILE_SIZE}\",\n",
    "        \"-J-Dsnap.jai.prefetchTiles=true\",\n",
    "        f\"-Pmaster={master}\",\n",
    "        f\"-Pslave={slave}\",\n",
    "        f\"-PdemName=SRTM 1Sec HGT\",\n",
    "        f\"-Poutput={coregistered_output}\"  # Fixed '=' syntax\n",
    "    ]\n",
    "    print(f\"Running Coregistration: {master} and {slave}\")\n",
    "    tic = perf_counter()\n",
    "    run_command(coregistration_cmd)\n",
    "    toc = perf_counter()\n",
    "    print(f\"Coregistration completed in {toc - tic:.2f}s: {coregistered_output}\")\n",
    "\n",
    "    # Step 2: Interferogram Formation\n",
    "    interferogram_cmd = [\n",
    "        GPT_PATH,\n",
    "        \"Interferogram\",\n",
    "        \"-q\", str(MAX_CORES),\n",
    "        \"-J-Xms2G\",\n",
    "        f\"-J-Xmx{bytes2snap(MAX_MEM)}\",\n",
    "        f\"-J-Dsnap.jai.defaultTileSize={TILE_SIZE}\",\n",
    "        f\"-J-Dsnap.dataio.reader.tileWidth={TILE_SIZE}\",\n",
    "        f\"-J-Dsnap.dataio.reader.tileHeight={TILE_SIZE}\",\n",
    "        \"-J-Dsnap.jai.prefetchTiles=true\",\n",
    "        f\"-Pinput={coregistered_output}\",\n",
    "        f\"-Poutput={interferogram_output}\"  # Fixed '=' syntax\n",
    "    ]\n",
    "    print(f\"Running Interferogram Formation: {coregistered_output}\")\n",
    "    tic = perf_counter()\n",
    "    run_command(interferogram_cmd)\n",
    "    toc = perf_counter()\n",
    "    print(f\"Interferogram Formation completed in {toc - tic:.2f}s: {interferogram_output}\")\n",
    "\n",
    "    return interferogram_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish needed paths for notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish working directory, where your SLCs were stored\n",
    "# will also be where the processing steps for the interferograms and GRD-like products are stored\n",
    "work_dir, data_dir = project_dir('/mnt/d/SabineRS', 'Sentinel-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get your path to the SNAP GPT install\n",
    "# typically found in your 'esa-snap' install file in the 'bin' subdirectory\n",
    "# Linux example: ~/esa-snap/bin/gpt\n",
    "# WSL example: /mnt/c/Program Files/bin/gpt\n",
    "\n",
    "# Define paths and parameters\n",
    "GPT_PATH = '/mnt/c/Program Files/esa-snap/bin/gpt.exe'  # Path to SNAP's gpt executable\n",
    "INPUT_DIR = data_dir  # Directory containing Sentinel-1 SLCs\n",
    "OUTPUT_DIR = os.path.join(work_dir, 'test')  # Directory to save interferograms\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "MAX_CORES = 12  # Adjust based on system capacity\n",
    "MAX_MEM = 24 * 1024 * 1024 * 1024  # Maximum memory for SNAP in bytes\n",
    "TILE_SIZE = 4096  # Tile size for SNAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all Sentinel-1 SLC files\n",
    "slc_files = sorted([os.path.join(INPUT_DIR, f) for f in os.listdir(INPUT_DIR) if f.endswith(\".zip\")])\n",
    "print(\"Available Sentinel-1 SLC Files:\")\n",
    "for i, file in enumerate(slc_files):\n",
    "    print(f\"{i + 1}: {file}\")\n",
    "\n",
    "# Select SLC pairs (e.g., manually choose indices for master and slave)\n",
    "master_index = 0  # Update this to the index of the desired master file\n",
    "slave_index = 1   # Update this to the index of the desired slave file\n",
    "\n",
    "master_file = slc_files[master_index]\n",
    "slave_file = slc_files[slave_index]\n",
    "\n",
    "print(f\"\\nSelected Master: {master_file}\")\n",
    "print(f\"Selected Slave: {slave_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example TOPSAR-Split cell, use this to build more cells for the other steps needed\n",
    "# may make two notebooks; one for interferograms and the other for the custom backscatter products\n",
    "\n",
    "# Define the command\n",
    "cmd = [\n",
    "    GPT_PATH,\n",
    "    \"TOPSAR-Split\", # operation name\n",
    "    \"-Ssource=D:\\\\SabineRS\\\\Sentinel-1\\\\0_initial\\\\S1A_IW_SLC__1SDV_20170402T001815_20170402T001842_015958_01A507_82BB.zip\", # SLC file\n",
    "    \"-PselectedPolarisations=VV,VH\", # bands being processed\n",
    "    #\"-PwktAoi='POLYGON((NNN NNN, NNN NNN))'\" # AOI\n",
    "    \"-t\", \"D:\\\\split_1.dim\" # keep separate, output file location\n",
    "]\n",
    "\n",
    "# Run the command\n",
    "try:\n",
    "    result = subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    print(\"Command executed successfully!\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Command failed with error code {e.returncode}\")\n",
    "    print(f\"Error message: {e.stderr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
