{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main goal of this notebook is to use the google earth engine to identify and create features that represent the shoreline/waterline of the wetland projects based on different parameters like NDWI, VV and VH backscatter, and individual mutispectral bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## before anything you need to visit the site below and make sure you have a google earth engine account\n",
    "## this is so you can access Sentinel-1 GRD and Sentinel-2 TOA and SR products, as well as other sensor packages and data types\n",
    "\n",
    "## visit the below website below to setup an earth engine account, enable a cloud project, and enable the ee API \n",
    "## https://developers.google.com/earth-engine/cloud/earthengine_cloud_project_setup#get-access-to-earth-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import geemap.colormaps as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## only need to run this once\n",
    "## after authenticating with google earth engine you will only need to initialize each session\n",
    "\n",
    "## https://developers.google.com/earth-engine/guides/auth\n",
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## init ee cloud project you made during initial setup\n",
    "ee.Initialize(project = '') ##enter your project name here as a string to initialize exchanges with ee api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm.plot_colormaps(width=12, height=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some functions for a bit easier mapping\n",
    "super simple for now, might make them better later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to add RGB images to the map.\n",
    "def add_rgb_to_map(image, map_object, coll):\n",
    "\n",
    "    date = ee.Date(image.get('date')).format('YYYY-MM-dd').getInfo()\n",
    "    for band in coll.first().bandNames().getInfo(): ## all images if small enough image collection\n",
    "        map_object.addLayer(image, {'min': 0, 'max': 2000, 'bands': ['B4', 'B3', 'B2']}, f'{date}_rgb')\n",
    "\n",
    "## Function to add spectral indices images to the map.\n",
    "def add_ind_to_map(image, map_object, band):\n",
    "\n",
    "    date = ee.Date(image.get('date')).format('YYYY-MM-dd').getInfo()\n",
    "    if band =='NDWI':\n",
    "        map_object.addLayer(image, {'min': -1, 'max': 1, 'bands': band, 'palette': cm.palettes.ndvi}, f'{date}_{band}')\n",
    "    elif band =='NDVI': \n",
    "        map_object.addLayer(image, {'min': -1, 'max': 1, 'bands': band, 'palette': cm.palettes.ndwi}, f'{date}_{band}')\n",
    "    elif band == 'MSAVI2':\n",
    "        map_object.addLayer(image, {'min': -1, 'max': 1, 'bands': band, 'palette': cm.palettes.RdYlGn}, f'{date}_{band}')\n",
    "\n",
    "\n",
    "## Function to add spectral indices images to the map.\n",
    "def add_sar_to_map(image, map_object, target_band):\n",
    "\n",
    "    date = ee.Date(image.get('date')).format('YYYY-MM-dd').getInfo()\n",
    "    map_object.addLayer(image, {'min': -50, 'max': 1, 'bands': target_band}, f'{date}_{target_band}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functiont to create three important and popular spectral indices\n",
    "## ndvi = Normalized Difference Vegetation Index, good for vegetation health and cover\n",
    "## ndwi = Normalized Difference Water Index, good for identifying water bodies and mositure in surface\n",
    "def s2_10m_target_indices(image):\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    ndwi = image.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
    "    msavi2 = image.expression(\n",
    "        '((2 * NIR + 1) - ((2 * NIR + 1) ** 2 - 8 * (NIR - RED)) ** 0.5) / 2',\n",
    "        {\n",
    "            'NIR': image.select('B8'),\n",
    "            'RED': image.select('B4')\n",
    "        }\n",
    "    ).rename('MSAVI2')\n",
    "    return image.addBands([ndvi, ndwi, msavi2])\n",
    "\n",
    "## collects sentinel-1 GRD (radar, no phase) and Sentinel-2 SR (multispectral, adjusted for top of atmosphere reflectance)\n",
    "def get_sentinel_imagery(aoi, start_date, end_date, s2_cloud_cov, orbit):\n",
    "    ## Sentinel-1 ImageCollection\n",
    "    s1_VV = (ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "               .filterBounds(aoi)\n",
    "               .filterDate(ee.Date(start_date), ee.Date(end_date))\n",
    "               .map(lambda img: img.set('date', ee.Date(img.date()).format('YYYYMMdd')))\n",
    "               .filter(ee.Filter.eq('orbitProperties_pass', orbit))\n",
    "               .select(['VV'])\n",
    "               .sort('date')\n",
    "    )\n",
    "\n",
    "    s1_VH = (ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "               .filterBounds(aoi)\n",
    "               .filterDate(ee.Date(start_date), ee.Date(end_date))\n",
    "               .map(lambda img: img.set('date', ee.Date(img.date()).format('YYYYMMdd')))\n",
    "               .filter(ee.Filter.eq('orbitProperties_pass', orbit))\n",
    "               .select(['VH'])\n",
    "               .sort('date')\n",
    "    )\n",
    "\n",
    "    ## Clip all images in the collection to the AOI\n",
    "    s1_VV = s1_VV.map(lambda img: img.clip(aoi))\n",
    "    s1_VH = s1_VH.map(lambda img:img.clip(aoi))\n",
    "    ## Sentinel-2 Surface Reflectance Harmonized ImageCollection\n",
    "    s2_10m = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "               .filterBounds(aoi)\n",
    "               .filterDate(ee.Date(start_date), ee.Date(end_date))\n",
    "               .map(lambda img: img.set('date', ee.Date(img.date()).format('YYYYMMdd')))\n",
    "               .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', s2_cloud_cov))\n",
    "               .sort('date')\n",
    "               .select(['B2', 'B3', 'B4', 'B8'])\n",
    "    )\n",
    "    ## Clip all images in the collection to the AOI\n",
    "    s2_10m = s2_10m.map(lambda img: img.clip(aoi))\n",
    "    ## Apply indices to the Sentinel-2 images\n",
    "    s2_10m_ndvi = s2_10m.map(s2_10m_target_indices).select(['NDVI'])\n",
    "    s2_10m_ndwi = s2_10m.map(s2_10m_target_indices).select(['NDWI'])\n",
    "    s2_10m_msavi2 = s2_10m.map(s2_10m_target_indices).select(['MSAVI2'])\n",
    "\n",
    "    \n",
    "    return s1_VV, s1_VH, s2_10m, s2_10m_ndvi, s2_10m_ndwi, s2_10m_msavi2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fucntion to get the date of each image in the image collection\n",
    "def get_date(image):\n",
    "    return ee.Feature(None, {'date': image.date().format('YYYY-MM-dd')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_image_to_drive(collection, collname, image, index):\n",
    "    # Define the description for the export, incorporating the index for uniqueness\n",
    "\n",
    "    if collname == 's1_VV':\n",
    "        description = f\"s1_VV_{index}\"\n",
    "    elif collname == 's1_VH':\n",
    "        description = f's1_VH_{index}'\n",
    "    elif collname == 'rgb':\n",
    "        description = f's2_10m_{index}'\n",
    "    elif collname == 'ndvi':\n",
    "        description = f's2_10m_ndvi_{index}'\n",
    "    elif collname == 'ndwi':\n",
    "        description = f's2_10m_ndwi_{index}'\n",
    "    else:\n",
    "        description = f's2_10m_msavi2_{index}'\n",
    "\n",
    "    # Setup the export task\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image=image,\n",
    "        description=description,\n",
    "        region=aoi,  # Make sure the geometry is defined earlier\n",
    "        fileFormat='GeoTIFF',\n",
    "        scale = 10\n",
    "    )\n",
    "    task.start()\n",
    "    print(f'Exporting {description} to Drive...')\n",
    "\n",
    "def export_all_images(collection, collname):\n",
    "    image_list = collection.toList(collection.size())  # Convert ImageCollection to List\n",
    "    num_images = image_list.size().getInfo()  # Get the number of images\n",
    "\n",
    "    if collname[:2] == 's1':\n",
    "        for i, date in enumerate(s1_date_list):\n",
    "            image = ee.Image(image_list.get(i))\n",
    "            export_image_to_drive(collection, collname, image, date[:10])\n",
    "\n",
    "    else:\n",
    "        for i, date in enumerate(s2_date_list):\n",
    "            image = ee.Image(image_list.get(i))\n",
    "            export_image_to_drive(collection, collname, image, date[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get histogram of NDWI for each image\n",
    "def get_histogram(image, scale, bucket_num, band_name):\n",
    "    \"\"\"\n",
    "    Used to create ndwi histograms for the imagery\n",
    "\n",
    "    image = ee.Image\n",
    "        NDWI image to determine the shoreline from\n",
    "    scale = int\n",
    "        scale to estimate the histogram from, typically 10 to match the resolution of the RGB imagery\n",
    "    bucket_num = int\n",
    "        number of buckets to put the data into for histogram\n",
    "    band_name = str\n",
    "        the name of your target band in the image\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Reduce the image to get a histogram over the region of interest (ROI)\n",
    "    hist = image.reduceRegion(\n",
    "        reducer=ee.Reducer.histogram(maxBuckets=bucket_num),  # Adjust the number of buckets as needed\n",
    "        geometry=aoi,\n",
    "        scale=scale,  # Adjust based on image resolution\n",
    "        maxPixels=1e8\n",
    "    )\n",
    "    \n",
    "    # Get the histogram data for NDWI\n",
    "    histogram = ee.Dictionary(hist.get(band_name)).getInfo() \n",
    "    \n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def otsu_trimodal_from_histogram(histogram):\n",
    "    # Extract histogram and means from the provided NDWI histogram\n",
    "    counts = np.array(histogram['histogram'])\n",
    "    means = np.array(histogram['bucketMeans'])\n",
    "    total = np.sum(counts)\n",
    "    sum_values = np.sum(means * counts)\n",
    "    overall_mean = sum_values / total\n",
    "    size = len(means)\n",
    "\n",
    "    # Define a function to compute the between-class variance (BSS)\n",
    "    def compute_intervariance(i, k):\n",
    "        # Compute for first region (A)\n",
    "        aCounts = counts[:i]\n",
    "        aCount = np.sum(aCounts)\n",
    "        aMeans = means[:i]\n",
    "        aMean = np.sum(aMeans * aCounts) / aCount if aCount != 0 else 0\n",
    "\n",
    "        # Compute for second region (B)\n",
    "        bCounts = counts[i:k]\n",
    "        bCount = np.sum(bCounts)\n",
    "        bMeans = means[i:k]\n",
    "        bMean = np.sum(bMeans * bCounts) / bCount if bCount != 0 else 0\n",
    "\n",
    "        # Compute for third region (C)\n",
    "        cCounts = counts[k:]\n",
    "        cCount = np.sum(cCounts)\n",
    "        cMeans = means[k:]\n",
    "        cMean = np.sum(cMeans * cCounts) / cCount if cCount != 0 else 0\n",
    "\n",
    "        # Return combined BSS\n",
    "        return aCount * (aMean - overall_mean) ** 2 + \\\n",
    "               bCount * (bMean - overall_mean) ** 2 + \\\n",
    "               cCount * (cMean - overall_mean) ** 2\n",
    "\n",
    "    # Initialize an empty list for BSS values\n",
    "    bss_values = []\n",
    "    \n",
    "    # Iterate through potential thresholds\n",
    "    for i in range(1, size - 1):  # Start at 1, and stop before the last element\n",
    "        for k in range(i + 1, size):  # Ensure k is always greater than i\n",
    "            bss_values.append(compute_intervariance(i, k))\n",
    "\n",
    "    # Convert BSS values to a NumPy array\n",
    "    bss_array = np.array(bss_values)\n",
    "\n",
    "    # Find indices of maximum BSS\n",
    "    max_bss_index = np.argmax(bss_array)\n",
    "    \n",
    "    # Convert the flat index back to i and k values\n",
    "    i_max = max_bss_index // (size - 1)\n",
    "    k_max = max_bss_index % (size - 1)\n",
    "\n",
    "    # Return corresponding means for the threshold\n",
    "    return means[i_max], means[k_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_shoreline(coll, datelist):\n",
    "    shorelines = []\n",
    "    smoothed_vectors = []\n",
    "\n",
    "    image_list = coll.toList(coll.size())  # Convert ImageCollection to List\n",
    "    for i, date in enumerate(datelist):\n",
    "        im = ee.Image(image_list.get(i))\n",
    "        hist = get_histogram(im, 10, 150, 'NDWI')\n",
    "    \n",
    "        t1, t2 = otsu_trimodal_from_histogram(hist)\n",
    "        if t1 < t2:\n",
    "            ndwi_thresh = [t1, t2]\n",
    "        else:\n",
    "            ndwi_thresh = [t2, t1]\n",
    "        \n",
    "        water_mask = im.lt(ee.Number(ndwi_thresh[0]))\n",
    "        land_mask = im.gt(ee.Number(ndwi_thresh[1]))\n",
    "        water_land_mask = water_mask.Not().add(land_mask).divide(2)\n",
    "        shores = water_land_mask.updateMask(water_land_mask.gt(0.0))\n",
    "    \n",
    "        binary_mask = im.updateMask(im.gte(0.0)).mask()\n",
    "        dilated_mask = binary_mask.focal_max(radius=10, units = 'meters')\n",
    "        eroded_mask = binary_mask.focal_min(radius=10, units = 'meters')\n",
    "        border_mask = dilated_mask.subtract(eroded_mask)\n",
    "        shoreline = shores.updateMask(border_mask) ###should be shoreline\n",
    "\n",
    "        shorelines.append(shoreline)  # shoreline\n",
    "        \n",
    "    return ee.ImageCollection(shorelines)\n",
    "\n",
    "def extract_vegline(coll, datelist):\n",
    "    veglines = []\n",
    "    \n",
    "    image_list = coll.toList(coll.size())  # Convert ImageCollection to List\n",
    "    for i, date in enumerate(datelist):\n",
    "        im = ee.Image(image_list.get(i))\n",
    "        hist = get_histogram(im, 10, 150, 'NDVI')\n",
    "    \n",
    "        t1, t2 = otsu_trimodal_from_histogram(hist)\n",
    "        if t1 < t2:\n",
    "            ndvi_thresh = [t1, t2]\n",
    "        else:\n",
    "            ndvi_thresh = [t2, t1]\n",
    "        \n",
    "        fv_mask = im.lt(ee.Number(ndvi_thresh[0]))\n",
    "        dv_mask = im.gt(ee.Number(ndvi_thresh[1]))\n",
    "        veg_land_mask = fv_mask.Not().add(dv_mask).divide(2)\n",
    "        veg = veg_land_mask.updateMask(veg_land_mask.gt(0.0))\n",
    "    \n",
    "        binary_mask = im.updateMask(im.gte(0.5)).mask()\n",
    "        dilated_mask = binary_mask.focal_max(radius=10, units = 'meters')\n",
    "        eroded_mask = binary_mask.focal_min(radius=10, units = 'meters')\n",
    "        border_mask = dilated_mask.subtract(eroded_mask)\n",
    "        vegline = veg.updateMask(border_mask) ###should be shoreline\n",
    "\n",
    "        veglines.append(vegline)\n",
    "\n",
    "    return ee.ImageCollection(veglines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate statistics for NDVI and NDMI over AOIs\n",
    "def extract_statistics(image, index_name):\n",
    "    # Reduce the image over the AOIs using mean, max, and min reducers\n",
    "    stats = image.reduceRegions(\n",
    "        collection=aois,\n",
    "        reducer=ee.Reducer.minMax().combine(\n",
    "            reducer2=ee.Reducer.percentile([25, 50, 75]).combine(\n",
    "                reducer2=ee.Reducer.mean().combine(\n",
    "                    reducer2=ee.Reducer.stdDev(),\n",
    "                    sharedInputs=True\n",
    "                ),\n",
    "                sharedInputs=True\n",
    "            ),\n",
    "            sharedInputs=True\n",
    "        ),\n",
    "        scale=10\n",
    "    )\n",
    "    \n",
    "    # Add the date of the image as a property to each feature in the collection\n",
    "    date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd')\n",
    "    stats = stats.map(lambda f: f.set('date', date))\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# my function needs im_coll, index_name, and aoi\n",
    "\n",
    "def extract_stats_from_aoi(image_collection, index_name, aoi):\n",
    "    stats_ims = image_collection.map(lambda img: img.clip(aoi))\n",
    "    stats_collection = stats_ims.map(lambda img: extract_statistics(img, index_name)).flatten()\n",
    "    statslist = stats_collection.getInfo()['features']\n",
    "\n",
    "    data=[]\n",
    "    for feature in statslist:\n",
    "        properties = feature['properties']\n",
    "        data_dict = {}\n",
    "        for key in properties:\n",
    "            data_dict[f'{key}'] = properties[key]\n",
    "        data.append(data_dict)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Convert the date column to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # Sort the DataFrame by date\n",
    "    df = df.sort_values(by='date')\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_VI_ts(aoi, aoi_str, plottype):\n",
    "    # Plotting the mean, standard deviation, and quartiles\n",
    "    if plottype == 'together':\n",
    "    \n",
    "        plt.figure(figsize=(14, 7))\n",
    "\n",
    "\n",
    "        for imcoll in [total_colls['s2_10m_ndvi'], total_colls['s2_10m_ndwi'], total_colls['s2_10m_msavi2']]:\n",
    "            if imcoll == total_colls['s2_10m_ndvi']:\n",
    "                df = extract_stats_from_aoi(imcoll, 'NDVI', aoi)\n",
    "                plt.plot(df['date'], df['mean'], color='green', marker='o', linestyle='-', label='Mean NDVI')\n",
    "                plt.fill_between(df['date'],\n",
    "                                df['mean'] - df['stdDev'],\n",
    "                                df['mean'] + df['stdDev'],\n",
    "                                color='green', alpha=0.2, label='NDVI ± 1 Std Dev'\n",
    "                            )\n",
    "\n",
    "                # Plot NDVI Interquartile Range (IQR)\n",
    "                plt.fill_between(df['date'],\n",
    "                                df['p25'],\n",
    "                                df['p75'],\n",
    "                                color='green', alpha=0.5, linestyle='-', label='NDVI IQR (25th to 75th Percentile)'\n",
    "                            )\n",
    "\n",
    "            elif imcoll == total_colls['s2_10m_ndwi']:\n",
    "            # Plot NDVI Mean with ±1 Std Dev Shading\n",
    "                df = extract_stats_from_aoi(imcoll, 'NDWI', aoi)\n",
    "                plt.plot(df['date'], df['mean'], color='blue', marker='o', linestyle='-', label='Mean NDWI')\n",
    "                plt.fill_between(df['date'],\n",
    "                                    df['mean'] - df['stdDev'],\n",
    "                                    df['mean'] + df['stdDev'],\n",
    "                                    color='blue', alpha=0.2, label='NDVI ± 1 Std Dev'\n",
    "                                )\n",
    "\n",
    "                # Plot NDVI Interquartile Range (IQR)\n",
    "                plt.fill_between(df['date'],\n",
    "                                    df['p25'],\n",
    "                                    df['p75'],\n",
    "                                    color='blue', alpha=0.5, linestyle='-', label='NDWI IQR (25th to 75th Percentile)'\n",
    "                                )\n",
    "                \n",
    "            elif imcoll == total_colls['s2_10m_msavi2']:\n",
    "                df = extract_stats_from_aoi(imcoll, 'MSAVI2', aoi)\n",
    "                plt.plot(df['date'], df['mean'], color='red', marker='o', linestyle='-', label='Mean MSAVI2')\n",
    "                plt.fill_between(df['date'],\n",
    "                                df['mean'] - df['stdDev'],\n",
    "                                df['mean'] + df['stdDev'],\n",
    "                                color='red', alpha=0.2, label='MSAVI2 ± 1 Std Dev'\n",
    "                            )\n",
    "\n",
    "                # Plot MSAVI2 Interquartile Range (IQR)\n",
    "                plt.fill_between(df['date'],\n",
    "                                df['p25'],\n",
    "                                df['p75'],\n",
    "                                color='red', alpha=0.5, linestyle='-', label='MSAVI2 IQR (25th to 75th Percentile)'\n",
    "                            )\n",
    "\n",
    "        # Add vertical lines for Hurricane Laura and Hurricane Delta\n",
    "        storm_dates = {\n",
    "            'Hurricane Laura': pd.to_datetime('2020-08-27'),\n",
    "            'Hurricane Delta': pd.to_datetime('2020-10-09'),\n",
    "            'Hurricane Zeta': pd.to_datetime('2020-10-28'),\n",
    "            'Hurricane Ida': pd.to_datetime('2021-08-29'),\n",
    "            'Hurricane Beryl': pd.to_datetime('2024-07-24'),\n",
    "            'Hurricane Francine': pd.to_datetime('2024-09-11')\n",
    "        }\n",
    "\n",
    "        for storm, date in storm_dates.items():\n",
    "            if storm[0] == 'H':\n",
    "                plt.axvline(x=date, color='purple', linestyle='--', linewidth=2)\n",
    "                \n",
    "        # Customizing the plot\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'NDVI, NDWI, and MSAVI2 Change Over Time for {aoi_str}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Show plot\n",
    "        plt.show()\n",
    "    \n",
    "    elif plottype == 'separate':\n",
    "        \n",
    "        plt.figure(figsize=(14,7))\n",
    "\n",
    "        df = extract_stats_from_aoi(total_colls['s2_10m_ndvi'], 'NDVI', aoi)\n",
    "        plt.plot(df['date'], df['mean'], color='green', marker='o', linestyle='-', label='Mean NDVI')\n",
    "        plt.fill_between(df['date'],\n",
    "                        df['mean'] - df['stdDev'],\n",
    "                        df['mean'] + df['stdDev'],\n",
    "                        color='green', alpha=0.2, label='NDVI ± 1 Std Dev'\n",
    "                    )\n",
    "\n",
    "        # Plot NDVI Interquartile Range (IQR)\n",
    "        plt.fill_between(df['date'],\n",
    "                        df['p25'],\n",
    "                        df['p75'],\n",
    "                        color='green', alpha=0.5, linestyle='-', label='NDVI IQR (25th to 75th Percentile)'\n",
    "                    )\n",
    "        \n",
    "        # Add vertical lines for Hurricane Laura and Hurricane Delta\n",
    "        storm_dates = {\n",
    "            'Hurricane Laura': pd.to_datetime('2020-08-27'),\n",
    "            'Hurricane Delta': pd.to_datetime('2020-10-09'),\n",
    "            'Hurricane Zeta': pd.to_datetime('2020-10-28'),\n",
    "            'Hurricane Ida': pd.to_datetime('2021-08-29'),\n",
    "            'Hurricane Beryl': pd.to_datetime('2024-07-24'),\n",
    "            'Hurricane Francine': pd.to_datetime('2024-09-11')\n",
    "        }\n",
    "\n",
    "        for storm, date in storm_dates.items():\n",
    "            if storm[0] == 'H':\n",
    "                plt.axvline(x=date, color='purple', linestyle='--', linewidth=2)\n",
    "\n",
    "        # Customizing the plot\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'NDVI Change Over Time for {aoi_str}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Show plot\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(14,7))\n",
    "        df = extract_stats_from_aoi(total_colls['s2_10m_ndwi'], 'NDWI', aoi)\n",
    "        plt.plot(df['date'], df['mean'], color='blue', marker='o', linestyle='-', label='Mean NDWI')\n",
    "        plt.fill_between(df['date'],\n",
    "                        df['mean'] - df['stdDev'],\n",
    "                        df['mean'] + df['stdDev'],\n",
    "                        color='blue', alpha=0.2, label='NDWI ± 1 Std Dev'\n",
    "                    )\n",
    "\n",
    "        # Plot NDWI Interquartile Range (IQR)\n",
    "        plt.fill_between(df['date'],\n",
    "                        df['p25'],\n",
    "                        df['p75'],\n",
    "                        color='blue', alpha=0.5, linestyle='-', label='NDWI IQR (25th to 75th Percentile)'\n",
    "                    )\n",
    "        \n",
    "        # Add vertical lines for Hurricane Laura and Hurricane Delta\n",
    "        storm_dates = {\n",
    "            'Hurricane Laura': pd.to_datetime('2020-08-27'),\n",
    "            'Hurricane Delta': pd.to_datetime('2020-10-09'),\n",
    "            'Hurricane Zeta': pd.to_datetime('2020-10-28'),\n",
    "            'Hurricane Ida': pd.to_datetime('2021-08-29'),\n",
    "            'Hurricane Beryl': pd.to_datetime('2024-07-24'),\n",
    "            'Hurricane Francine': pd.to_datetime('2024-09-11')\n",
    "        }\n",
    "\n",
    "        for storm, date in storm_dates.items():\n",
    "            if storm[0] == 'H':\n",
    "                plt.axvline(x=date, color='purple', linestyle='--', linewidth=2)\n",
    "\n",
    "        # Customizing the plot\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'NDWI Change Over Time for {aoi_str}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Show plot\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(14,7))\n",
    "\n",
    "        df = extract_stats_from_aoi(total_colls['s2_10m_msavi2'], 'MSAVI2', aoi)\n",
    "        plt.plot(df['date'], df['mean'], color='red', marker='o', linestyle='-', label='Mean MSAVI2')\n",
    "        plt.fill_between(df['date'],\n",
    "                        df['mean'] - df['stdDev'],\n",
    "                        df['mean'] + df['stdDev'],\n",
    "                        color='red', alpha=0.2, label='MSAVI2 ± 1 Std Dev'\n",
    "                    )\n",
    "\n",
    "        # Plot NDVI Interquartile Range (IQR)\n",
    "        plt.fill_between(df['date'],\n",
    "                        df['p25'],\n",
    "                        df['p75'],\n",
    "                        color='red', alpha=0.5, linestyle='-', label='MSAVI2 IQR (25th to 75th Percentile)'\n",
    "                    )\n",
    "        \n",
    "        # Add vertical lines for Hurricane Laura and Hurricane Delta\n",
    "        storm_dates = {\n",
    "            'Hurricane Laura': pd.to_datetime('2020-08-27'),\n",
    "            'Hurricane Delta': pd.to_datetime('2020-10-09'),\n",
    "            'Hurricane Zeta': pd.to_datetime('2020-10-28'),\n",
    "            'Hurricane Ida': pd.to_datetime('2021-08-29'),\n",
    "            'Hurricane Beryl': pd.to_datetime('2024-07-24'),\n",
    "            'Hurricane Francine': pd.to_datetime('2024-09-11')\n",
    "        }\n",
    "\n",
    "        for storm, date in storm_dates.items():\n",
    "            if storm[0] == 'H':\n",
    "                plt.axvline(x=date, color='purple', linestyle='--', linewidth=2)\n",
    "\n",
    "        # Customizing the plot\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'MSAVI2 Change Over Time for {aoi_str}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Show plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_GRD_ts(aoi, aoi_str, plottype):\n",
    "    # Plotting the mean, standard deviation, and quartiles\n",
    "    if plottype == 'together':\n",
    "        plt.figure(figsize=(14, 7))\n",
    "\n",
    "\n",
    "        for imcoll in [total_colls['s1_VV'], total_colls['s1_VH']]:\n",
    "            if imcoll == total_colls['s1_VV']:\n",
    "                df = extract_stats_from_aoi(imcoll, 'VV', aoi)\n",
    "                plt.plot(df['date'], df['mean'], color='green', marker='o', linestyle='-', label='Mean VV Backscatter')\n",
    "                plt.fill_between(df['date'],\n",
    "                                df['mean'] - df['stdDev'],\n",
    "                                df['mean'] + df['stdDev'],\n",
    "                                color='green', alpha=0.2, label='VV Backscatter ± 1 Std Dev'\n",
    "                            )\n",
    "\n",
    "                # Plot VV Interquartile Range (IQR)\n",
    "                plt.fill_between(df['date'],\n",
    "                                df['p25'],\n",
    "                                df['p75'],\n",
    "                                color='green', alpha=0.5, linestyle='-', label='VV Backascatter IQR (25th to 75th Percentile)'\n",
    "                            )\n",
    "\n",
    "            elif imcoll == total_colls['s1_VH']:\n",
    "            # Plot VH Mean with ±1 Std Dev Shading\n",
    "                df = extract_stats_from_aoi(imcoll, 'VH', aoi)\n",
    "                plt.plot(df['date'], df['mean'], color='blue', marker='o', linestyle='-', label='Mean VH Backscatter')\n",
    "                plt.fill_between(df['date'],\n",
    "                                    df['mean'] - df['stdDev'],\n",
    "                                    df['mean'] + df['stdDev'],\n",
    "                                    color='blue', alpha=0.2, label='VH Backscatter ± 1 Std Dev'\n",
    "                                )\n",
    "\n",
    "                # Plot VH Interquartile Range (IQR)\n",
    "                plt.fill_between(df['date'],\n",
    "                                    df['p25'],\n",
    "                                    df['p75'],\n",
    "                                    color='blue', alpha=0.5, linestyle='-', label='VH Backscatter IQR (25th to 75th Percentile)'\n",
    "                                )\n",
    "\n",
    "\n",
    "        # Add vertical lines for Hurricane Laura and Hurricane Delta\n",
    "        storm_dates = {\n",
    "            'Hurricane Laura': pd.to_datetime('2020-08-27'),\n",
    "            'Hurricane Delta': pd.to_datetime('2020-10-09'),\n",
    "            'Hurricane Zeta': pd.to_datetime('2020-10-28'),\n",
    "            'Hurricane Ida': pd.to_datetime('2021-08-29'),\n",
    "            'Hurricane Beryl': pd.to_datetime('2024-07-24'),\n",
    "            'Hurricane Francine': pd.to_datetime('2024-09-11')\n",
    "        }\n",
    "\n",
    "        for storm, date in storm_dates.items():\n",
    "            if storm[0] == 'H':\n",
    "                plt.axvline(x=date, color='purple', linestyle='--', linewidth=2)\n",
    "\n",
    "        \n",
    "        # Customizing the plot\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'Sentinel-1 Backscatter Amplitude Change Over Time for {aoi_str}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Show plot\n",
    "        plt.show()\n",
    "\n",
    "    elif plottype == 'separate':\n",
    "        df = extract_stats_from_aoi(total_colls['s1_VV'], 'VV', aoi)\n",
    "        plt.plot(df['date'], df['mean'], color='green', marker='o', linestyle='-', label='Mean VV Backscatter')\n",
    "        plt.fill_between(df['date'],\n",
    "                        df['mean'] - df['stdDev'],\n",
    "                        df['mean'] + df['stdDev'],\n",
    "                        color='green', alpha=0.2, label='VV Backscatter ± 1 Std Dev'\n",
    "                    )\n",
    "\n",
    "        # Plot VV Interquartile Range (IQR)\n",
    "        plt.fill_between(df['date'],\n",
    "                        df['p25'],\n",
    "                        df['p75'],\n",
    "                        color='green', alpha=0.5, linestyle='-', label='VV Backascatter IQR (25th to 75th Percentile)'\n",
    "                    )\n",
    "        \n",
    "        # Add vertical lines for Hurricane Laura and Hurricane Delta\n",
    "        storm_dates = {\n",
    "            'Hurricane Laura': pd.to_datetime('2020-08-27'),\n",
    "            'Hurricane Delta': pd.to_datetime('2020-10-09'),\n",
    "            'Hurricane Zeta': pd.to_datetime('2020-10-28'),\n",
    "            'Hurricane Ida': pd.to_datetime('2021-08-29'),\n",
    "            'Hurricane Beryl': pd.to_datetime('2024-07-24'),\n",
    "            'Hurricane Francine': pd.to_datetime('2024-09-11')\n",
    "        }\n",
    "\n",
    "        for storm, date in storm_dates.items():\n",
    "            if storm[0] == 'H':\n",
    "                plt.axvline(x=date, color='purple', linestyle='--', linewidth=2)\n",
    "\n",
    "        # Customizing the plot\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'Sentinel-1 VV Backscatter Amplitude Change Over Time for {aoi_str}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Show plot\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        df = extract_stats_from_aoi(total_colls['s1_VH'], 'VH', aoi)\n",
    "        plt.plot(df['date'], df['mean'], color='blue', marker='o', linestyle='-', label='Mean VH Backscatter')\n",
    "        plt.fill_between(df['date'],\n",
    "                        df['mean'] - df['stdDev'],\n",
    "                        df['mean'] + df['stdDev'],\n",
    "                        color='blue', alpha=0.2, label='VH Backscatter ± 1 Std Dev'\n",
    "                    )\n",
    "\n",
    "        # Plot VV Interquartile Range (IQR)\n",
    "        plt.fill_between(df['date'],\n",
    "                        df['p25'],\n",
    "                        df['p75'],\n",
    "                        color='blue', alpha=0.5, linestyle='-', label='VH Backascatter IQR (25th to 75th Percentile)'\n",
    "                    )\n",
    "        \n",
    "\n",
    "        # Add vertical lines for Hurricane Laura and Hurricane Delta\n",
    "        storm_dates = {\n",
    "            'Hurricane Laura': pd.to_datetime('2020-08-27'),\n",
    "            'Hurricane Delta': pd.to_datetime('2020-10-09'),\n",
    "            'Hurricane Zeta': pd.to_datetime('2020-10-28'),\n",
    "            'Hurricane Ida': pd.to_datetime('2021-08-29'),\n",
    "            'Hurricane Beryl': pd.to_datetime('2024-07-24'),\n",
    "            'Hurricane Francine': pd.to_datetime('2024-09-11')\n",
    "        }\n",
    "\n",
    "        for storm, date in storm_dates.items():\n",
    "            if storm[0] == 'H':\n",
    "                plt.axvline(x=date, color='purple', linestyle='--', linewidth=2)\n",
    "\n",
    "        # Customizing the plot\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'Sentinel-1 VH Backscatter Amplitude Change Over Time for {aoi_str}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Show plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## interactive map for you to draw a polygon to signify your aoi\n",
    "\n",
    "## Create a map centered at a specific location\n",
    "m = geemap.Map(center=[20, 0], zoom=2, basemap='HYBRID')\n",
    "## Add drawing tools\n",
    "m.add_draw_control()\n",
    "## Display the map\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the drawn features\n",
    "draw_features = m.draw_features[0]\n",
    "## Establish ee.Polygon from drawn area of interest to collect imagery\n",
    "aoi = ee.Geometry.Polygon(draw_features.getInfo()['geometry']['coordinates'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2018-01-01' ## start date of search window\n",
    "end_date = '2024-10-03' ## end date of search window\n",
    "s2_cloud_cov = 10 ## percentage of clouds in sentinel-2 multispectral imagery, less means you see more surface\n",
    "orbit = 'ASCENDING' ## orbit for imagery\n",
    "\n",
    "collections = {}\n",
    "for i in range(int(start_date[:4]), int(end_date[:4])):\n",
    "    collections[f's1_VV_{i}_{i+1}'], collections[f's1_VH_{i}_{i+1}'], collections[f's2_10m_{i}_{i+1}'], collections[f's2_10m_ndvi_{i}_{i+1}'], collections[f's2_10m_ndwi_{i}_{i+1}'], collections[f's2_10m_msavi2_{i}_{i+1}']  = get_sentinel_imagery(aoi, f'{i}{start_date[4:]}', f'{i+1}{end_date[4:]}', s2_cloud_cov, orbit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_colls = {}\n",
    "total_colls['s1_VV'], total_colls['s1_VH'], total_colls['s2_10m'], total_colls['s2_10m_ndvi'], total_colls['s2_10m_ndwi'], total_colls['s2_10m_msavi2']= get_sentinel_imagery(aoi, start_date, end_date, s2_cloud_cov, orbit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colls = []\n",
    "for i, coll in enumerate(collections):\n",
    "    if collections[coll].size().getInfo() != 0: # removes image collections that are empty\n",
    "        colls.append(coll)\n",
    "\n",
    "for i, coll in enumerate(colls):\n",
    "    print(f'{i}: {coll}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Distribution of Spectral Indices Values for Select Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no mask\n",
    "\n",
    "# all I need for segmenting images into coastlines would be\n",
    "# Need to make this applicable for each image in image collection\n",
    "# it will read in a specified band of a passed image collection, then segment it using Otsu's method\n",
    "# It should create a new image collection of \n",
    "#   1) Water Bodies, 2) Land Bodies, 3) Shorelines\n",
    "# those can then be used to measure horizontal changes in shoreline over time\n",
    "\n",
    "# Get the first image in the collection (or map over the collection if needed)\n",
    "s2_date_list = collections[colls[4]].map(get_date).aggregate_array('date').getInfo()\n",
    "ndwi_image = collections[colls[4]].first()\n",
    "ndwi_image = ndwi_image.updateMask(ndwi_image.lt(0.0))\n",
    "\n",
    "ndwi_date = s2_date_list[0]\n",
    "ndwi_histogram = get_histogram(ndwi_image, 10, 150, 'NDWI')\n",
    "\n",
    "# Extract the histogram values for plotting\n",
    "ndwi_values = ndwi_histogram['bucketMeans']\n",
    "ndwi_counts = ndwi_histogram['histogram']\n",
    "\n",
    "\n",
    "# second date\n",
    "# Get the first image in the collection (or map over the collection if needed)\n",
    "s2_date_list2 = collections[colls[22]].map(get_date).aggregate_array('date').getInfo()\n",
    "ndwi_image2 = collections[colls[22]].first()\n",
    "ndwi_image2 = ndwi_image2.updateMask(ndwi_image2.lt(0.0))\n",
    "\n",
    "\n",
    "ndwi_date2 = s2_date_list2[0]\n",
    "ndwi_histogram2 = get_histogram(ndwi_image2, 10, 150, 'NDWI')\n",
    "\n",
    "# Extract the histogram values for plotting\n",
    "ndwi_values2 = ndwi_histogram2['bucketMeans']\n",
    "ndwi_counts2 = ndwi_histogram2['histogram']\n",
    "\n",
    "# Plot the histogram using Matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(ndwi_values, ndwi_counts, width=0.02, color='blue', alpha=0.7, label = ndwi_date)\n",
    "plt.bar(ndwi_values2, ndwi_counts2, width=0.02, color='red', alpha=0.4, label = ndwi_date2)\n",
    "plt.title(f\"NDWI Histogram\")\n",
    "plt.xlabel(\"NDWI Values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "edge_i, edge_k = otsu_trimodal_from_histogram(ndwi_histogram)\n",
    "print(f'NDWI Thershold 1 {ndwi_date}= {edge_i}')\n",
    "print(f'NDWI Thershold 2 {ndwi_date}= {edge_k}')\n",
    "\n",
    "if edge_i < edge_k:\n",
    "    ndwi_thresh = [edge_i, edge_k]\n",
    "else:\n",
    "    ndwi_thresh = [edge_k, edge_i]\n",
    "\n",
    "edge_i2, edge_k2 = otsu_trimodal_from_histogram(ndwi_histogram2)\n",
    "print(f'NDWI Thershold 1 {ndwi_date2}= {edge_i2}')\n",
    "print(f'NDWI Thershold 2 {ndwi_date2}= {edge_k2}')\n",
    "\n",
    "if edge_i2 < edge_k2:\n",
    "    ndwi_thresh2 = [edge_i2, edge_k2]\n",
    "else:\n",
    "    ndwi_thresh2 = [edge_k2, edge_i2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no mask\n",
    "\n",
    "# all I need for segmenting images into coastlines would be\n",
    "# Need to make this applicable for each image in image collection\n",
    "# it will read in a specified band of a passed image collection, then segment it using Otsu's method\n",
    "# It should create a new image collection of \n",
    "#   1) Water Bodies, 0) Land Bodies, 3) Shorelines\n",
    "# those can then be used to measure horizontal changes in shoreline over time\n",
    "\n",
    "# Get the first image in the collection (or map over the collection if needed)\n",
    "s2_date_list = collections[colls[3]].map(get_date).aggregate_array('date').getInfo()\n",
    "ndvi_image = collections[colls[3]].first()\n",
    "ndvi_image = ndvi_image.updateMask(ndvi_image.gte(0.0))     ### mask to remove the water and low vegetation areas\n",
    "\n",
    "ndvi_date = s2_date_list[0]\n",
    "ndvi_histogram = get_histogram(ndvi_image, 10, 150, 'NDVI')\n",
    "\n",
    "# Extract the histogram values for plotting\n",
    "ndvi_values = ndvi_histogram['bucketMeans']\n",
    "ndvi_counts = ndvi_histogram['histogram']\n",
    "\n",
    "\n",
    "# second date\n",
    "# Get the first image in the collection (or map over the collection if needed)\n",
    "s1_date_list2 = collections[colls[21]].map(get_date).aggregate_array('date').getInfo()\n",
    "ndvi_image2 = collections[colls[21]].first()\n",
    "ndvi_image2 = ndvi_image2.updateMask(ndvi_image2.gte(0.0))\n",
    "\n",
    "ndvi_date2 = s1_date_list2[0]\n",
    "ndvi_histogram2 = get_histogram(ndvi_image2, 10, 150, 'NDVI')\n",
    "\n",
    "# Extract the histogram values for plotting\n",
    "ndvi_values2 = ndvi_histogram2['bucketMeans']\n",
    "ndvi_counts2 = ndvi_histogram2['histogram']\n",
    "\n",
    "# Plot the histogram using Matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(ndvi_values, ndvi_counts, width=0.02, color='blue', alpha=0.7, label = ndvi_date)\n",
    "plt.bar(ndvi_values2, ndvi_counts2, width=0.02, color='red', alpha=0.4, label = ndvi_date2)\n",
    "plt.title(f\"NDVI Histogram\")\n",
    "plt.xlabel(\"NDVI Values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "edge_i, edge_k = otsu_trimodal_from_histogram(ndvi_histogram)\n",
    "if edge_i < edge_k:\n",
    "    ndvi_thresh = [edge_i, edge_k]\n",
    "else:\n",
    "    ndvi_thresh = [edge_k, edge_i]\n",
    "\n",
    "edge_i2, edge_k2 = otsu_trimodal_from_histogram(ndvi_histogram2)\n",
    "if edge_i2 < edge_k2:\n",
    "    ndvi_thresh2 = [edge_i2, edge_k2]\n",
    "else:\n",
    "    ndvi_thresh2 = [edge_k2, edge_i2]\n",
    "\n",
    "print(f'NDVI Thersholds for {ndvi_date} = {ndvi_thresh}')\n",
    "print(f'NDVI Thersholds for {ndvi_date2} = {ndvi_thresh2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_date_list = collections[colls[5]].map(get_date).aggregate_array('date').getInfo()\n",
    "msavi2_image = collections[colls[5]].first()\n",
    "msavi2_image = msavi2_image.updateMask(msavi2_image.gte(0.0))     ### mask to remove the water and low vegetation areas\n",
    "\n",
    "msavi2_date = s2_date_list[0]\n",
    "msavi2_histogram = get_histogram(msavi2_image, 10, 150, 'MSAVI2')\n",
    "\n",
    "# Extract the histogram values for plotting\n",
    "msavi2_values = msavi2_histogram['bucketMeans']\n",
    "msavi2_counts = msavi2_histogram['histogram']\n",
    "\n",
    "\n",
    "# second date\n",
    "# Get the first image in the collection (or map over the collection if needed)\n",
    "s2_date_list2 = collections[colls[23]].map(get_date).aggregate_array('date').getInfo()\n",
    "msavi2_image2 = collections[colls[23]].first()\n",
    "msavi2_image2 = msavi2_image2.updateMask(msavi2_image2.gte(0.0))\n",
    "\n",
    "msavi2_date2 = s2_date_list2[0]\n",
    "msavi2_histogram2 = get_histogram(msavi2_image2, 10, 150, 'MSAVI2')\n",
    "\n",
    "# Extract the histogram values for plotting\n",
    "msavi2_values2 = msavi2_histogram2['bucketMeans']\n",
    "msavi2_counts2 = msavi2_histogram2['histogram']\n",
    "\n",
    "# Plot the histogram using Matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(msavi2_values, msavi2_counts, width=0.02, color='blue', alpha=0.7, label = msavi2_date)\n",
    "plt.bar(msavi2_values2, msavi2_counts2, width=0.02, color='red', alpha=0.4, label = msavi2_date2)\n",
    "plt.title(f\"MSAVI2 Histogram\")\n",
    "plt.xlabel(\"MSAVI2 Values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "edge_i, edge_k = otsu_trimodal_from_histogram(msavi2_histogram)\n",
    "if edge_i < edge_k:\n",
    "    msavi2_thresh = [edge_i, edge_k]\n",
    "else:\n",
    "    msavi2_thresh = [edge_k, edge_i]\n",
    "\n",
    "edge_i2, edge_k2 = otsu_trimodal_from_histogram(msavi2_histogram2)\n",
    "if edge_i2 < edge_k2:\n",
    "    msavi2_thresh2 = [edge_i2, edge_k2]\n",
    "else:\n",
    "    msavi2_thresh2 = [edge_k2, edge_i2]\n",
    "\n",
    "print(f'MSAVI2 Thersholds for {msavi2_date} = {msavi2_thresh}')\n",
    "print(f'MSAVI2 Thersholds for {msavi2_date2} = {msavi2_thresh2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shoreline and Veg line detection based on Otsu Trimodal Thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get info of specific areas of information\n",
    "- can be specific areas where change has occurred, in my application probably sediment enrichment\n",
    "- (working) get a time series of NDVI and NDWI for the area delineated by the drawn aois and shoreline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_date_list = collections[colls[4]].map(get_date).aggregate_array('date').getInfo()\n",
    "s2_date = s2_date_list[0]\n",
    "\n",
    "## Create a map centered at a specific location\n",
    "m = geemap.Map()\n",
    "m.centerObject(aoi, 12)\n",
    "\n",
    "# Add the original rgb image for context\n",
    "m.addLayer(collections[colls[2]].first(), {'min': 0, 'max': 2000, 'bands': ['B4', 'B3', 'B2']}, f'{s2_date} RGB')\n",
    "\n",
    "\n",
    "#draw the specific aois you want to get time series info from\n",
    "# for now needs to be an area\n",
    "# later will add stuff for transects\n",
    "m.add_draw_control()\n",
    "m.addLayerControl()\n",
    "display(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to add another \n",
    "## Get the drawn features\n",
    "drawn_features = m.draw_features\n",
    "\n",
    "aois = ee.FeatureCollection(drawn_features)\n",
    "\n",
    "sites = {}\n",
    "for i, site in enumerate(drawn_features):\n",
    "    sites[f'Site {i}'] = ee.Geometry.Polygon(site.getInfo()['geometry']['coordinates'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2_date_list = total_colls['s2_10m_ndwi'].map(get_date).aggregate_array('date').getInfo()\n",
    "# shoreline_collection = extract_shoreline(coll = total_colls['s2_10m_ndwi'] , datelist =s2_date_list)\n",
    "# vegline_collection = extract_vegline(coll = total_colls['s2_10m_ndvi'], datelist = s2_date_list )\n",
    "\n",
    "# clipped_shores = shoreline_collection.map(lambda img: img.clip(aois))\n",
    "# clipped_veg = vegline_collection.map(lambda img: img.clip(aois))\n",
    "# clipped_rgb = total_colls['s2_10m'].map(lambda img: img.clip(aois))\n",
    "\n",
    "# clipped_VV = total_colls['s1_VV'].map(lambda img: img.clip(aois))\n",
    "# clipped_VH = total_colls['s1_VH'].map(lambda img: img.clip(aois))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_date_list = collections[colls[20]].map(get_date).aggregate_array('date').getInfo()\n",
    "shoreline_collection = extract_shoreline(coll = collections[colls[22]] , datelist =s2_date_list)\n",
    "vegline_collection = extract_vegline(coll = collections[colls[21]], datelist = s2_date_list )\n",
    "\n",
    "clipped_shores = shoreline_collection.map(lambda img: img.clip(aois))\n",
    "clipped_veg = vegline_collection.map(lambda img: img.clip(aois))\n",
    "clipped_rgb = collections[colls[20]].map(lambda img: img.clip(aois))\n",
    "\n",
    "clipped_VV = collections[colls[18]].map(lambda img: img.clip(aois))\n",
    "clipped_VH = collections[colls[19]].map(lambda img: img.clip(aois))\n",
    "clipped_ndvi = collections[colls[21]].map(lambda img: img.clip(aois))\n",
    "clipped_ndwi = collections[colls[22]].map(lambda img: img.clip(aois))\n",
    "clipped_msavi2 = collections[colls[23]].map(lambda img: img.clip(aois))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_ts = geemap.Map()\n",
    "map_ts.centerObject(aoi, 12)\n",
    "\n",
    "rgb_images = clipped_rgb.toList(clipped_rgb.size())\n",
    "for i in range(clipped_rgb.size().getInfo()//10):\n",
    "    image = ee.Image(rgb_images.get(-i))\n",
    "    add_rgb_to_map(image, map_ts, clipped_rgb)\n",
    "\n",
    "    # VV_image = ee.Image((clipped_VV.toList(clipped_VV.size())).get(-i))\n",
    "    # add_sar_to_map(VV_image, map_ts, 'VV')\n",
    "\n",
    "    # VH_image = ee.Image((clipped_VH.toList(clipped_VH.size())).get(-i))\n",
    "    # add_sar_to_map(VH_image, map_ts, 'VH')\n",
    "\n",
    "    ndvi_image = ee.Image((clipped_ndvi.toList(clipped_ndvi.size())).get(-i))\n",
    "    add_ind_to_map(ndvi_image, map_ts, 'NDVI')\n",
    "\n",
    "    ndwi_image = ee.Image((clipped_ndwi.toList(clipped_ndwi.size())).get(-i))\n",
    "    add_ind_to_map(ndwi_image, map_ts, 'NDWI')\n",
    "\n",
    "    msavi2_image = ee.Image((clipped_msavi2.toList(clipped_msavi2.size())).get(-i))\n",
    "    add_ind_to_map(msavi2_image, map_ts, 'MSAVI2')\n",
    "    # shore_im = ee.Image(clipped_shores.toList(clipped_shores.size()).get(-i))\n",
    "    # map_ts.addLayer(shore_im, {}, f'{s2_date_list[i]} shore')\n",
    "\n",
    "    # veg_im = ee.Image(clipped_veg.toList(clipped_veg.size()).get(-i))\n",
    "    # map_ts.addLayer(veg_im, {}, f'{s2_date_list[i]} veg')\n",
    "\n",
    "\n",
    "\n",
    "# map_ts.add_draw_control()\n",
    "# Display the map\n",
    "map_ts.addLayerControl()\n",
    "\n",
    "## Display the map\n",
    "display(map_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot time series for the sites you identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sites:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Time series plot to show changes in NDVI and NDWI\n",
    "# plot_VI_ts(sites['Site 2'], 'Unit 1A', 'separate')\n",
    "# plot_VI_ts(sites['Site 1'], 'Unit 1B', 'separate')\n",
    "plot_VI_ts(sites['Site 1'], 'Unit 1D', 'separate') # site finished in Sept 2019\n",
    "plot_VI_ts(sites['Site 0'], 'Unit 1E', 'separate') # site finished in Sept 2019\n",
    "plot_VI_ts(sites['Site 2'], '2023 Site', 'separate') #Site Created in late 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Time series plot to show changes in Sentinel-1 GRD\n",
    "\n",
    "# plot_GRD_ts(sites['Site 4'], 'Unit 1A', 'together')\n",
    "# plot_GRD_ts(sites['Site 3'], 'Unit 1B', 'together')\n",
    "plot_GRD_ts(sites['Site 1'], 'Unit 1D', 'together') # Site finished in Sept 2019\n",
    "plot_GRD_ts(sites['Site 0'], 'Unit 1E', 'together') # Site finished in Sept 2019\n",
    "plot_GRD_ts(sites['Site 2'], '2023 Site', 'together') # Site created in Late 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_VI_ts_combined(aoi, aoi_str, plottype):\n",
    "    # Plotting the mean, standard deviation, and quartiles\n",
    "    if plottype == 'together':\n",
    "    \n",
    "        plt.figure(figsize=(14, 7))\n",
    "\n",
    "        for imcoll in [total_colls['s2_10m_ndvi'], total_colls['s2_10m_ndwi']]:\n",
    "            if imcoll == total_colls['s2_10m_ndvi']:\n",
    "                df_msavi2 = extract_stats_from_aoi(total_colls['s2_10m_msavi2'], 'MSAVI2', aoi)\n",
    "                df_ndvi = extract_stats_from_aoi(imcoll, 'NDVI', aoi)\n",
    "\n",
    "                # Replace NDVI/MSAVI2 values with NDVI where MSAVI2 > 0.6\n",
    "                df_combined = df_msavi2.copy()\n",
    "                condition = df_msavi2['mean'] > 0.6\n",
    "                df_combined.loc[condition, 'mean'] = df_ndvi.loc[condition, 'mean']\n",
    "                df_combined.loc[condition, 'stdDev'] = df_ndvi.loc[condition, 'stdDev']\n",
    "                df_combined.loc[condition, 'p25'] = df_ndvi.loc[condition, 'p25']\n",
    "                df_combined.loc[condition, 'p75'] = df_ndvi.loc[condition, 'p75']\n",
    "\n",
    "                plt.plot(df_combined['date'], df_combined['mean'], color='green', marker='o', linestyle='-', label='Mean NDVI/MSAVI2 (with NDVI substitution)')\n",
    "                plt.fill_between(df_combined['date'],\n",
    "                                df_combined['mean'] - df_combined['stdDev'],\n",
    "                                df_combined['mean'] + df_combined['stdDev'],\n",
    "                                color='green', alpha=0.2, label='NDVI/MSAVI2 ± 1 Std Dev (with NDVI substitution)'\n",
    "                            )\n",
    "\n",
    "                # Plot NDVI/MSAVI2 Interquartile Range (IQR)\n",
    "                plt.fill_between(df_combined['date'],\n",
    "                                df_combined['p25'],\n",
    "                                df_combined['p75'],\n",
    "                                color='green', alpha=0.5, linestyle='-', label='NDVI/MSAVI2 IQR (with NDVI substitution)'\n",
    "                            )\n",
    "\n",
    "            elif imcoll == total_colls['s2_10m_ndwi']:\n",
    "                df_ndwi = extract_stats_from_aoi(imcoll, 'NDWI', aoi)\n",
    "                plt.plot(df_ndwi['date'], df_ndwi['mean'], color='blue', marker='o', linestyle='-', label='Mean NDWI')\n",
    "                plt.fill_between(df_ndwi['date'],\n",
    "                                    df_ndwi['mean'] - df_ndwi['stdDev'],\n",
    "                                    df_ndwi['mean'] + df_ndwi['stdDev'],\n",
    "                                    color='blue', alpha=0.2, label='NDWI ± 1 Std Dev'\n",
    "                                )\n",
    "\n",
    "                # Plot NDWI Interquartile Range (IQR)\n",
    "                plt.fill_between(df_ndwi['date'],\n",
    "                                    df_ndwi['p25'],\n",
    "                                    df_ndwi['p75'],\n",
    "                                    color='blue', alpha=0.5, linestyle='-', label='NDWI IQR (25th to 75th Percentile)'\n",
    "                                )\n",
    "        \n",
    "\n",
    "\n",
    "        # Add vertical lines for Hurricane Laura and Hurricane Delta\n",
    "        storm_dates = {\n",
    "            'Hurricane Laura': pd.to_datetime('2020-08-27'),\n",
    "            'Hurricane Delta': pd.to_datetime('2020-10-09'),\n",
    "            'Hurricane Zeta': pd.to_datetime('2020-10-28'),\n",
    "            'Hurricane Ida': pd.to_datetime('2021-08-29'),\n",
    "            'Hurricane Beryl': pd.to_datetime('2024-07-24'),\n",
    "            'Hurricane Francine': pd.to_datetime('2024-09-11')\n",
    "        }\n",
    "\n",
    "        for storm, date in storm_dates.items():\n",
    "            if storm[0] == 'H':\n",
    "                plt.axvline(x=date, color='purple', linestyle='--', linewidth=2)\n",
    "\n",
    "        # Customizing the plot\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'NDVI/MSAVI2 and NDWI Change Over Time for {aoi_str}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Show plot\n",
    "        plt.show()\n",
    "        \n",
    "    elif plottype == 'separate':\n",
    "        \n",
    "        plt.figure(figsize=(14,7))\n",
    "\n",
    "        df_ndvi = extract_stats_from_aoi(total_colls['s2_10m_ndvi'], 'NDVI', aoi)\n",
    "        df_msavi2 = extract_stats_from_aoi(total_colls['s2_10m_msavi2'], 'MSAVI2', aoi)\n",
    "\n",
    "        # Replace NDVI/MSAVI2 values with NDVI where MSAVI2 > 0.6\n",
    "        df_combined = df_msavi2.copy()\n",
    "        condition = df_msavi2['mean'] > 0.6\n",
    "        df_combined.loc[condition, 'mean'] = df_ndvi.loc[condition, 'mean']\n",
    "        df_combined.loc[condition, 'stdDev'] = df_ndvi.loc[condition, 'stdDev']\n",
    "        df_combined.loc[condition, 'p25'] = df_ndvi.loc[condition, 'p25']\n",
    "        df_combined.loc[condition, 'p75'] = df_ndvi.loc[condition, 'p75']\n",
    "\n",
    "        plt.plot(df_combined['date'], df_combined['mean'], color='green', marker='o', linestyle='-', label='Mean NDVI/MSAVI2 (with NDVI substitution)')\n",
    "        plt.fill_between(df_combined['date'],\n",
    "                        df_combined['mean'] - df_combined['stdDev'],\n",
    "                        df_combined['mean'] + df_combined['stdDev'],\n",
    "                        color='green', alpha=0.2, label='NDVI/MSAVI2 ± 1 Std Dev (with NDVI substitution)'\n",
    "                    )\n",
    "\n",
    "        # Plot NDVI/MSAVI2 Interquartile Range (IQR)\n",
    "        plt.fill_between(df_combined['date'],\n",
    "                        df_combined['p25'],\n",
    "                        df_combined['p75'],\n",
    "                        color='green', alpha=0.5, linestyle='-', label='NDVI/MSAVI2 IQR (with NDVI substitution)'\n",
    "                    )\n",
    "        \n",
    "        # Add vertical lines for Hurricane Laura and Hurricane Delta\n",
    "        storm_dates = {\n",
    "            'Hurricane Laura': pd.to_datetime('2020-08-27'),\n",
    "            'Hurricane Delta': pd.to_datetime('2020-10-09'),\n",
    "            'Hurricane Zeta': pd.to_datetime('2020-10-28'),\n",
    "            'Hurricane Ida': pd.to_datetime('2021-08-29'),\n",
    "            'Hurricane Beryl': pd.to_datetime('2024-07-24'),\n",
    "            'Hurricane Francine': pd.to_datetime('2024-09-11')\n",
    "        }\n",
    "\n",
    "        for storm, date in storm_dates.items():\n",
    "            if storm[0] == 'H':\n",
    "                plt.axvline(x=date, color='purple', linestyle='--', linewidth=2)\n",
    "\n",
    "        # Customizing the plot\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'Vegetation Change Over Time for {aoi_str}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Show plot\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(14,7))\n",
    "\n",
    "        df = extract_stats_from_aoi(total_colls['s2_10m_ndwi'], 'NDWI', aoi)\n",
    "        plt.plot(df['date'], df['mean'], color='blue', marker='o', linestyle='-', label='Mean NDWI')\n",
    "        plt.fill_between(df['date'],\n",
    "                        df['mean'] - df['stdDev'],\n",
    "                        df['mean'] + df['stdDev'],\n",
    "                        color='blue', alpha=0.2, label='NDWI ± 1 Std Dev'\n",
    "                    )\n",
    "\n",
    "        # Plot NDWI Interquartile Range (IQR)\n",
    "        plt.fill_between(df['date'],\n",
    "                        df['p25'],\n",
    "                        df['p75'],\n",
    "                        color='blue', alpha=0.5, linestyle='-', label='NDWI IQR (25th to 75th Percentile)'\n",
    "                    )\n",
    "        \n",
    "        # Add vertical lines for Hurricane Laura and Hurricane Delta\n",
    "        storm_dates = {\n",
    "            'Hurricane Laura': pd.to_datetime('2020-08-27'),\n",
    "            'Hurricane Delta': pd.to_datetime('2020-10-09'),\n",
    "            'Hurricane Zeta': pd.to_datetime('2020-10-28'),\n",
    "            'Hurricane Ida': pd.to_datetime('2021-08-29'),\n",
    "            'Hurricane Beryl': pd.to_datetime('2024-07-24'),\n",
    "            'Hurricane Francine': pd.to_datetime('2024-09-11')\n",
    "        }\n",
    "\n",
    "        for storm, date in storm_dates.items():\n",
    "            if storm[0] == 'H':\n",
    "                plt.axvline(x=date, color='purple', linestyle='--', linewidth=2)\n",
    "\n",
    "        # Customizing the plot\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title(f'NDWI Change Over Time for {aoi_str}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Show plot\n",
    "        plt.show()\n",
    "\n",
    "plot_VI_ts_combined(sites['Site 0'], 'Unit 1E', 'together')\n",
    "plot_VI_ts_combined(sites['Site 1'], 'Unit 1D', 'together')\n",
    "plot_VI_ts_combined(sites['Site 2'], '2023 Site', 'together')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean NDVI/NDWI Above Q3: small proportion of higher values pulling the mean upwards—perhaps due to localized greening or a recent vegetation growth spurt affecting only part of the area.\n",
    "- Mean NDVI/NDWI Below Q1: extreme low values are present, pulling the mean down—potentially due to vegetation loss, seasonal dry periods, or land cover change in part of the region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "- Get spatial statisitics from drawn_features, plot them in a time-series to show upper-value, lower-value, and mean-value for NDWI and NDVI. Will show evolution of vegetation cover and surface moisture from Sentinel-2\n",
    "- Vectorize the shoreline? Need to get the horizontal changes in the identified shorelines between subsequent changes\n",
    "- Once able to spatially estimate shoreline changes, use those to estimate area changes for the marsh creation sites. (Once the area is estiamted, the volumetric changes can be estimated using closmure phase corrected InSAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_shoreline_test(coll, datelist):\n",
    "    shorelines = []\n",
    "    smoothed_vectors = []\n",
    "\n",
    "    image_list = coll.toList(coll.size())  # Convert ImageCollection to List\n",
    "    for i, date in enumerate(datelist):\n",
    "        im = ee.Image(image_list.get(i))\n",
    "        ndvi_im = ee.Image(collections[colls[15]].toList(collections[colls[15]].size()).get(i))\n",
    "        im = im.updateMask(ndvi_im.gt(0.0))\n",
    "        hist = get_histogram(im, 10, 150, 'NDWI')\n",
    "    \n",
    "        t1, t2 = otsu_trimodal_from_histogram(hist)\n",
    "        if t1 < t2:\n",
    "            ndwi_thresh = [t1, t2]\n",
    "        else:\n",
    "            ndwi_thresh = [t2, t1]\n",
    "        \n",
    "        water_mask = im.lt(ee.Number(ndwi_thresh[0]))\n",
    "        land_mask = im.gt(ee.Number(ndwi_thresh[1]))\n",
    "        combo_mask = water_mask.Not().add(land_mask).divide(2)\n",
    "        shores = combo_mask.updateMask(combo_mask.gt(0.0))\n",
    "    \n",
    "        binary_mask = im.updateMask(im.gte(0.0)).mask()\n",
    "        dilated_mask = binary_mask.focal_max(radius=10, units = 'meters')\n",
    "        eroded_mask = binary_mask.focal_min(radius=10, units = 'meters')\n",
    "        border_mask = dilated_mask.subtract(eroded_mask)\n",
    "        shoreline = shores.updateMask(border_mask) ###should be shoreline\n",
    "\n",
    "        shorelines.append(shoreline)  # shoreline\n",
    "        \n",
    "    return ee.ImageCollection(shorelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_date_list = collections[colls[14]].map(get_date).aggregate_array('date').getInfo()\n",
    "testcoll = extract_shoreline_test(coll = collections[colls[16]] , datelist =s2_date_list)\n",
    "\n",
    "clipped_shores_test = testcoll.map(lambda img: img.clip(aois))\n",
    "clipped_rgb = collections[colls[14]].map(lambda img: img.clip(aois))\n",
    "\n",
    "clipped_VV = collections[colls[12]].map(lambda img: img.clip(aois))\n",
    "clipped_VH = collections[colls[13]].map(lambda img: img.clip(aois))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cannyedge = ee.Algorithms.CannyEdgeDetector(clipped_shores.first(), threshold = 0.5, sigma =1)\n",
    "\n",
    "vectors = clipped_shores_test.first().toInt().reduceToVectors(\n",
    "# vectors = cannyedge.toInt().reduceToVectors(\n",
    "    geometry = sites['Site 0'],\n",
    "    geometryType='polygon', \n",
    "    reducer=ee.Reducer.countEvery(),\n",
    "    scale=10  # Use an appropriate scale for your data\n",
    ")\n",
    "\n",
    "# Define a function that converts polygons to lines by using the .difference() method\n",
    "def polygon_to_line(feature):\n",
    "    geometry = feature.geometry()\n",
    "    # Using .difference() to convert a polygon to a line by removing the interior\n",
    "    line_geometry = geometry.difference(geometry.buffer(-1))\n",
    "    return feature.setGeometry(line_geometry)\n",
    "\n",
    "# Apply the function to convert polygons to lines\n",
    "lines = vectors.map(polygon_to_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maptest = geemap.Map()\n",
    "maptest.centerObject(aoi, 12)\n",
    "\n",
    "rgb_images = clipped_rgb.toList(clipped_rgb.size())\n",
    "for i in range(clipped_rgb.size().getInfo()//4):\n",
    "    image = ee.Image(rgb_images.get(-i))\n",
    "    add_rgb_to_map(image, maptest, clipped_rgb)\n",
    "\n",
    "    # sar_image = ee.Image((clipped_VV.toList(clipped_VV.size())).get(-i))\n",
    "    # add_sar_to_map(sar_image, maptest, 'VV')\n",
    "\n",
    "    shore_im = ee.Image(clipped_shores_test.toList(clipped_shores.size()).get(-i))\n",
    "    maptest.addLayer(shore_im, {}, f'{s2_date_list[i]} shore')\n",
    "\n",
    "    # veg_im = ee.Image(clipped_veg.toList(clipped_veg.size()).get(-i))\n",
    "    # maptest.addLayer(veg_im, {}, f'{s2_date_list[i]} veg')\n",
    "\n",
    "\n",
    "# maptest.addLayer(vectors, {}, f'test')\n",
    "# maptest.addLayer(lines, {}, f'test')\n",
    "# maptest.add_draw_control()\n",
    "# Display the map\n",
    "maptest.addLayerControl()\n",
    "\n",
    "## Display the map\n",
    "display(maptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maptest = geemap.Map()\n",
    "maptest.centerObject(aoi, 12)\n",
    "\n",
    "\n",
    "# Visualize each image in the ImageCollection.\n",
    "rgb_images = clipped_rgb.toList(clipped_rgb.size())\n",
    "for i in range(clipped_rgb.size().getInfo()//5):\n",
    "    image = ee.Image(rgb_images.get(i))\n",
    "    add_rgb_to_map(image, maptest, clipped_rgb)\n",
    "    \n",
    "    shore_im = ee.Image(clipped_shores.toList(clipped_shores.size()).get(i))\n",
    "    maptest.addLayer(shore_im, {'palette': 'black'}, f'{s2_date_list[i]} shore')\n",
    "\n",
    "    veg_im = ee.Image(clipped_veg.toList(clipped_veg.size()).get(i))\n",
    "    maptest.addLayer(veg_im, {'palette': 'red'}, f'{s2_date_list[i]} veg')\n",
    "\n",
    "# Display the map.\n",
    "maptest.addLayerControl(position = 'topright')\n",
    "maptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the shorelines so that I can clip the images by them\n",
    "### how to do this????\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Shoreline information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the shoreline vector as GeoJSON for use in QGIS or GDAL\n",
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection=vector_shoreline,\n",
    "    description='Shoreline_Export',\n",
    "    fileFormat='GeoJSON',  # GeoJSON is well-supported in QGIS and GDAL\n",
    "    fileNamePrefix='shoreline'\n",
    ")\n",
    "\n",
    "# Start the export task\n",
    "task.start()\n",
    "print(\"Shoreline extraction task started, check Google Earth Engine tasks for progress.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Export.image.toDrive({\n",
    "    'image': first_edge_image,\n",
    "    'description': 'Canny_Edges_Example',\n",
    "    'scale': 10,  # Adjust the scale according to the dataset resolution\n",
    "    'region': aoi,\n",
    "    'maxPixels': 1e8\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
