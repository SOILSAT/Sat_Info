{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## before anything you need to visit the site below and make sure you have a google earth engine account\n",
    "## this is so you can access Sentinel-1 GRD and Sentinel-2 TOA and SR products, as well as other sensor packages and data types\n",
    "\n",
    "## visit the below website below to setup an earth engine account, enable a cloud project, and enable the ee API \n",
    "## https://developers.google.com/earth-engine/cloud/earthengine_cloud_project_setup#get-access-to-earth-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import math\n",
    "import os\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## only need to run this once\n",
    "## after authenticating with google earth engine you will only need to initialize each session\n",
    "\n",
    "## https://developers.google.com/earth-engine/guides/auth\n",
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## init ee cloud project you made during initial setup\n",
    "ee.Initialize(project = 'ee-claycaldgsl') ##enter your project name here as a string to initialize exchanges with ee api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to add RGB images to the map.\n",
    "def add_rgb_to_map(image, map_object):\n",
    "\n",
    "    date = ee.Date(image.get('date')).format('YYYY-MM-dd').getInfo()\n",
    "    map_object.addLayer(image, {'min': 0, 'max': 2000, 'bands': ['B4', 'B3', 'B2']}, f'{date}_rgb')\n",
    "\n",
    "## Function to add spectral indices images to the map.\n",
    "def add_ind_to_map(image, map_object, band):\n",
    "\n",
    "    date = ee.Date(image.get('date')).format('YYYY-MM-dd').getInfo()\n",
    "    if band =='NDWI':\n",
    "        map_object.addLayer(image, {'min': -1, 'max': 1, 'bands': band, 'palette': cm.palettes.ndwi}, f'{date}_{band}')\n",
    "    elif band =='NDVI': \n",
    "        map_object.addLayer(image, {'min': -1, 'max': 1, 'bands': band, 'palette': cm.palettes.ndvi}, f'{date}_{band}')\n",
    "    elif band == 'MSAVI2':\n",
    "        map_object.addLayer(image, {'min': -1, 'max': 1, 'bands': band, 'palette': cm.palettes.RdYlGn}, f'{date}_{band}')\n",
    "    elif band == 'BSI':\n",
    "        map_object.addLayer(image, {'min': -1, 'max': 1, 'bands': band, 'palette': cm.palettes.Greens}, f'{date}_{band}')\n",
    "\n",
    "## Function to add spectral indices images to the map.\n",
    "def add_sar_to_map(image, map_object, target_band):\n",
    "\n",
    "    date = ee.Date(image.get('date')).format('YYYY-MM-dd').getInfo()\n",
    "    map_object.addLayer(image, {'min': -50, 'max': 1, 'bands': target_band}, f'{date}_{target_band}')\n",
    "\n",
    "\n",
    "## functiont to create three important and popular spectral indices\n",
    "## ndvi = Normalized Difference Vegetation Index, good for vegetation health and cover\n",
    "## ndwi = Normalized Difference Water Index, good for identifying water bodies and mositure in surface\n",
    "def s2_10m_target_indices(image):\n",
    "    # Calculate NDVI\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    # Calculate NDWI\n",
    "    ndwi = image.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
    "    # Calculate MNDWI with SWIR1 band\n",
    "    mndwi_1 = image.normalizedDifference(['B8', 'B11']).rename('NDWI_1')\n",
    "    # Calculate MNDWI with SWIR2 band\n",
    "    mndwi_2 = image.normalizedDifference(['B8', 'B12']).rename('NDWI_2')\n",
    "\n",
    "    # Add all indices as new bands to the image\n",
    "    return image.addBands([ndvi, ndwi, mndwi_1, mndwi_2])\n",
    "\n",
    "## collects sentinel-1 GRD (radar, no phase) and Sentinel-2 SR (multispectral, adjusted for top of atmosphere reflectance)\n",
    "def get_sentinel_imagery(aoi, start_date, end_date, s2_cloud_cov, orbit):\n",
    "    ## Sentinel-1 ImageCollection\n",
    "    s1 = (ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "               .filterBounds(aoi)\n",
    "               .filterDate(ee.Date(start_date), ee.Date(end_date))\n",
    "               .map(lambda img: img.set('date', ee.Date(img.date()).format('YYYYMMdd')))\n",
    "               .filter(ee.Filter.eq('orbitProperties_pass', orbit))\n",
    "               .select(['VV', 'VH'])\n",
    "               .sort('date')\n",
    "    )\n",
    "\n",
    "    s1= s1.map(lambda img: img.clip(aoi))\n",
    "    ## Sentinel-2 Surface Reflectance Harmonized ImageCollection\n",
    "    s2_10m = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "               .filterBounds(aoi)\n",
    "               .filterDate(ee.Date(start_date), ee.Date(end_date))\n",
    "               .map(lambda img: img.set('date', ee.Date(img.date()).format('YYYYMMdd')))\n",
    "               .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', s2_cloud_cov))\n",
    "               .sort('date')\n",
    "               .select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12'])\n",
    "    )\n",
    "    ## Clip all images in the collection to the AOI\n",
    "    s2_10m = s2_10m.map(lambda img: img.clip(aoi))\n",
    "    ## Apply indices to the Sentinel-2 images\n",
    "    s2_10m_indices = s2_10m.map(s2_10m_target_indices).select(['NDVI', 'NDWI', 'MNDWI_1', 'MNDWI_2'])\n",
    "    # s2_10m_ndvi = s2_10m.map(s2_10m_target_indices).select(['NDVI'])\n",
    "    # s2_10m_ndwi = s2_10m.map(s2_10m_target_indices).select(['NDWI'])\n",
    "    # s2_10m_msavi2 = s2_10m.map(s2_10m_target_indices).select(['MSAVI2'])\n",
    "    # s2_10m_bsi = s2_10m.map(s2_10m_target_indices).select(['BSI'])\n",
    "\n",
    "    \n",
    "    # return s1_VV, s1_VH, s2_10m, s2_10m_ndvi, s2_10m_ndwi, s2_10m_msavi2, s2_10m_bsi\n",
    "    return s1, s2_10m, s2_10m_indices #s2_10m_ndvi, s2_10m_ndwi, s2_10m_msavi2, s2_10m_bsi\n",
    "\n",
    "## fucntion to get the date of each image in the image collection\n",
    "def get_date(image):\n",
    "    return ee.Feature(None, {'date': image.date().format('YYYY-MM-dd')})\n",
    "\n",
    "def glcm_texture_selected(image):\n",
    "\n",
    "    # image=image.multiply(10000).toInt32() # changes VV and VH to int32, maybe don't need this it adds additonal data manipulation that isnt needed\n",
    "\n",
    "    # # Compute GLCM texture measures with a window size (e.g., 4 pixels)\n",
    "\n",
    "\n",
    "    # Convert VV and VH bands from dB to linear scale\n",
    "    linear_vv = ee.Image.constant(10).pow(image.select('VV').divide(10))\n",
    "    linear_vh = ee.Image.constant(10).pow(image.select('VH').divide(10))\n",
    "    \n",
    "    # Optionally scale the linear values to an integer range for GLCM calculation\n",
    "    scaled_vv = linear_vv.multiply(10000).toInt32().rename('VV')\n",
    "    scaled_vh = linear_vh.multiply(10000).toInt32().rename('VH')\n",
    "    \n",
    "    # Combine the VV and VH bands into one image\n",
    "    image_int = scaled_vv.addBands(scaled_vh)\n",
    "\n",
    "\n",
    "    texture = image_int.select(['VV', 'VH']).glcmTexture(size=3)\n",
    "\n",
    "\n",
    "    # Add these metrics as new bands to the original image\n",
    "    return image.addBands(texture)\n",
    "\n",
    "def export_image_to_drive(collection, collname, image, index):\n",
    "    # Define the description for the export, incorporating the index for uniqueness\n",
    "\n",
    "    if collname == 's1':\n",
    "        description = f\"s1_{index}\"\n",
    "    elif collname == 's1_glcm':\n",
    "        description = f's1_glcm_{index}'\n",
    "    elif collname == 'rgb':\n",
    "        description = f's2_10m_{index}'\n",
    "    elif collname == 'indices':\n",
    "        description = f's2_10m_{index}'\n",
    "    elif collname == 'ndvi':\n",
    "        description = f's2_10m_ndvi_{index}'\n",
    "    else:\n",
    "        description = f's2_glcm_{index}'\n",
    "\n",
    "    # Setup the export task\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image=image,\n",
    "        description=description,\n",
    "        region=aoi,  # Make sure the geometry is defined earlier\n",
    "        fileFormat='GeoTIFF',\n",
    "        scale = 10\n",
    "    )\n",
    "    task.start()\n",
    "    print(f'Exporting {description} to Drive...')\n",
    "\n",
    "def export_all_images(collection, collname):\n",
    "    image_list = collection.toList(collection.size())  # Convert ImageCollection to List\n",
    "    num_images = image_list.size().getInfo()  # Get the number of images\n",
    "\n",
    "    if collname[:2] == 's1':\n",
    "        for i, date in enumerate(s1_date_list):\n",
    "            image = ee.Image(image_list.get(i))\n",
    "            export_image_to_drive(collection, collname, image, date[:10])\n",
    "\n",
    "    else:\n",
    "        for i, date in enumerate(s2_date_list):\n",
    "            image = ee.Image(image_list.get(i))\n",
    "            export_image_to_drive(collection, collname, image, date[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------//\n",
    "# 1.SPECKLE FILTERS\n",
    "# ---------------------------------------------------------------------------//\n",
    "\n",
    "def boxcar(image, KERNEL_SIZE):\n",
    "    \"\"\"\n",
    "    Apply boxcar filter on every image in the collection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : ee.Image\n",
    "        Image to be filtered\n",
    "    KERNEL_SIZE : positive odd integer\n",
    "        Neighbourhood window size\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ee.Image\n",
    "        Filtered Image\n",
    "\n",
    "    \"\"\"\n",
    "    bandNames = image.bandNames().remove('angle')\n",
    "      #Define a boxcar kernel\n",
    "    kernel = ee.Kernel.square((KERNEL_SIZE/2), units='pixels', normalize=True)\n",
    "     #Apply boxcar\n",
    "    output = image.select(bandNames).convolve(kernel).rename(bandNames)\n",
    "    return image.addBands(output, None, True)\n",
    "\n",
    "def leefilter(image, KERNEL_SIZE):\n",
    "    \"\"\"\n",
    "    Lee Filter applied to one image.\n",
    "    It is implemented as described in\n",
    "    J. S. Lee, “Digital image enhancement and noise filtering by use of local statistics,”\n",
    "    IEEE Pattern Anal. Machine Intell., vol. PAMI-2, pp. 165–168, Mar. 1980.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : ee.Image\n",
    "        Image to be filtered\n",
    "    KERNEL_SIZE : positive odd integer\n",
    "        Neighbourhood window size\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ee.Image\n",
    "        Filtered Image\n",
    "\n",
    "    \"\"\"\n",
    "    bandNames = image.bandNames().remove('angle')\n",
    "\n",
    "    # S1-GRD images are multilooked 5 times in range\n",
    "    enl = 5\n",
    "    # Compute the speckle standard deviation\n",
    "    eta = 1.0/math.sqrt(enl)\n",
    "    eta = ee.Image.constant(eta)\n",
    "\n",
    "    # MMSE estimator\n",
    "    # Neighbourhood mean and variance\n",
    "    oneImg = ee.Image.constant(1)\n",
    "    # Estimate stats\n",
    "    reducers = ee.Reducer.mean().combine(\n",
    "                      reducer2= ee.Reducer.variance()\n",
    "                      ,sharedInputs= True\n",
    "                      )\n",
    "    stats = (image.select(bandNames).reduceNeighborhood(\n",
    "                      reducer= reducers\n",
    "                          ,kernel= ee.Kernel.square(KERNEL_SIZE/2, 'pixels')\n",
    "                              ,optimization= 'window'))\n",
    "    meanBand = bandNames.map(lambda bandName: ee.String(bandName).cat('_mean'))\n",
    "    varBand = bandNames.map(lambda bandName:  ee.String(bandName).cat('_variance'))\n",
    "\n",
    "    z_bar = stats.select(meanBand)\n",
    "    varz = stats.select(varBand)\n",
    "    # Estimate weight \n",
    "    varx = (varz.subtract(z_bar.pow(2).multiply(eta.pow(2)))).divide(oneImg.add(eta.pow(2)))\n",
    "    b = varx.divide(varz)\n",
    "  \n",
    "    # if b is negative set it to zero\n",
    "    new_b = b.where(b.lt(0), 0)\n",
    "    output = oneImg.subtract(new_b).multiply(z_bar.abs()).add(new_b.multiply(image.select(bandNames)))\n",
    "    output = output.rename(bandNames)\n",
    "    return image.addBands(output, None, True)\n",
    "\n",
    "\n",
    "def gammamap(image,KERNEL_SIZE): \n",
    "    \n",
    "    \"\"\"\n",
    "    Gamma Maximum a-posterior Filter applied to one image. It is implemented as described in \n",
    "    Lopes A., Nezry, E., Touzi, R., and Laur, H., 1990.  \n",
    "    Maximum A Posteriori Speckle Filtering and First Order texture Models in SAR Images.  \n",
    "    International  Geoscience  and  Remote  Sensing  Symposium (IGARSS).\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : ee.Image\n",
    "        Image to be filtered\n",
    "    KERNEL_SIZE : positive odd integer\n",
    "        Neighbourhood window size\n",
    "    Returns\n",
    "    -------\n",
    "    ee.Image\n",
    "        Filtered Image\n",
    "    \"\"\"\n",
    "    enl = 5\n",
    "    bandNames = image.bandNames().remove('angle')\n",
    "    #local mean\n",
    "    reducers = ee.Reducer.mean().combine( \\\n",
    "                      reducer2= ee.Reducer.stdDev(), \\\n",
    "                      sharedInputs= True\n",
    "                      )\n",
    "    stats = (image.select(bandNames).reduceNeighborhood( \\\n",
    "                      reducer= reducers, \\\n",
    "                          kernel= ee.Kernel.square(KERNEL_SIZE/2,'pixels'), \\\n",
    "                              optimization= 'window'))\n",
    "    meanBand = bandNames.map(lambda bandName: ee.String(bandName).cat('_mean'))\n",
    "    stdDevBand = bandNames.map(lambda bandName:  ee.String(bandName).cat('_stdDev'))\n",
    "        \n",
    "    z = stats.select(meanBand)\n",
    "    sigz = stats.select(stdDevBand)\n",
    "    \n",
    "    #local observed coefficient of variation\n",
    "    ci = sigz.divide(z)\n",
    "    #noise coefficient of variation (or noise sigma)\n",
    "    cu = 1.0/math.sqrt(enl)\n",
    "    #threshold for the observed coefficient of variation\n",
    "    cmax = math.sqrt(2.0) * cu\n",
    "    cu = ee.Image.constant(cu)\n",
    "    cmax = ee.Image.constant(cmax)\n",
    "    enlImg = ee.Image.constant(enl)\n",
    "    oneImg = ee.Image.constant(1)\n",
    "    twoImg = ee.Image.constant(2)\n",
    "\n",
    "    alpha = oneImg.add(cu.pow(2)).divide(ci.pow(2).subtract(cu.pow(2)))\n",
    "\n",
    "    #Implements the Gamma MAP filter described in equation 11 in Lopez et al. 1990\n",
    "    q = image.select(bandNames).expression('z**2 * (z * alpha - enl - 1)**2 + 4 * alpha * enl * b() * z', { 'z': z,  'alpha':alpha,'enl': enl})\n",
    "    rHat = z.multiply(alpha.subtract(enlImg).subtract(oneImg)).add(q.sqrt()).divide(twoImg.multiply(alpha))\n",
    "  \n",
    "    #if ci <= cu then its a homogenous region ->> boxcar filter\n",
    "    zHat = (z.updateMask(ci.lte(cu))).rename(bandNames)\n",
    "    #if cmax > ci > cu then its a textured medium ->> apply Gamma MAP filter\n",
    "    rHat = (rHat.updateMask(ci.gt(cu)).updateMask(ci.lt(cmax))).rename(bandNames)\n",
    "    #ci>cmax then its strong signal ->> retain\n",
    "    x = image.select(bandNames).updateMask(ci.gte(cmax)).rename(bandNames)  \n",
    "    #Merge\n",
    "    output = ee.ImageCollection([zHat,rHat,x]).sum()\n",
    "    return image.addBands(output, None, True)\n",
    "\n",
    "def RefinedLee(image):\n",
    "    \"\"\"\n",
    "    This filter is modified from the implementation by Guido Lemoine \n",
    "    Source: Lemoine et al. https://code.earthengine.google.com/5d1ed0a0f0417f098fdfd2fa137c3d0c\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: ee.Image\n",
    "        Image to be filtered\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: ee.Image\n",
    "        Filtered Image\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    bandNames = image.bandNames().remove('angle')\n",
    "\n",
    "    def inner(b):\n",
    "\n",
    "        img = image.select([b]);\n",
    "    \n",
    "        # img must be linear, i.e. not in dB!\n",
    "        # Set up 3x3 kernels \n",
    "        weights3 = ee.List.repeat(ee.List.repeat(1,3),3);\n",
    "        kernel3 = ee.Kernel.fixed(3,3, weights3, 1, 1, False);\n",
    "  \n",
    "        mean3 = img.reduceNeighborhood(ee.Reducer.mean(), kernel3);\n",
    "        variance3 = img.reduceNeighborhood(ee.Reducer.variance(), kernel3);\n",
    "  \n",
    "        # Use a sample of the 3x3 windows inside a 7x7 windows to determine gradients and directions\n",
    "        sample_weights = ee.List([[0,0,0,0,0,0,0], [0,1,0,1,0,1,0],[0,0,0,0,0,0,0], [0,1,0,1,0,1,0], [0,0,0,0,0,0,0], [0,1,0,1,0,1,0],[0,0,0,0,0,0,0]]);\n",
    "  \n",
    "        sample_kernel = ee.Kernel.fixed(7,7, sample_weights, 3,3, False);\n",
    "  \n",
    "        # Calculate mean and variance for the sampled windows and store as 9 bands\n",
    "        sample_mean = mean3.neighborhoodToBands(sample_kernel); \n",
    "        sample_var = variance3.neighborhoodToBands(sample_kernel);\n",
    "  \n",
    "        # Determine the 4 gradients for the sampled windows\n",
    "        gradients = sample_mean.select(1).subtract(sample_mean.select(7)).abs();\n",
    "        gradients = gradients.addBands(sample_mean.select(6).subtract(sample_mean.select(2)).abs());\n",
    "        gradients = gradients.addBands(sample_mean.select(3).subtract(sample_mean.select(5)).abs());\n",
    "        gradients = gradients.addBands(sample_mean.select(0).subtract(sample_mean.select(8)).abs());\n",
    "  \n",
    "        # And find the maximum gradient amongst gradient bands\n",
    "        max_gradient = gradients.reduce(ee.Reducer.max());\n",
    "  \n",
    "        # Create a mask for band pixels that are the maximum gradient\n",
    "        gradmask = gradients.eq(max_gradient);\n",
    "  \n",
    "        # duplicate gradmask bands: each gradient represents 2 directions\n",
    "        gradmask = gradmask.addBands(gradmask);\n",
    "  \n",
    "        # Determine the 8 directions\n",
    "        directions = sample_mean.select(1).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(7))).multiply(1);\n",
    "        directions = directions.addBands(sample_mean.select(6).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(2))).multiply(2));\n",
    "        directions = directions.addBands(sample_mean.select(3).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(5))).multiply(3));\n",
    "        directions = directions.addBands(sample_mean.select(0).subtract(sample_mean.select(4)).gt(sample_mean.select(4).subtract(sample_mean.select(8))).multiply(4));\n",
    "        # The next 4 are the not() of the previous 4\n",
    "        directions = directions.addBands(directions.select(0).Not().multiply(5));\n",
    "        directions = directions.addBands(directions.select(1).Not().multiply(6));\n",
    "        directions = directions.addBands(directions.select(2).Not().multiply(7));\n",
    "        directions = directions.addBands(directions.select(3).Not().multiply(8));\n",
    "  \n",
    "        # Mask all values that are not 1-8\n",
    "        directions = directions.updateMask(gradmask);\n",
    "  \n",
    "        # \"collapse\" the stack into a singe band image (due to masking, each pixel has just one value (1-8) in it's directional band, and is otherwise masked)\n",
    "        directions = directions.reduce(ee.Reducer.sum());  \n",
    "  \n",
    "        sample_stats = sample_var.divide(sample_mean.multiply(sample_mean));\n",
    "  \n",
    "        #Calculate localNoiseVariance\n",
    "        sigmaV = sample_stats.toArray().arraySort().arraySlice(0,0,5).arrayReduce(ee.Reducer.mean(), [0]);\n",
    "  \n",
    "        # Set up the 7*7 kernels for directional statistics\n",
    "        rect_weights = ee.List.repeat(ee.List.repeat(0,7),3).cat(ee.List.repeat(ee.List.repeat(1,7),4));\n",
    "  \n",
    "        diag_weights = ee.List([[1,0,0,0,0,0,0], [1,1,0,0,0,0,0], [1,1,1,0,0,0,0], [1,1,1,1,0,0,0], [1,1,1,1,1,0,0], [1,1,1,1,1,1,0], [1,1,1,1,1,1,1]]);\n",
    "  \n",
    "        rect_kernel = ee.Kernel.fixed(7,7, rect_weights, 3, 3, False);\n",
    "        diag_kernel = ee.Kernel.fixed(7,7, diag_weights, 3, 3, False);\n",
    "  \n",
    "        # Create stacks for mean and variance using the original kernels. Mask with relevant direction.\n",
    "        dir_mean = img.reduceNeighborhood(ee.Reducer.mean(), rect_kernel).updateMask(directions.eq(1));\n",
    "        dir_var = img.reduceNeighborhood(ee.Reducer.variance(), rect_kernel).updateMask(directions.eq(1));\n",
    "  \n",
    "        dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), diag_kernel).updateMask(directions.eq(2)));\n",
    "        dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), diag_kernel).updateMask(directions.eq(2)));\n",
    "  \n",
    "        # and add the bands for rotated kernels\n",
    "        for i in range(1, 4):\n",
    "            dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), rect_kernel.rotate(i)).updateMask(directions.eq(2*i+1)))\n",
    "            dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), rect_kernel.rotate(i)).updateMask(directions.eq(2*i+1)))\n",
    "            dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), diag_kernel.rotate(i)).updateMask(directions.eq(2*i+2)))\n",
    "            dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), diag_kernel.rotate(i)).updateMask(directions.eq(2*i+2)))\n",
    "\n",
    "  \n",
    "        # \"collapse\" the stack into a single band image (due to masking, each pixel has just one value in it's directional band, and is otherwise masked)\n",
    "        dir_mean = dir_mean.reduce(ee.Reducer.sum());\n",
    "        dir_var = dir_var.reduce(ee.Reducer.sum());\n",
    "  \n",
    "        # A finally generate the filtered value\n",
    "        varX = dir_var.subtract(dir_mean.multiply(dir_mean).multiply(sigmaV)).divide(sigmaV.add(1.0))\n",
    "  \n",
    "        b = varX.divide(dir_var)\n",
    "        result = dir_mean.add(b.multiply(img.subtract(dir_mean)))\n",
    "  \n",
    "        return result.arrayProject([0]).arrayFlatten([['sum']]).float()\n",
    "    \n",
    "    result = ee.ImageCollection(bandNames.map(inner)).toBands().rename(bandNames).copyProperties(image)\n",
    "    \n",
    "    return image.addBands(result, None, True) \n",
    "\n",
    "\n",
    "\n",
    "def leesigma(image,KERNEL_SIZE):\n",
    "    \"\"\"\n",
    "    Implements the improved lee sigma filter to one image. \n",
    "    It is implemented as described in, Lee, J.-S. Wen, J.-H. Ainsworth, T.L. Chen, K.-S. Chen, A.J. \n",
    "    Improved sigma filter for speckle filtering of SAR imagery. \n",
    "    IEEE Trans. Geosci. Remote Sens. 2009, 47, 202–213.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : ee.Image\n",
    "        Image to be filtered\n",
    "    KERNEL_SIZE : positive odd integer\n",
    "        Neighbourhood window size\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ee.Image\n",
    "        Filtered Image\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #parameters\n",
    "    Tk = ee.Image.constant(7) #number of bright pixels in a 3x3 window\n",
    "    sigma = 0.9\n",
    "    enl = 4\n",
    "    target_kernel = 3\n",
    "    bandNames = image.bandNames().remove('angle')\n",
    "  \n",
    "    #compute the 98 percentile intensity \n",
    "    z98 = ee.Dictionary(image.select(bandNames).reduceRegion(\n",
    "                reducer= ee.Reducer.percentile([98]),\n",
    "                geometry= image.geometry(),\n",
    "                scale=10,\n",
    "                maxPixels=1e13\n",
    "            )).toImage()\n",
    "  \n",
    "\n",
    "    #select the strong scatterers to retain\n",
    "    brightPixel = image.select(bandNames).gte(z98)\n",
    "    K = brightPixel.reduceNeighborhood(ee.Reducer.countDistinctNonNull()\n",
    "            ,ee.Kernel.square(target_kernel/2)) \n",
    "    retainPixel = K.gte(Tk)\n",
    "  \n",
    "  \n",
    "    #compute the a-priori mean within a 3x3 local window\n",
    "    #original noise standard deviation since the data is 5 look\n",
    "    eta = 1.0/math.sqrt(enl) \n",
    "    eta = ee.Image.constant(eta)\n",
    "    #MMSE applied to estimate the apriori mean\n",
    "    reducers = ee.Reducer.mean().combine( \\\n",
    "                      reducer2= ee.Reducer.variance(), \\\n",
    "                      sharedInputs= True\n",
    "                      )\n",
    "    stats = image.select(bandNames).reduceNeighborhood( \\\n",
    "                      reducer= reducers, \\\n",
    "                          kernel= ee.Kernel.square(target_kernel/2,'pixels'), \\\n",
    "                              optimization= 'window')\n",
    "    meanBand = bandNames.map(lambda bandName: ee.String(bandName).cat('_mean'))\n",
    "    varBand = bandNames.map(lambda bandName:  ee.String(bandName).cat('_variance'))\n",
    "        \n",
    "    z_bar = stats.select(meanBand)\n",
    "    varz = stats.select(varBand)\n",
    "    \n",
    "    oneImg = ee.Image.constant(1)\n",
    "    varx = (varz.subtract(z_bar.abs().pow(2).multiply(eta.pow(2)))).divide(oneImg.add(eta.pow(2)))\n",
    "    b = varx.divide(varz)\n",
    "    xTilde = oneImg.subtract(b).multiply(z_bar.abs()).add(b.multiply(image.select(bandNames)))\n",
    "  \n",
    "    #step 3: compute the sigma range\n",
    "    #Lookup table (J.S.Lee et al 2009) for range and eta values for intensity (only 4 look is shown here)\n",
    "    LUT = ee.Dictionary({0.5: ee.Dictionary({'I1': 0.694,'I2': 1.385,'eta': 0.1921}),\n",
    "                                 0.6: ee.Dictionary({'I1': 0.630,'I2': 1.495,'eta': 0.2348}),\n",
    "                                 0.7: ee.Dictionary({'I1': 0.560,'I2': 1.627,'eta': 0.2825}),\n",
    "                                 0.8: ee.Dictionary({'I1': 0.480,'I2': 1.804,'eta': 0.3354}),\n",
    "                                 0.9: ee.Dictionary({'I1': 0.378,'I2': 2.094,'eta': 0.3991}),\n",
    "                                 0.95: ee.Dictionary({'I1': 0.302,'I2': 2.360,'eta': 0.4391})});\n",
    "  \n",
    "    #extract data from lookup\n",
    "    sigmaImage = ee.Dictionary(LUT.get(str(sigma))).toImage()\n",
    "    I1 = sigmaImage.select('I1')\n",
    "    I2 = sigmaImage.select('I2')\n",
    "    #new speckle sigma\n",
    "    nEta = sigmaImage.select('eta')\n",
    "    #establish the sigma ranges\n",
    "    I1 = I1.multiply(xTilde)\n",
    "    I2 = I2.multiply(xTilde)\n",
    "  \n",
    "    #step 3: apply MMSE filter for pixels in the sigma range\n",
    "    #MMSE estimator\n",
    "    mask = image.select(bandNames).gte(I1).Or(image.select(bandNames).lte(I2))\n",
    "    z = image.select(bandNames).updateMask(mask)\n",
    "  \n",
    "    stats = z.reduceNeighborhood( \\\n",
    "                      reducer= reducers, \\\n",
    "                          kernel= ee.Kernel.square(KERNEL_SIZE/2,'pixels'), \\\n",
    "                              optimization= 'window')\n",
    "        \n",
    "    z_bar = stats.select(meanBand)\n",
    "    varz = stats.select(varBand)\n",
    "    \n",
    "    \n",
    "    varx = (varz.subtract(z_bar.abs().pow(2).multiply(nEta.pow(2)))).divide(oneImg.add(nEta.pow(2)))\n",
    "    b = varx.divide(varz)\n",
    "    #if b is negative set it to zero\n",
    "    new_b = b.where(b.lt(0), 0)\n",
    "    xHat = oneImg.subtract(new_b).multiply(z_bar.abs()).add(new_b.multiply(z))\n",
    "  \n",
    "    #remove the applied masks and merge the retained pixels and the filtered pixels\n",
    "    xHat = image.select(bandNames).updateMask(retainPixel).unmask(xHat)\n",
    "    output = ee.Image(xHat).rename(bandNames)\n",
    "    return image.addBands(output, None, True)\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------//\n",
    "# 2. MONO-TEMPORAL SPECKLE FILTER (WRAPPER)\n",
    "#---------------------------------------------------------------------------//\n",
    "\n",
    "\n",
    "def MonoTemporal_Filter(coll,KERNEL_SIZE, SPECKLE_FILTER) :\n",
    "    \"\"\"\n",
    "    A wrapper function for monotemporal filter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coll : ee Image collection\n",
    "        the image collection to be filtered\n",
    "    KERNEL_SIZE : odd integer\n",
    "        Spatial Neighbourhood window\n",
    "    SPECKLE_FILTER : String\n",
    "        Type of speckle filter\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ee.ImageCollection\n",
    "        An image collection where a mono-temporal filter is applied to each \n",
    "        image individually\n",
    "\n",
    "    \"\"\"\n",
    "    def _filter(image):    \n",
    "       if (SPECKLE_FILTER=='BOXCAR'):\n",
    "          _filtered = boxcar(image, KERNEL_SIZE)\n",
    "       elif (SPECKLE_FILTER=='LEE'):\n",
    "          _filtered = leefilter(image, KERNEL_SIZE)\n",
    "       elif (SPECKLE_FILTER=='GAMMA MAP'):\n",
    "          _filtered = gammamap(image, KERNEL_SIZE)\n",
    "       elif (SPECKLE_FILTER=='REFINED LEE'):\n",
    "          _filtered = RefinedLee(image)\n",
    "       elif (SPECKLE_FILTER=='LEE SIGMA'):\n",
    "          _filtered = leesigma(image, KERNEL_SIZE)\n",
    "       return _filtered\n",
    "    return coll.map(_filter)\n",
    "\n",
    "# ---------------------------------------------------------------------------//\n",
    "# 3. MULTI-TEMPORAL SPECKLE FILTER\n",
    "# ---------------------------------------------------------------------------//\n",
    "\n",
    "def MultiTemporal_Filter(coll,KERNEL_SIZE, SPECKLE_FILTER,NR_OF_IMAGES):\n",
    "    \"\"\"\n",
    "\n",
    "    A wrapper function for multi-temporal filter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    coll : ee Image collection\n",
    "        the image collection to be filtered\n",
    "    KERNEL_SIZE : odd integer\n",
    "        Spatial Neighbourhood window\n",
    "    SPECKLE_FILTER : String\n",
    "        Type of speckle filter\n",
    "    NR_OF_IMAGES : positive integer\n",
    "        Number of images to use in multi-temporal filtering\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ee.ImageCollection\n",
    "        An image collection where a multi-temporal filter is applied to each\n",
    "        image individually\n",
    "\n",
    "    \"\"\"\n",
    "  \n",
    "    def Quegan(image) :\n",
    "        \"\"\"\n",
    "        The following Multi-temporal speckle filters are implemented as described in\n",
    "        S. Quegan and J. J. Yu, “Filtering of multichannel SAR images,” \n",
    "        IEEE Trans Geosci. Remote Sensing, vol. 39, Nov. 2001.\n",
    "        \n",
    "        this function will filter the collection used for the multi-temporal part\n",
    "        it takes care of:\n",
    "        - same image geometry (i.e relative orbit)\n",
    "        - full overlap of image\n",
    "        - amount of images taken for filtering \n",
    "            -- all before\n",
    "           -- if not enough, images taken after the image to filter are added\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image : ee.Image\n",
    "            Image to be filtered\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ee.Image\n",
    "            Filtered image\n",
    "\n",
    "        \"\"\"\n",
    "        def setresample(image):\n",
    "                return image.resample()\n",
    "            \n",
    "        def get_filtered_collection(image):\n",
    "            \"\"\"\n",
    "            Generate a dedicated image collection\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            image : ee.Image\n",
    "                Image whose geometry is used to define the new collection\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            ee Image collection\n",
    "\n",
    "            \"\"\"\n",
    "  \n",
    "            #filter collection over are and by relative orbit\n",
    "            s1_coll = ee.ImageCollection('COPERNICUS/S1_GRD_FLOAT') \\\n",
    "                .filterBounds(image.geometry()) \\\n",
    "                .filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n",
    "                .filter(ee.Filter.listContains('transmitterReceiverPolarisation', ee.List(image.get('transmitterReceiverPolarisation')).get(-1))) \\\n",
    "                .filter(ee.Filter.Or(ee.Filter.eq('relativeOrbitNumber_stop', image.get('relativeOrbitNumber_stop')), \\\n",
    "                                     ee.Filter.eq('relativeOrbitNumber_stop', image.get('relativeOrbitNumber_start'))\n",
    "                )).map(setresample)\n",
    "      \n",
    "            #a function that takes the image and checks for the overlap\n",
    "            def check_overlap(_image):\n",
    "                \"\"\"\n",
    "                get all S1 frames from this date intersecting with the image bounds\n",
    "\n",
    "                Parameters\n",
    "                ----------\n",
    "                _image : ee.Image\n",
    "                    Image to check the overlap with\n",
    "\n",
    "                Returns\n",
    "                -------\n",
    "                ee Image Collection\n",
    "                    A collection with matching geometry\n",
    "\n",
    "                \"\"\"\n",
    "                \n",
    "                # get all S1 frames from this date intersecting with the image bounds\n",
    "                s1 = s1_coll.filterDate(_image.date(), _image.date().advance(1, 'day'))\n",
    "                # intersect those images with the image to filter\n",
    "                intersect = image.geometry().intersection(s1.geometry().dissolve(), 10)\n",
    "                # check if intersect is sufficient\n",
    "                valid_date = ee.Algorithms.If(intersect.area(10).divide(image.geometry().area(10)).gt(0.95), \\\n",
    "                                              _image.date().format('YYYY-MM-dd')\n",
    "                                              )\n",
    "                return ee.Feature(None, {'date': valid_date})\n",
    "      \n",
    "      \n",
    "            # this function will pick up the acq dates for fully overlapping acquisitions before the image acquistion\n",
    "            dates_before = s1_coll.filterDate('2014-01-01', image.date().advance(1, 'day')) \\\n",
    "                                    .sort('system:time_start', False).limit(5*NR_OF_IMAGES) \\\n",
    "                                    .map(check_overlap).distinct('date').aggregate_array('date')\n",
    "    \n",
    "            # if the images before are not enough, we add images from after the image acquisition \n",
    "            # this will only be the case at the beginning of S1 mission\n",
    "            dates = ee.List(ee.Algorithms.If( \\\n",
    "                                             dates_before.size().gte(NR_OF_IMAGES), \\\n",
    "                                                 dates_before.slice(0, NR_OF_IMAGES), \\\n",
    "                                                     s1_coll \\\n",
    "                                                         .filterDate(image.date(), '2100-01-01') \\\n",
    "                                                             .sort('system:time_start', True).limit(5*NR_OF_IMAGES) \\\n",
    "                                                                 .map(check_overlap) \\\n",
    "                                                                     .distinct('date') \\\n",
    "                                                                         .aggregate_array('date') \\\n",
    "                                                                             .cat(dates_before).distinct().sort().slice(0, NR_OF_IMAGES)\n",
    "                                                                             )\n",
    "                                                )\n",
    "    \n",
    "            #now we re-filter the collection to get the right acquisitions for multi-temporal filtering\n",
    "            return ee.ImageCollection(dates.map(lambda date: s1_coll.filterDate(date, ee.Date(date).advance(1,'day')).toList(s1_coll.size())).flatten())\n",
    "      \n",
    "          \n",
    "  \n",
    "        #we get our dedicated image collection for that image\n",
    "        s1 = get_filtered_collection(image)\n",
    "  \n",
    "        bands = image.bandNames().remove('angle')\n",
    "        s1 = s1.select(bands)\n",
    "        meanBands = bands.map(lambda bandName: ee.String(bandName).cat('_mean'))\n",
    "        ratioBands = bands.map(lambda bandName: ee.String(bandName).cat('_ratio'))\n",
    "        count_img = s1.reduce(ee.Reducer.count())\n",
    "\n",
    "        def inner(image):\n",
    "            \"\"\"\n",
    "            Creats an image whose bands are the filtered image and image ratio\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            image : ee.Image\n",
    "                Image to be filtered\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            ee.Image\n",
    "                Filtered image and image ratio\n",
    "\n",
    "            \"\"\"\n",
    "            if (SPECKLE_FILTER=='BOXCAR'):\n",
    "                _filtered = boxcar(image, KERNEL_SIZE).select(bands).rename(meanBands) \n",
    "            elif (SPECKLE_FILTER=='LEE'):\n",
    "                _filtered = leefilter(image, KERNEL_SIZE).select(bands).rename(meanBands)\n",
    "            elif (SPECKLE_FILTER=='GAMMA MAP'):\n",
    "                _filtered = gammamap(image, KERNEL_SIZE).select(bands).rename(meanBands)\n",
    "            elif (SPECKLE_FILTER=='REFINED LEE'):\n",
    "                _filtered = RefinedLee(image).select(bands).rename(meanBands)\n",
    "            elif (SPECKLE_FILTER=='LEE SIGMA'):\n",
    "                _filtered = leesigma(image, KERNEL_SIZE).select(bands).rename(meanBands)\n",
    "    \n",
    "            _ratio = image.select(bands).divide(_filtered).rename(ratioBands) \n",
    "            return _filtered.addBands(_ratio)\n",
    "\n",
    "        isum = s1.map(inner).select(ratioBands).reduce(ee.Reducer.sum())\n",
    "        filtered = inner(image).select(meanBands)\n",
    "        divide = filtered.divide(count_img)\n",
    "        output = divide.multiply(isum).rename(bands)\n",
    "\n",
    "        return image.addBands(output, None, True)\n",
    "    return coll.map(Quegan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, establish the project path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = '/home/wcc/Desktop/SabineRS/Sentinel-1/InSAR/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get area of interest\n",
    "1. Sabine National Wildlife Refuge (Louisiana) -- Gulf Coast\n",
    "2. Deer Island (Mississippi) -- Gulf Coast\n",
    "3. SMIIL (New Jersey) -- East Coast\n",
    "4. Poplar Island (Maryland) -- East Coast\n",
    "5. South Bay Salt Pond Restoration (California) -- West Coast\n",
    "6. Niaqually National Wildlife Refuge (Washington) -- West Coast\n",
    "7. Kachemak Bay National Estuarine Research Researve (Alaska) -- Arctic \n",
    "8. Mendenhall Wetlands (Alaska) -- Arctic\n",
    "\n",
    "Going to look for sites on the EWN as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using the dem like below, I will just use an initial unwrapped geocoded ifg from the baseline. Load it here using rasterio and extract the bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_phase = os.path.join(work_dir, 'interferometry/work/merged/filt_topophase.flat.geo.vrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dem = [f for f in os.listdir(os.path.join(work_dir, 'interferometry/work')) if f.endswith('.unw.geo')][0]\n",
    "with rasterio.open(w_phase) as src:\n",
    "    bounds = src.bounds\n",
    "    bbox = [bounds.bottom, bounds.top, bounds.left, bounds.right]\n",
    "    aoi = ee.Geometry.Rectangle([bbox[2], bbox[0], bbox[3], bbox[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2020-01-01' ## start date of search window\n",
    "end_date = '2024-11-14' ## end date of search window\n",
    "s2_cloud_cov = 1 ## percentage of clouds in sentinel-2 multispectral imagery, less means you see more surface\n",
    "orbit = 'ASCENDING' ## orbit for imagery\n",
    "\n",
    "collections = {}\n",
    "for i in range(int(start_date[:4]), int(end_date[:4])):\n",
    "    # collections[f's1_{i}_{i+1}'], collections[f's2_10m_{i}_{i+1}'], collections[f's2_10m_ndvi_{i}_{i+1}'], collections[f's2_10m_ndwi_{i}_{i+1}'], collections[f's2_10m_msavi2_{i}_{i+1}'], collections[f's2_10m_bsi_{i}_{i+1}']  = get_sentinel_imagery(aoi, f'{i}{start_date[4:]}', f'{i+1}{end_date[4:]}', s2_cloud_cov, orbit)\n",
    "    collections[f's1_{i}_{i+1}'], collections[f's2_10m_{i}_{i+1}'], collections[f's2_10m_indices_{i}_{i+1}'] = get_sentinel_imagery(aoi, f'{i}{start_date[4:]}', f'{i+1}{end_date[4:]}', s2_cloud_cov, orbit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_colls = {}\n",
    "# total_colls['s1'], total_colls['s2_10m'], total_colls['s2_10m_ndvi'], total_colls['s2_10m_ndwi'], total_colls['s2_10m_msavi2'], total_colls['s2_10m_bsi']= get_sentinel_imagery(aoi, start_date, end_date, s2_cloud_cov, orbit)\n",
    "total_colls['s1'], total_colls['s2_10m'], total_colls['s2_10m_indices']= get_sentinel_imagery(aoi, start_date, end_date, s2_cloud_cov, orbit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colls = []\n",
    "for i, coll in enumerate(collections):\n",
    "    if collections[coll].size().getInfo() != 0: # removes image collections that are empty\n",
    "        colls.append(coll)\n",
    "\n",
    "for i, coll in enumerate(colls):\n",
    "    print(f'{i}: {coll}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply speckle filtering to the Sentinel-1 Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monotemporal\n",
    "# filters based on images of a single image\n",
    "s1monofilt = MonoTemporal_Filter(total_colls['s1'], 5, 'REFINED LEE')\n",
    "\n",
    "# Multitemporal\n",
    "# filters based on the pixels in each image of the entire image collection\n",
    "# s1multifilt = MultiTemporal_Filter(total_colls['s1'], 3, 'GAMMA MAP', total_colls['s1'].size().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get GLCM Texture Features for Sentinel-1 VV and VH bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_glcm_bands = ['VV_contrast', 'VV_diss', 'VV_corr', 'VV_ent',\n",
    "                 'VH_contrast', 'VH_diss', 'VH_corr', 'VH_ent']\n",
    "\n",
    "# Apply the function to the im collection\n",
    "# s1_glcm = total_colls['s1'].map(glcm_texture_selected).select(s1_glcm_bands)\n",
    "s1_filt_glcm = s1monofilt.map(glcm_texture_selected).select(s1_glcm_bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a large mode image for the entire time series\n",
    "- this will be used in a similar fashion as the land area change\n",
    "- that is, use the NIR, SWIR bands, NDVI, NDWI, and MNDWI from the SWIR bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watermask = collections[colls[1]].reduce(ee.Reducer.mode())\n",
    "\n",
    "map = geemap.Map()\n",
    "map.centerObject(aoi, 12)\n",
    "\n",
    "map.addLayer(watermask, {'min': 0, 'max': 2000, 'bands': ['B4_mode', 'B3_mode', 'B2_mode']}, f'mode_rgb')\n",
    "map.addLayer(aoi)\n",
    "\n",
    "\n",
    "map.addLayerControl(position='topleft')\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = ee.batch.Export.image.toDrive(\n",
    "    image=watermask,\n",
    "    description='ModeImage',\n",
    "    fileNamePrefix='mode_image',\n",
    "    region=aoi.getInfo()['coordinates'],\n",
    "    scale=10,  # Adjust resolution (meters)\n",
    "    maxPixels=1e13\n",
    ")\n",
    "task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections[colls[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####rgb map####\n",
    "\n",
    "Map = geemap.Map()\n",
    "Map.centerObject(aoi, 12)\n",
    "\n",
    "# Visualize each image in the ImageCollection.\n",
    "s2_images = collections[colls[1]].toList(collections[colls[1]].size())\n",
    "for i in [20, 21, 22, 23]:\n",
    "    image = ee.Image(s2_images.get(i))\n",
    "    add_rgb_to_map(image, Map)\n",
    "\n",
    "# Display the map.\n",
    "Map.addLayerControl(position = 'topright')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map_sar_vv = geemap.Map()\n",
    "Map_sar_vv.centerObject(aoi, 12)\n",
    "\n",
    "# Visualize each image in the ImageCollection.\n",
    "s1_images = collections[colls[3]].toList(collections[colls[3]].size())\n",
    "for i in range(collections[colls[3]].size().getInfo()//40):\n",
    "    image = ee.Image(s1_images.get(i))\n",
    "    add_sar_to_map(image, Map_sar_vv, 'VV')\n",
    "\n",
    "# Display the map.\n",
    "Map_sar_vv.addLayerControl(position = 'topright')\n",
    "Map_sar_vv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map_sar = geemap.Map()\n",
    "Map_sar.centerObject(aoi, 12)\n",
    "\n",
    "# Visualize each image in the ImageCollection.\n",
    "s1_images = s1monofilt.toList(s1monofilt.size())\n",
    "for i in range(s1monofilt.size().getInfo()//40):\n",
    "    image = ee.Image(s1_images.get(i))\n",
    "    add_sar_to_map(image, Map_sar, 'VH')\n",
    "\n",
    "# Display the map.\n",
    "Map_sar.addLayerControl(position = 'topright')\n",
    "Map_sar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map_ind = geemap.Map()\n",
    "\n",
    "# Visualize each image in the ImageCollection.\n",
    "s2ind_images = collections[colls[3]].toList(collections[colls[3]].size())\n",
    "for i in range(collections[colls[3]].size().getInfo()//2):\n",
    "    image = ee.Image(s2ind_images.get(i))\n",
    "    add_ind_to_map(image, Map_ind, collections[colls[3]])\n",
    "\n",
    "# Display the map.\n",
    "Map_ind.addLayerControl(position = 'topright')\n",
    "Map_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map_ind = geemap.Map()\n",
    "\n",
    "# Visualize each image in the ImageCollection.\n",
    "s2ind_images = collections[colls[4]].toList(collections[colls[4]].size())\n",
    "for i in range(collections[colls[4]].size().getInfo()//2):\n",
    "    image = ee.Image(s2ind_images.get(i))\n",
    "    add_ind_to_map(image, Map_ind, collections[colls[4]])\n",
    "\n",
    "# Display the map.\n",
    "Map_ind.addLayerControl(position = 'topright')\n",
    "Map_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export imagery to google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_date_list = total_colls['s2_10m'].map(get_date).aggregate_array('date').getInfo()\n",
    "export_all_images(total_colls['s2_10m'], 'rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_date_list = s1monofilt.map(get_date).aggregate_array('date').getInfo()\n",
    "export_all_images(s1monofilt, 's1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_date_list = s1_filt_glcm.map(get_date).aggregate_array('date').getInfo()\n",
    "export_all_images(s1_filt_glcm, 's1_glcm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
