{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for implementing ISCE2 interferometry to form Interferograms, and MintPy SBAS Time-Series analysis\n",
    "This notebook will:\n",
    "1. Find scenes from ASF Vertex using the asf_search library\n",
    "2. Download said scenes\n",
    "3. Use scenes to form interferograms using ISCE2\n",
    "4. Utilize the closure phase to improve phase unwrapping\n",
    "5. Create SBAS Time-Series of deformation using the closure phase corrected interferograms\n",
    "6. Relate non-zero closure phase to surface vegatation and mositure changes using NDVI and EO moisture products\n",
    "7. Report on erosion driver events and show relation to deformation and insar velocity from corrected SBAS time-series "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-DO\n",
    "1. Get notebook working first with manually installed SLC images\n",
    "2. Build off 'mintpy_get_isceburst.ipynb' to build interactive for retrieving SLCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nbviewer.org/github/isce-framework/isce2-docs/blob/master/Notebooks/UNAVCO_2020/TOPS/topsApp.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, some helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing needed libraries for the entire notebook in one go\n",
    "# %matplotlib inline\n",
    "# %matplotlib widget\n",
    "import os\n",
    "from dateutil.parser import parse as parse_date\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from osgeo import gdal, osr\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Union\n",
    "from itertools import combinations\n",
    "import eof\n",
    "import geemap\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "from shapely.geometry import Polygon, box\n",
    "\n",
    "\n",
    "# only need these two if you plan on searching andrequesting for data from within this notebook\n",
    "# in my opinion, while it may take longer, it is much easier to use the ASF Vertex Website\n",
    "# that said, if you are monitoring a reoccuring site and just need more imagery, searching using the notebook would be best\n",
    "import asf_search as asf\n",
    "import hyp3_sdk as sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_dir(proj_name):\n",
    "    \"\"\"\n",
    "    This function reads in a string that you wish to make your working directory \n",
    "    for the InSAR project, and creates a data directory to store the data for ISCE2 and mintpy\n",
    "    \"\"\"\n",
    "\n",
    "    #creates file on your desktop containing the work of this notebook\n",
    "    work_dir = os.path.join(os.path.expanduser('~'),f'Desktop/{proj_name}')\n",
    "    os.makedirs(work_dir, exist_ok=True)\n",
    "    \n",
    "    # file inside work_dir for isce2 interferometry\n",
    "    if_dir = os.path.join(work_dir,'interferometry')\n",
    "    os.makedirs(if_dir, exist_ok=True)\n",
    "    \n",
    "    # file inside work_dir for mintpy time-series\n",
    "    ts_dir = os.path.join(work_dir,'time_series')\n",
    "    os.makedirs(ts_dir, exist_ok=True)\n",
    "    \n",
    "\n",
    "    xmls_dir = os.path.join(if_dir,'xmls')\n",
    "    os.makedirs(xmls_dir, exist_ok=True)\n",
    "    \n",
    "    xmldirectories=[]\n",
    "    for dir in ['topsApp', 'reference', 'secondary']:\n",
    "        dirpath = os.path.join(xmls_dir, dir)\n",
    "        os.makedirs(dirpath, exist_ok=True)\n",
    "        xmldirectories.append(dirpath)\n",
    "\n",
    "    ifdirectories=[]\n",
    "    for dir in ['reference', 'secondary', 'orbits', 'work']:\n",
    "        dirpath = os.path.join(if_dir, dir)\n",
    "        os.makedirs(dirpath, exist_ok=True)\n",
    "        ifdirectories.append(dirpath)\n",
    "\n",
    "    tsdirectories=[]\n",
    "    for dir in ['baseline', 'reference', 'merged', 'secondaries', 'mintpy']:\n",
    "        dirpath = os.path.join(ts_dir, dir)\n",
    "        os.makedirs(dirpath, exist_ok=True)\n",
    "        if dir == 'merged':\n",
    "                geomref_dir = os.path.join(dirpath,'geom_reference')\n",
    "                os.makedirs(geomref_dir, exist_ok=True)\n",
    "\n",
    "                interfer_dir = os.path.join(dirpath,'interferograms')\n",
    "                os.makedirs(interfer_dir, exist_ok=True)\n",
    "\n",
    "                tsdirectories.append(geomref_dir)\n",
    "                tsdirectories.append(interfer_dir)\n",
    "\n",
    "        tsdirectories.append(dirpath)\n",
    "\n",
    "    return work_dir, ifdirectories, tsdirectories, xmldirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplets(slc_list):\n",
    "    \"\"\"\n",
    "    this program will generate a dictionary with keys triplet_n, where n is the triplet stack\n",
    "    each triplet_n contains 4 sets. Each set contains (path/to/ref.xml, path/to/sec.xml)\n",
    "    \n",
    "    slc_zips = list of directories containing the topsApp, reference, and secondary .xml files    \n",
    "    created an returned using the project_dir fucntion\n",
    "    \"\"\"\n",
    "    \n",
    "    triplet_dict={}\n",
    "    \n",
    "    for i in range(len(slc_list) - 2):\n",
    "        triplet_dict[f'triplet_{i+1}'] = ((slc_list[i],slc_list[i+1]), (slc_list[i+1],slc_list[i+2]), (slc_list[i+2], slc_list[i]))\n",
    "        if i == 0:\n",
    "            test_triplet = ((slc_list[i],slc_list[i+1]), (slc_list[i+1],slc_list[i+2]), (slc_list[i+2], slc_list[i]), (slc_list[i], slc_list[i+2]))\n",
    "        else:\n",
    "            continue\n",
    "    return triplet_dict, test_triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create the reference and secondary .xml files needed for ISCE2 interferometry\n",
    "# function to write the \n",
    "def ref_sec_xml(slc_zips_list, slc_zips_dirs):\n",
    "    for i in range(len(slc_zips_dirs)):\n",
    "        for j, type in enumerate(['reference', 'secondary']):\n",
    "            imset = ET.Element('component', name=type)\n",
    "            safe = ET.SubElement(imset, 'property', name='safe').text = slc_zips_dirs[i]\n",
    "            out_dir =ET.SubElement(imset, 'property', name='output directory').text = ifdirectories[j]\n",
    "            orbit_dir =ET.SubElement(imset, 'property', name='orbit directory').text = ifdirectories[2]\n",
    "            roi = ET.SubElement(imset, 'property', name='region of interest').text = str(isce_aoi)\n",
    "            tree = ET.ElementTree(imset)\n",
    "            tree.write(os.path.join(xmldirectories[j+1], f'{slc_zips_list[i][17:25]}{type[:3]}.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create the topsApp.xml files for topsInSAR\n",
    "def topsApp_xml(triplet_dict):\n",
    "    for key in triplet_dict:\n",
    "        for pair in triplet_dict[key]:\n",
    "            data = ET.Element('topsApp')\n",
    "            tinsar = ET.SubElement(data, 'component', name='topsinsar')\n",
    "            snsr_name = ET.SubElement(tinsar, 'property', name='Sensor name').text = 'SENTINEL1'\n",
    "            ref_xmlcomp = ET.SubElement(tinsar, 'component', name='reference')\n",
    "            xml_file = ET.SubElement(ref_xmlcomp, 'catalog').text = os.path.join(xmldirectories[1], f\"{pair[0][17:25]}ref.xml\")\n",
    "            sec_xmlcomp = ET.SubElement(tinsar, 'component', name='secondary')\n",
    "            xml_file = ET.SubElement(sec_xmlcomp, 'catalog').text = os.path.join(xmldirectories[2], f\"{pair[1][17:25]}sec.xml\")\n",
    "            \n",
    "            swathnums = ET.SubElement(tinsar, 'property', name='swaths').text=str([1,2])\n",
    "\n",
    "            azi_looks = ET.SubElement(tinsar, 'property', name='azimuth looks').text = str(6)\n",
    "            range_looks = ET.SubElement(tinsar, 'property', name='range looks').text = str(2)\n",
    "            \n",
    "            phasefilt = ET.SubElement(tinsar, 'property', name='filter strength').text = str(0.2)\n",
    "            \n",
    "            \n",
    "            unwrap_yn = ET.SubElement(tinsar, 'property', name='do unwrap').text = str(True) # or False\n",
    "            unwrap_name = ET.SubElement(tinsar, 'property', name='unwrapper name').text = 'snaphu_mcf' # grass, icu, snaphu, snaphu_mcf, downsample_snap\n",
    "            \n",
    "            do_iono_corr = ET.SubElement(tinsar, 'property', name='do ionosphere correction').text = str(False)\n",
    "            apply_iono_corr = ET.SubElement(tinsar, 'property', name='apply ionosphere correction').text = str(False)\n",
    "            \n",
    "            #choose from: ['subband', 'rawion', 'grd2ion', 'filt_gaussian', 'ionosphere_shift', 'ion2grd', 'esd']\n",
    "            start_iono_corr = ET.SubElement(tinsar, 'property', name='start ionosphere step').text = 'filt_gaussian'\n",
    "            end_iono_corr = ET.SubElement(tinsar, 'property', name='end ionosphere step').text = 'esd'\n",
    "    \n",
    "            geocode = ET.SubElement(tinsar, 'property', name='geocode bounding box').text = str(isce_aoi)\n",
    "            \n",
    "            tree = ET.ElementTree(data)\n",
    "            tree.write(os.path.join(xmldirectories[0], f\"{pair[0][17:25]}_{pair[1][17:25]}topsApp.xml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish working directroy and data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish working directories, and locate Sentinel-1 SLC .zip files\n",
    "proj_name = 'Harris_etal_2023'\n",
    "work_dir, ifdirectories, tsdirectories, xmldirectories = project_dir(proj_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming you have downloaded .zip files covering your AOI from ASF Vertex\n",
    "# enter the file directory below\n",
    "slc_zips = '/home/wcc/Documents/InSAR/Brians_Paper/Harrisetal_slcs/2017_2018'\n",
    "\n",
    "slc_zips_list = sorted(os.listdir(slc_zips), key=lambda x: datetime.strptime(x[17:25], '%Y%m%d'))\n",
    "slc_zips_dirs = [os.path.join(slc_zips, slc) for slc in slc_zips_list]\n",
    "slc_zips_dates = [slc[17:25] for slc in slc_zips_list]\n",
    "\n",
    "triplet_dict, test_triplet = get_triplets(slc_zips_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine each triplet if you would like\n",
    "# this shows the tuple that stores the string filenmem of the SLC .zip files\n",
    "# in each triplet there will be 4 SLC pairs = 4 interferograms\n",
    "# the first makes if_ij = the multilooked wrapped interferometric phase between SLC i and j\n",
    "# the second makes if_jk = the multilooked wrapped interferometric phase between SLC j and k\n",
    "# the third makes if_ki = the multilooked wrapped interferometric phase between SLC k and i\n",
    "# where i, j, k are a time-series of SLC images\n",
    "# choose a triplet to examine its pairs\n",
    "# closure phase = if_ij+if_jk+if_ki\n",
    "\n",
    "# triplet_choice = 'triple_1'\n",
    "triplet_choice = f'triplet_{len(triplet_dict)}'  # uncomment to just check the last triplet in the dict\n",
    "\n",
    "if_ij = triplet_dict[triplet_choice][0]\n",
    "if_jk = triplet_dict[triplet_choice][1]\n",
    "if_ki = triplet_dict[triplet_choice][2]\n",
    "\n",
    "print()\n",
    "print(f'Pair 1:{if_ij}')\n",
    "print(f'Pair 2:{if_jk}')\n",
    "print(f'Pair 3:{if_ki}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get bbox for your area of interest in the SLC images, faster processing with less data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## interactive map for you to draw a polygon to signify your aoi\n",
    "\n",
    "## Create a map centered at a specific location\n",
    "m = geemap.Map(center=[20, 0], zoom=2, basemap='HYBRID')\n",
    "\n",
    "## Add drawing tools\n",
    "m.add_draw_control()\n",
    "\n",
    "## Display the map\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the vertices pf the feature\n",
    "vertices = [(coords[0], coords[1]) for i, coords in enumerate(m.draw_features[0].getInfo()['geometry']['coordinates'][0])]\n",
    "\n",
    "# create POLYGON string to use when searching asf for imagery\n",
    "isce_aoi_polygon = Polygon(vertices)\n",
    "\n",
    "#create isce compatibile bbox\n",
    "isce_aoi = [min([easting for northing, easting in vertices[:]]), max([easting for northing, easting in vertices[:]]), min([northing for northing, easting in vertices[:]]), max([northing for northing, easting in vertices[:]])]\n",
    "print(isce_aoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get s-1 orbit files (.EOF) using sentineleof library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below downloads orbit files for your S1 SLC imagery to orbits_dir created with project_dir\n",
    "for i,slc in enumerate(slc_zips_list):\n",
    "    eof.download.download_eofs(\n",
    "        orbit_dts=slc_zips_dates[i],  # slc date in str YYYYMMDD format\n",
    "        missions=['S1A', 'S1B'],        # gets both S1 missions, third was just launched (2024) so may need updating\n",
    "        sentinel_file=slc,              # image name\n",
    "        save_dir=ifdirectories[2],      # orbits_dir\n",
    "        orbit_type='precise'            # can be 'precise' or 'restituted'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sentinel-1 SLC .xml files\n",
    "- One reference and one secondary for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_sec_xml(slc_zips_list, slc_zips_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create topsApp.xml file\n",
    "- one for each interferogram in each triplet\n",
    "- (N_triplets * 4) - (N_triplets - 1)   ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topsApp_xml(triplet_dict) # stores these in xmldirectories[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to make sure all topsApp.xml files were created\n",
    "# if the cell prints somehting, not all topsApp.xmls were created\n",
    "\n",
    "topsAppxml_triplet_dict = {}\n",
    "for key, triplets in triplet_dict.items():\n",
    "    topsapppairs = (f'{triplets[0][0][17:25]}_{triplets[0][1][17:25]}topsApp.xml', \n",
    "             f'{triplets[1][0][17:25]}_{triplets[1][1][17:25]}topsApp.xml', \n",
    "             f'{triplets[2][0][17:25]}_{triplets[2][1][17:25]}topsApp.xml'\n",
    "             )\n",
    "    topsAppxml_triplet_dict[key] = topsapppairs\n",
    "\n",
    "\n",
    "for i in range(1, len(triplet_dict)+1):\n",
    "    topsapptrip = topsAppxml_triplet_dict[f'triplet_{i}']\n",
    "    slctrip = triplet_dict[f'triplet_{i}']\n",
    "    for j, slcpair in enumerate(slctrip):\n",
    "        slcdate = f'{slcpair[0][17:25]}_{slcpair[1][17:25]}'\n",
    "        topsappdate = topsapptrip[j][:-11]\n",
    "        if slcdate != topsappdate:\n",
    "            print(slcdate, topsappdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# topsApp interferometry (finally!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should import isce toolbox and print the version of it here\n",
    "# if nothing prints or nothing imports, you need to reinstall isce2\n",
    "\n",
    "import isce\n",
    "isce.version.release_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the cell that performs the InSAR processing. Still need to work on a couple things:\n",
    "\n",
    "1. ISCE2 CLI allows for running separate steps and saving pickles between steps, want to figure out how to do that in the IDE\n",
    "2. Iterating through each .xml to create the interferograms\n",
    "3. Saving XMLs to appropriate storage locations for MintPy time-series\n",
    "4. runnings prep_isce.py from mintPy to prep the topsApp results\n",
    "\n",
    "Need to look into the difference between topsStack and topsApp results, as Mintpy docs only specified topsStack. Presumably, topsStack stacks the interferograms in an easier to use format for mintpy, compared to the individual interferograms generated by topsApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is used to change directory into the storage directory for all interferograms\n",
    "# should be used, else will save results to github repo\n",
    "os.chdir(ifdirectories[3])\n",
    "print(ifdirectories[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interferometry woohoo\n",
    "\n",
    "from topsApp import TopsInSAR\n",
    "a = TopsInSAR(name=\"topsApp\", cmdline=os.path.join(xmldirectories[0], os.listdir(xmldirectories[0])[0]))\n",
    "a.configure()\n",
    "a.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working to make it so that the above saves into needed file directories for Mintpy\n",
    "\n",
    "https://mintpy.readthedocs.io/en/stable/dir_structure/\n",
    "\n",
    "Essentially just needs another function for:\n",
    "1. runnings prep_isce.py on the data produced above\n",
    "2. move all needed data created from ISCE2 into the tsdirectories according to the above link\n",
    "\n",
    "(this may need to be done in the mintpy environment, so I may end up including this in the time series ipynb, or a short .py to run on it's own)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
