{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be used to process Sentinel-2 L2A products from GEE. These products have RGB, NIR, and SWIR1, as well as NDVI, NDWI, MSAVI2, and BSI spectral indices. Otsu thresholding is used on the NIR, SWIR1, NDVI,\n",
    "\n",
    "Assuming the images have been downloaded from GEE Python API (check notebook \"01_sentinel_one_two.ipynb\" under the \"gee_python\" folder).\n",
    "\n",
    "1. Load in the .tif files and the needed bands using gdal or similar\n",
    "2. Label the RGB imagery using NDVI and NDWI thresholding as water or land\n",
    "3. Save the classified image for labeling Sentinel-1 imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import depenedencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.ticker as mticker\n",
    "import rasterio\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.filters import threshold_otsu\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import cv2\n",
    "from osgeo import gdal, osr\n",
    "from datetime import datetime\n",
    "from scipy.stats import mode\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def map_indices(imagepath):\n",
    "    with rasterio.open(imagepath) as ind_src:\n",
    "        ndvi = ind_src.read(1)  # Read first band (assume NDVI is in first band)\n",
    "        ndwi = ind_src.read(2)  # Read first band (assume NDVI is in first band)\n",
    "        msavi2 = ind_src.read(3)  # Read first band (assume NDVI is in first band)\n",
    "        bsi = ind_src.read(4)  # Read first band (assume NDVI is in first band)\n",
    "    \n",
    "    \n",
    "    # Visualizing each band using matplotlib\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # NDVI visualization\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(ndvi, cmap='RdYlGn')  # 'RdYlGn' is a color map for NDVI-like data\n",
    "    plt.colorbar(label='NDVI')\n",
    "    plt.title('NDVI')\n",
    "\n",
    "    # NDWI visualization\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(ndwi, cmap='Blues')  # 'Blues' is good for water index\n",
    "    plt.colorbar(label='NDWI')\n",
    "    plt.title('NDWI')\n",
    "\n",
    "    # MSAVI2 visualization\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(msavi2, cmap='Greens')  # 'Greens' for vegetation index\n",
    "    plt.colorbar(label='MSAVI2')\n",
    "    plt.title('MSAVI2')\n",
    "\n",
    "    # BSI visualization\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(bsi, cmap='BrBG')  # 'BrBG' for contrast between soil and water\n",
    "    plt.colorbar(label='BSI')\n",
    "    plt.title('BSI')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return ndvi, ndwi, msavi2, bsi\n",
    "\n",
    "def normalize_rgb(rgb):\n",
    "    \"\"\"Normalize the RGB values to the range [0, 255].\"\"\"\n",
    "    rgb_min, rgb_max = np.min(rgb), np.max(rgb)\n",
    "    rgb_normalized = (rgb - rgb_min) / (rgb_max - rgb_min)  # Normalize to [0, 1]\n",
    "    rgb_normalized *= 255  # Scale to [0, 255]\n",
    "    return rgb_normalized.astype(np.uint8)  # Convert to uint8 for display\n",
    "\n",
    "def plot_majvote_with_rgb(rgb_path, majority_vote):\n",
    "    # Open the RGB image\n",
    "    with rasterio.open(rgb_path) as rgb_src:\n",
    "        rgb = rgb_src.read([3, 2, 1])  # Read the first three bands (R, G, B)\n",
    "        rgb = np.moveaxis(rgb, 0, -1)  # Rearrange dimensions to (height, width, bands)\n",
    "        rgb = normalize_rgb(rgb)  # Normalize the RGB image to [0, 255]\n",
    "\n",
    "        transform = rgb_src.transform\n",
    "        height, width = rgb.shape[:2]\n",
    "        top_left = rasterio.transform.xy(transform, 0, 0, offset='center')\n",
    "        bottom_right = rasterio.transform.xy(transform, height-1, width-1, offset='center')\n",
    "\n",
    "    # Extract easting and northing from the corners\n",
    "    min_easting, max_northing = top_left\n",
    "    max_easting, min_northing = bottom_right\n",
    "\n",
    "    # Define a custom colormap for the classifications\n",
    "    cmap = ListedColormap(['black', 'white'])  # Blue for class 0, Green for class 1, Red for class 2\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 6))  # 5 subplots for RGB, Otsu, K-Means, GMM, and Majority Vote\n",
    "\n",
    "    # RGB image visualization\n",
    "    ax[0].imshow(rgb, extent=[min_easting, max_easting, min_northing, max_northing])\n",
    "    ax[0].set_title(f'{rgb_path[-14:4]} True Color')\n",
    "    ax[0].set_xlabel('Easting (meters)')\n",
    "    ax[0].set_ylabel('Northing (meters)')\n",
    "    ax[0].xaxis.set_major_locator(mticker.MaxNLocator(5))  # Reduce x-axis ticks\n",
    "\n",
    "    # Custom legends for classification plots\n",
    "    white_patch = mpatches.Patch(color='white', label='Subaerial')\n",
    "    black_patch = mpatches.Patch(color='black', label='Subaqeuous')\n",
    "    \n",
    "    # Majority vote classification visualization\n",
    "    ax[1].imshow(majority_vote, cmap=cmap, extent=[min_easting, max_easting, min_northing, max_northing])\n",
    "    ax[1].set_title('Majority Vote')\n",
    "    ax[1].set_xlabel('Easting (meters)')\n",
    "    ax[1].legend(handles=[black_patch, white_patch], loc='lower right', title=\"Classification\")\n",
    "    ax[1].xaxis.set_major_locator(mticker.MaxNLocator(5))  # Reduce x-axis ticks\n",
    "\n",
    "    # Show the plot with layout adjustments\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def export_labels_to_tif(labels, reference_tif_path, output_tif_path):\n",
    "    # Open the reference Sentinel-1 image to get the transform and CRS\n",
    "    with rasterio.open(reference_tif_path) as src:\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "        \n",
    "        height, width = labels.shape\n",
    "\n",
    "        # Define metadata for the new GeoTIFF file\n",
    "        meta = src.meta.copy()\n",
    "        meta.update({\n",
    "            'driver': 'GTiff',\n",
    "            'height': height,\n",
    "            'width': width,\n",
    "            'count': 1,  # Single band (the labels)\n",
    "            'dtype': 'uint8',  # Assuming the labels are 0 or 1\n",
    "            'crs': crs,\n",
    "            'transform': transform\n",
    "        })\n",
    "\n",
    "        # Write the labels array to a new GeoTIFF file\n",
    "        with rasterio.open(output_tif_path, 'w', **meta) as dst:\n",
    "            dst.write(labels.astype('uint8'), 1)  # Write the labels as the first band\n",
    "\n",
    "def get_rgb_avg(rgb_avg_path, combined_ims):\n",
    "    # Open all the combined .vrt files and read their bands\n",
    "    all_bands = []\n",
    "    \n",
    "    # Loop over each file to read its bands\n",
    "    for f in combined_ims:\n",
    "        ds = gdal.Open(f)\n",
    "        bands = [ds.GetRasterBand(i+1).ReadAsArray() for i in range(ds.RasterCount)]\n",
    "        all_bands.append(bands)\n",
    "    \n",
    "    # Stack the bands across all images (axis=0 for stacking across different images)\n",
    "    stacked_bands = [np.stack([image_bands[i] for image_bands in all_bands], axis=0) for i in range(len(all_bands[0]))]\n",
    "    \n",
    "    # Compute the mean for each band across the stacked images (axis=0 is across images)\n",
    "    mean_bands = [np.mean(stacked_band, axis=0) for stacked_band in stacked_bands]\n",
    "\n",
    "    # Create a new GeoTIFF with the averaged bands\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    \n",
    "    # Use the first file for spatial reference (CRS and geotransform)\n",
    "    ds = gdal.Open(combined_ims[0])\n",
    "    \n",
    "    # Create an output file with the same dimensions and number of bands as the input\n",
    "    result = driver.Create(rgb_avg_path, ds.RasterXSize, ds.RasterYSize, len(mean_bands), gdal.GDT_Float32)\n",
    "\n",
    "    # Copy projection and geotransform from the original dataset\n",
    "    result.SetProjection(ds.GetProjection())\n",
    "    result.SetGeoTransform(ds.GetGeoTransform())\n",
    "\n",
    "    # Write each averaged band to the output file\n",
    "    for i, meanband in enumerate(mean_bands):\n",
    "        result.GetRasterBand(i+1).WriteArray(meanband)\n",
    "\n",
    "    # Close the result dataset to flush the data to disk\n",
    "    result = None\n",
    "\n",
    "    return rgb_avg_path\n",
    "\n",
    "def perform_pca(image_path, output_pca_path):\n",
    "    # Load the Sentinel-2 multi-band image using GDAL\n",
    "    dataset = gdal.Open(image_path)\n",
    "\n",
    "    # Read all bands as separate arrays\n",
    "    bands = [dataset.GetRasterBand(i + 1).ReadAsArray() for i in range(dataset.RasterCount)]\n",
    "\n",
    "    # Convert the list of bands into a 3D NumPy array (bands, rows, cols)\n",
    "    bands_array = np.stack(bands, axis=0)\n",
    "\n",
    "    # Reshape the bands array into (pixels, bands) for PCA\n",
    "    pixels, bands_count = bands_array.shape[1] * bands_array.shape[2], bands_array.shape[0]\n",
    "    flattened_image = bands_array.reshape(bands_count, -1).T  # Shape: (pixels, bands)\n",
    "\n",
    "    # Convert to float32 for OpenCV PCA\n",
    "    flattened_image = flattened_image.astype(np.float32)\n",
    "\n",
    "    # Perform PCA using OpenCV (reduce to 1 principal component)\n",
    "    mean, eigenvectors = cv2.PCACompute(flattened_image, mean=None, maxComponents=1)\n",
    "    pca_result = cv2.PCAProject(flattened_image, mean, eigenvectors)\n",
    "\n",
    "    # Reshape the PCA result back to the original image dimensions\n",
    "    pca_image = pca_result.reshape(bands_array.shape[1], bands_array.shape[2])\n",
    "    # pca_image = np.nan_to_num(pca_image, nan=0.0, posinf=255.0, neginf=0.0)\n",
    "\n",
    "    # Normalize the PCA image to 0-255 for OpenCV processing\n",
    "    pca_image_normalized = cv2.normalize(pca_image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "    # Save the PCA-reduced image\n",
    "    output = gdal.GetDriverByName('GTiff').Create(output_pca_path, dataset.RasterXSize, dataset.RasterYSize, 1, gdal.GDT_Float32)\n",
    "    output.SetProjection(dataset.GetProjection())\n",
    "    output.SetGeoTransform(dataset.GetGeoTransform())\n",
    "    output.GetRasterBand(1).WriteArray(pca_image_normalized)\n",
    "    output.FlushCache()  # Ensure data is written to disk\n",
    "    output = None\n",
    "\n",
    "def get_labels(labelpath):\n",
    "    man_ims = [os.path.join(labelpath, f'manual/{file}') for file in os.listdir(os.path.join(labelpath, f'manual')) if file.endswith('.tif')]\n",
    "    man_ims = sorted(man_ims, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))\n",
    "    \n",
    "    otsu_ims = [os.path.join(labelpath, f'otsu/{file}') for file in os.listdir(os.path.join(labelpath, f'otsu')) if file.endswith('.tif')]\n",
    "    otsu_ims = sorted(otsu_ims, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))\n",
    "    \n",
    "    kmeans_ims = [os.path.join(labelpath, f'kmeans/{file}') for file in os.listdir(os.path.join(labelpath, f'kmeans')) if file.endswith('.tif')]\n",
    "    kmeans_ims = sorted(kmeans_ims, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))\n",
    "    \n",
    "    gmm_ims = [os.path.join(labelpath, f'gmm/{file}') for file in os.listdir(os.path.join(labelpath, f'gmm')) if file.endswith('.tif')]\n",
    "    gmm_ims = sorted(gmm_ims, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))\n",
    "\n",
    "    return man_ims, otsu_ims, kmeans_ims, gmm_ims\n",
    "\n",
    "def register_images(reference_image, target_image):\n",
    "    # Define warp mode: use affine transformation (can also use cv2.MOTION_EUCLIDEAN)\n",
    "    warp_mode = cv2.MOTION_TRANSLATION\n",
    "\n",
    "    # Initialize the transformation matrix (2x3 affine transformation matrix)\n",
    "    warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "\n",
    "    # Define criteria for the ECC algorithm\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 5000, 1e-6)\n",
    "\n",
    "    # Perform the ECC algorithm to find the transformation matrix\n",
    "    try:\n",
    "        cc, warp_matrix = cv2.findTransformECC(reference_image, target_image, warp_matrix, warp_mode, criteria)\n",
    "    except cv2.error as e:\n",
    "        print(f\"Error in ECC: {e}\")\n",
    "        return None\n",
    "\n",
    "    return warp_matrix\n",
    "\n",
    "def apply_transformation_to_all_bands(target_bands, warp_matrix, image_shape, output_dtype=np.float32):\n",
    "    transformed_bands = []\n",
    "    \n",
    "    for band in target_bands:\n",
    "        # Apply the transformation to the band\n",
    "        transformed_band = cv2.warpAffine(band.astype(np.float32), warp_matrix, (image_shape[1], image_shape[0]), \n",
    "                                          flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "        \n",
    "        # Handle NaN or infinite values by replacing them with valid values (e.g., 0)\n",
    "        # transformed_band = np.nan_to_num(transformed_band, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        \n",
    "        # Convert to the desired output data type\n",
    "        transformed_band = transformed_band.astype(output_dtype)\n",
    "        \n",
    "        transformed_bands.append(transformed_band)\n",
    "    \n",
    "    return transformed_bands\n",
    "\n",
    "def save_multiband_image_as_tiff(output_path, transformed_bands, reference_dataset, gdal_dtype=gdal.GDT_Float32):\n",
    "    # Create an output GeoTIFF file with the same dimensions and the same number of bands\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    out_dataset = driver.Create(output_path, reference_dataset.RasterXSize, reference_dataset.RasterYSize, len(transformed_bands), gdal_dtype)\n",
    "\n",
    "    # Set the projection and geotransform from the reference dataset\n",
    "    out_dataset.SetProjection(reference_dataset.GetProjection())\n",
    "    out_dataset.SetGeoTransform(reference_dataset.GetGeoTransform())\n",
    "\n",
    "    # Write each transformed band to the output file\n",
    "    for i, transformed_band in enumerate(transformed_bands):\n",
    "        out_dataset.GetRasterBand(i + 1).WriteArray(transformed_band)\n",
    "\n",
    "    # Flush data to disk\n",
    "    out_dataset.FlushCache()\n",
    "    out_dataset = None\n",
    "\n",
    "def calculate_indices(impathlist, outpath):\n",
    "    for im in impathlist:\n",
    "        testds = gdal.Open(im)\n",
    "\n",
    "        red = testds.GetRasterBand(3).ReadAsArray()  #.astype(float)\n",
    "        green = testds.GetRasterBand(2).ReadAsArray()    #.astype(float)\n",
    "        blue = testds.GetRasterBand(1).ReadAsArray() #.astype(float)\n",
    "        nir = testds.GetRasterBand(4).ReadAsArray()  #.astype(float)\n",
    "        swir1_10m = testds.GetRasterBand(5).ReadAsArray()    #.astype(float)\n",
    "\n",
    "\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            ndvi = (nir - red) / (nir + red)\n",
    "            ndvi[ndvi == np.inf] = np.nan\n",
    "\n",
    "\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            ndwi = (green - nir) / (green + nir)\n",
    "            ndwi[ndwi == np.inf] = np.nan\n",
    "\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            mndwi = (green - swir1_10m) / (green + swir1_10m)\n",
    "            mndwi[mndwi == np.inf] = np.nan\n",
    "\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            msavi2 = (2 * nir + 1 - np.sqrt((2 * nir + 1) ** 2 - 8 * (nir - red))) / 2\n",
    "            msavi2[msavi2 == np.inf] = np.nan\n",
    "\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            bsi = ((swir1_10m + red) - (nir + blue)) / ((swir1_10m + red) + (nir + blue))\n",
    "            bsi[bsi == np.inf] = np.nan\n",
    "\n",
    "        save_multiband_image_as_tiff(os.path.join(outpath, im[-14:]), [ndvi, ndwi, mndwi, msavi2, bsi], testds)\n",
    "\n",
    "def calculate_mean_nir_for_classes(nir_image_path, labels_list):\n",
    "    # Read the NIR band image\n",
    "    with rasterio.open(nir_image_path) as src:\n",
    "        nir_band = src.read(4)  # Assuming the NIR band is the first band\n",
    "\n",
    "    # Initialize lists to store mean NIR for each class\n",
    "    mean_nir_class0 = [] # subaqueuous\n",
    "    mean_nir_class1 = [] #  subaerial\n",
    "\n",
    "    # Iterate through each set of labels\n",
    "    for labels in labels_list:\n",
    "        # Create masks for each class\n",
    "        class0_mask = (labels == 0) # subaqueous\n",
    "        class1_mask = (labels == 1) # subaerial\n",
    "\n",
    "        # Calculate the mean NIR for each class, ignoring NaNs\n",
    "        mean_nir_0 = np.nanmean(nir_band[class0_mask])\n",
    "        mean_nir_1 = np.nanmean(nir_band[class1_mask])\n",
    "\n",
    "        # Append the mean values to the lists\n",
    "        mean_nir_class0.append(mean_nir_0)\n",
    "        mean_nir_class1.append(mean_nir_1)\n",
    "\n",
    "    return mean_nir_class0, mean_nir_class1\n",
    "\n",
    "def reorder_labels_by_nir(means, labels):\n",
    "    # Sort classes by mean NIR, keeping track of the original class order\n",
    "    sorted_indices = np.argsort(means)  # indices of sorted mean NIR values\n",
    "    \n",
    "    # Map the original class labels to the sorted order (class 0, 1, 2)\n",
    "    reordered_labels = np.copy(labels)\n",
    "    for orig_label, new_label in enumerate(sorted_indices):\n",
    "        reordered_labels[labels == new_label] = orig_label\n",
    "    \n",
    "    return reordered_labels\n",
    "\n",
    "def correct_flipped_labels(mean_nir_otsu, mean_nir_kmeans, mean_nir_gmm, otsuclasses, kmeansclasses, gmmclasses):\n",
    "    # Initialize lists to hold corrected class assignments\n",
    "    corrected_otsu = []\n",
    "    corrected_kmeans = []\n",
    "    corrected_gmm = []\n",
    "\n",
    "    # Iterate over each set of mean NIR values and classifications\n",
    "    for i in range(len(mean_nir_otsu)):\n",
    "        # Correct Otsu classifications\n",
    "        otsu_means = mean_nir_otsu[i]\n",
    "        otsu_labels = otsuclasses[i]\n",
    "        corrected_otsu.append(reorder_labels_by_nir(otsu_means, otsu_labels))\n",
    "        \n",
    "        # Correct K-means classifications\n",
    "        kmeans_means = mean_nir_kmeans[i]\n",
    "        kmeans_labels = kmeansclasses[i]\n",
    "        corrected_kmeans.append(reorder_labels_by_nir(kmeans_means, kmeans_labels))\n",
    "        \n",
    "        # Correct GMM classifications\n",
    "        gmm_means = mean_nir_gmm[i]\n",
    "        gmm_labels = gmmclasses[i]\n",
    "        corrected_gmm.append(reorder_labels_by_nir(gmm_means, gmm_labels))\n",
    "\n",
    "    return corrected_otsu, corrected_kmeans, corrected_gmm\n",
    "\n",
    "# Main function to process image bands with trimodal Otsu thresholding\n",
    "def process_image_otsu(imagepath, indexpath):\n",
    "    # Step 1: Read and normalize the bands\n",
    "    with rasterio.open(imagepath) as src:\n",
    "        b = src.read(1)\n",
    "        g = src.read(2)\n",
    "        r = src.read(3)\n",
    "        nir = src.read(4)\n",
    "        swir1_10 = src.read(5)\n",
    "\n",
    "    with rasterio.open(indexpath) as ind_src:\n",
    "        ndvi = ind_src.read(1)\n",
    "        ndwi = ind_src.read(2)\n",
    "        mndwi = ind_src.read(3)\n",
    "        msavi2 = ind_src.read(4)\n",
    "        bsi = ind_src.read(5)\n",
    "\n",
    "    # Normalize each band and index\n",
    "    b = min_max_scale(b, np.nanmin(b), np.nanmax(b))\n",
    "    g = min_max_scale(g, np.nanmin(g), np.nanmax(g))\n",
    "    r = min_max_scale(r, np.nanmin(r), np.nanmax(r))\n",
    "    nir = min_max_scale(nir, np.nanmin(nir), np.nanmax(nir))\n",
    "    swir1_10 = min_max_scale(swir1_10, np.nanmin(swir1_10), np.nanmax(swir1_10))\n",
    "    ndvi = min_max_scale(ndvi, np.nanmin(ndvi), np.nanmax(ndvi))\n",
    "    ndwi = min_max_scale(ndwi, np.nanmin(ndwi), np.nanmax(ndwi))\n",
    "    mndwi = min_max_scale(mndwi, np.nanmin(mndwi), np.nanmax(mndwi))\n",
    "    msavi2 = min_max_scale(msavi2, np.nanmin(msavi2), np.nanmax(msavi2))\n",
    "    bsi = min_max_scale(bsi, np.nanmin(bsi), np.nanmax(bsi))\n",
    "\n",
    "    # Stack all bands and indices\n",
    "    bands = {\n",
    "        \"b\": b, \"g\": g, \"r\": r, \"nir\": nir, \"swir1_10\": swir1_10,\n",
    "        \"ndvi\": ndvi, \"ndwi\": ndwi, \"mndwi\": mndwi, \"msavi2\": msavi2, \"bsi\": bsi\n",
    "    }\n",
    "\n",
    "    # Dictionary to store trimodal masks for each band/index\n",
    "    results = {}\n",
    "\n",
    "    # Apply Trimodal Otsu's thresholding to each band/index\n",
    "    for name, band in bands.items():\n",
    "        band_valid = band[np.isfinite(band)]\n",
    "        \n",
    "        if band_valid.size > 0:\n",
    "            # Calculate Otsu threshold\n",
    "            threshold = threshold_otsu(band_valid)\n",
    "\n",
    "            # Create mask based on threshold\n",
    "            mask = np.full_like(band, np.nan)\n",
    "            mask[band < threshold] = 0\n",
    "            mask[band >= threshold] = 1\n",
    "\n",
    "            # Store the mask in the results dictionary\n",
    "            results[name] = (band, mask)\n",
    "\n",
    "    return results\n",
    "\n",
    "def min_max_scale(arr, min_val, max_val):\n",
    "    return 2 * (arr - min_val) / (max_val - min_val) - 1\n",
    "\n",
    "\n",
    "# Helper function to normalize RGB\n",
    "def normalize_rgb(rgb):\n",
    "    rgb = (rgb - rgb.min()) / (rgb.max() - rgb.min())\n",
    "    return (rgb * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick which site you are doing\n",
    "sites =[\n",
    "    'SabineRS',\n",
    "    'SouthBayRestoration',\n",
    "    'DeerIsland',\n",
    "    'KachemakBay',\n",
    "    'MenenhallWetlands',\n",
    "    'NiaquallyRefuge',\n",
    "    'PoplarIsland',\n",
    "    'SMIIL'\n",
    "]\n",
    "\n",
    "site = sites[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the directory for where your images are located\n",
    "# rgbpath ='/mnt/d/SabineRS/MSI/RGB_NIR_SWIR1/original'\n",
    "\n",
    "rgbpath =f'/home/wcc/Desktop/{site}/MSI/RGB_NIR_SWIR1/original'\n",
    "\n",
    "rgb_ims = [os.path.join(rgbpath, file) for file in os.listdir(rgbpath) if file.endswith('.tif')]\n",
    "rgb_ims = sorted(rgb_ims, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register all rgb and indices images together to reduce impact of S2 perpendicular baseline changes\n",
    "- https://www.geeksforgeeks.org/image-registration-using-opencv-python/\n",
    "- https://medium.com/sentinel-hub/how-to-co-register-temporal-stacks-of-satellite-images-5167713b3e0b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rgb_avg_im = get_rgb_avg('/mnt/d/SabineRS/MSI/RGB_NIR_SWIR1/rgb_average.tif', rgb_ims)\n",
    "rgb_avg_im = get_rgb_avg(f'/home/wcc/Desktop/{site}/MSI/RGB_NIR_SWIR1/rgb_average.tif', rgb_ims)\n",
    "\n",
    "# PCA for the averaged image\n",
    "perform_pca(rgb_avg_im, rgb_avg_im.replace('.tif', '_pca.tif'))\n",
    "\n",
    "# PCA for each image\n",
    "for im in rgb_ims:\n",
    "    perform_pca(im,os.path.join(im[:-30], f'pca/{im[-21:-4]}_pca.tif'))\n",
    "\n",
    "# avg_pca_im = '/mnt/d/SabineRS/MSI/RGB_NIR_SWIR1/rgb_average_pca.tif'\n",
    "avg_pca_im = f'/home/wcc/Desktop/{site}/MSI/RGB_NIR_SWIR1/rgb_average_pca.tif'\n",
    "\n",
    "pcapath = os.path.join(rgbpath[:-9], f'pca')\n",
    "pca_ims = [os.path.join(pcapath, file) for file in os.listdir(pcapath) if file.endswith('.tif')]\n",
    "pca_ims = sorted(pca_ims, key=lambda x: datetime.strptime(x[-18:-8], '%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_ds = gdal.Open(avg_pca_im)\n",
    "ref_im = ref_ds.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "for i, im in enumerate(pca_ims):\n",
    "    pca_ds = gdal.Open(im)\n",
    "    pca_im = pca_ds.GetRasterBand(1).ReadAsArray() \n",
    "\n",
    "    warp_matrix = register_images(ref_im,pca_im)\n",
    "\n",
    "    if warp_matrix is not None:\n",
    "        reflectance_dataset = gdal.Open(rgb_ims[i])\n",
    "        reflectance_bands = [reflectance_dataset.GetRasterBand(j + 1).ReadAsArray() for j in range(reflectance_dataset.RasterCount)]\n",
    "\n",
    "        transformed_reflectance = apply_transformation_to_all_bands(reflectance_bands, warp_matrix, ref_im.shape)\n",
    "        save_multiband_image_as_tiff(f'/home/wcc/Desktop/{site}/MSI/RGB_NIR_SWIR1/registered/{rgb_ims[i][-14:]}', transformed_reflectance, reflectance_dataset)\n",
    "        # save_multiband_image_as_tiff(f'/mnt/d/{site}/MSI/RGB_NIR_SWIR1/registered/{rgb_ims[i][-14:]}', transformed_reflectance, reflectance_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate NDVI, NDWI, MNDWI, MSAVI2, and BSI (for later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just go ahead and make these for later\n",
    "\n",
    "regrgbpath = f'/home/wcc/Desktop/{site}/MSI/RGB_NIR_SWIR1/registered'\n",
    "# regrgbpath = f'/mnt/d/{site}/MSI/RGB_NIR_SWIR1/registered'\n",
    "\n",
    "regindpath = f'/home/wcc/Desktop/{site}/MSI/Indices'\n",
    "# regindpath = f'/mnt/d/{site}/MSI/Indices'\n",
    "\n",
    "\n",
    "reg_rgb_ims = [os.path.join(regrgbpath, file) for file in os.listdir(regrgbpath) if file.endswith('.tif')]\n",
    "reg_rgb_ims = sorted(reg_rgb_ims, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))\n",
    "\n",
    "calculate_indices(reg_rgb_ims, regindpath)\n",
    "\n",
    "reg_ind_ims = [os.path.join(regindpath, file) for file in os.listdir(regindpath) if file.endswith('.tif')]\n",
    "reg_ind_ims = sorted(reg_ind_ims, key=lambda x: datetime.strptime(x[-14:-4], '%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Otsu thresholding to specific bands\n",
    "- from literature, seems like nir, swir (maybe both), ndvi, ndwi, and mndwi are best\n",
    "\n",
    "0 is subaqueous, 1 is subaerial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgtbands = ['nir', 'swir1_10', 'ndvi', 'ndwi', 'mndwi']    # definitely using ndwi, ndwi, and mndwi; going to test with swir, nir, b and g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2otsuclasses = []\n",
    "\n",
    "for i, path in enumerate(reg_rgb_ims):\n",
    "    results = process_image_otsu(path, reg_ind_ims[i])\n",
    "\n",
    "    s2otsuclasses.append([results[key][1] for key in tgtbands])\n",
    "\n",
    "    # s2otsuclasses.append([mask for _, mask in results.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference NIR band to correct classes where needed\n",
    "\n",
    "Expecting lower NIR for Subaqueous and higher for Subaerial (long wavelength NIR dissipated in water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nir_means_otsu = []\n",
    "\n",
    "for i, nir_im in enumerate(reg_rgb_ims):\n",
    "    # Calculate mean NIR for each of the 10 Otsu class arrays and average them\n",
    "    allbandotsu  = []\n",
    "    for otsu_class in s2otsuclasses[i]:  # Iterate over each of the 10 Otsu arrays\n",
    "        mean_nir_0, mean_nir_1 = calculate_mean_nir_for_classes(nir_im, [otsu_class])\n",
    "        allbandotsu.append((mean_nir_0[0], mean_nir_1[0]))\n",
    "    nir_means_otsu.append(allbandotsu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relabeled_otsu = []\n",
    "\n",
    "for i in range(len(nir_means_otsu)):\n",
    "    allrelabeled = []\n",
    "    for j, set in enumerate(nir_means_otsu[i]):\n",
    "        labelsort = np.argsort(set)\n",
    "\n",
    "        # Create a relabel map to remap the classes to [0, 1]\n",
    "        relabel_map = {labelsort[idx]: idx for idx in range(len(labelsort))}\n",
    "\n",
    "        # Copy the classified image to avoid overwriting the original\n",
    "        image_copy = copy.deepcopy(s2otsuclasses[i][j])\n",
    "\n",
    "        # Replace None values with np.nan for consistency\n",
    "        image_copy = np.where(image_copy == None, np.nan, image_copy)  # Convert None to np.nan\n",
    "\n",
    "        # Apply the relabel map to the image, keeping np.nan where values don't match the map\n",
    "        relabeled_image = np.vectorize(lambda x: relabel_map.get(x, np.nan))(image_copy)\n",
    "        \n",
    "        allrelabeled.append(relabeled_image)\n",
    "\n",
    "    # Add the processed relabeled image to the dictionary\n",
    "    relabeled_otsu.append(allrelabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majvote = []\n",
    "\n",
    "for i in range(len(relabeled_otsu)):  # Assuming all methods have the same number of images\n",
    "    # Stack the three classification arrays for image `j` across the method dimension (0)\n",
    "    # Shape will be (methods, height, width) -> (3, height, width)\n",
    "    stacked_classes = np.stack(relabeled_otsu[i], axis=0)\n",
    "    \n",
    "    # Apply majority voting along the first axis (methods)\n",
    "    majority_vote = mode(stacked_classes, axis=0, nan_policy='omit')[0].squeeze()\n",
    "    \n",
    "    # Store the result in the majority vote list\n",
    "    majvote.append(majority_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mode of the classifications\n",
    "# can use this as the water mask for isce2 and mintpy processing\n",
    "\n",
    "water_mask = mode(np.stack(majvote, axis=0), axis=0).mode[0]\n",
    "plot_majvote_with_rgb(\n",
    "    reg_rgb_ims[20],\n",
    "    water_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, im in enumerate(reg_rgb_ims):\n",
    "    plot_majvote_with_rgb(\n",
    "        reg_rgb_ims[i],\n",
    "        majvote[i]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Labeled Sentinel-2 labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to save corrected classifications as .tif files\n",
    "for i, labels in enumerate(majvote):\n",
    "    reference_tif = reg_rgb_ims[i]  # Path to the original Sentinel-1 image\n",
    "\n",
    "    # outdir = os.path.join(reference_tif[:16], f's2classifications/majority')  # Define the directory path\n",
    "    outdir = os.path.join(reference_tif[:30], f's2classifications/majority')  # Define the directory path\n",
    "        \n",
    "    os.makedirs(outdir, exist_ok=True)  # Ensure the directory exists\n",
    "    output_tif = os.path.join(outdir, f'{reference_tif[-14:-4]}.tif')  # Define the output file name\n",
    "    export_labels_to_tif(labels, reference_tif, output_tif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
