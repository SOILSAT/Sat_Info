{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will be used to read in the two .nc files containing the Sentinel-1 Gamma0 backscatter, as well as the composite bands created from the backscatter. Using these .nc files, cloud-masked Sentinel-2 images will be retrieved from the GEE. The NDVI and NDWI will be used at 10-meter resolution. Otsu thresholding will be applied on all 9 bands, where the NDVI and NDWI will serve as refinement given the finer spatial resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "from netCDF4 import Dataset\n",
    "import os\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "import ee\n",
    "import geemap\n",
    "import geemap.colormaps as cm\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize the NetCDF bands\n",
    "def visualize_nc_file(nc_file):\n",
    "    # Open the NetCDF file\n",
    "    dataset = nc.Dataset(nc_file, mode='r')\n",
    "\n",
    "    # Extract variables\n",
    "    lat = dataset.variables['lat'][:]\n",
    "    lon = dataset.variables['lon'][:]\n",
    "    gamma0_vv = dataset.variables['Gamma0_VV'][:]\n",
    "    gamma0_vh = dataset.variables['Gamma0_VH'][:]\n",
    "\n",
    "    # Close the dataset after reading\n",
    "    dataset.close()\n",
    "\n",
    "    # Determine global min/max for consistent color scaling\n",
    "    vmin = min(gamma0_vv.min(), gamma0_vh.min())\n",
    "    vmax = max(gamma0_vv.max(), gamma0_vh.max())\n",
    "\n",
    "    # Plot Gamma0_VV\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    im1 = plt.imshow(gamma0_vv, extent=[lon.min(), lon.max(), lat.min(), lat.max()],\n",
    "                     cmap='gray', interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "    plt.colorbar(im1, label='Gamma0_VV')\n",
    "    plt.title('Gamma0_VV')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "\n",
    "    # Plot Gamma0_VH\n",
    "    plt.subplot(1, 2, 2)\n",
    "    im2 = plt.imshow(gamma0_vh, extent=[lon.min(), lon.max(), lat.min(), lat.max()],\n",
    "                     cmap='gray', interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "    plt.colorbar(im2, label='Gamma0_VH')\n",
    "    plt.title('Gamma0_VH')\n",
    "    plt.xlabel('Longitude')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def check_spatial_resolution(nc_file):\n",
    "    # Open the NetCDF file\n",
    "    dataset = nc.Dataset(nc_file, mode='r')\n",
    "\n",
    "    # Extract latitude and longitude\n",
    "    lat = dataset.variables['lat'][:]\n",
    "    lon = dataset.variables['lon'][:]\n",
    "\n",
    "    # Close the dataset\n",
    "    dataset.close()\n",
    "\n",
    "    # Calculate the resolution by taking the mean difference\n",
    "    lat_res = np.abs(lat[1] - lat[0])  # Latitude resolution\n",
    "    lon_res = np.abs(lon[1] - lon[0])  # Longitude resolution\n",
    "\n",
    "    print(f\"Latitude resolution: {lat_res:.6f} degrees\")\n",
    "    print(f\"Longitude resolution: {lon_res:.6f} degrees\")\n",
    "\n",
    "    # Approximate resolution in meters (assuming 1 degree â‰ˆ 111 km)\n",
    "    lat_res_m = lat_res * 111000\n",
    "    lon_res_m = lon_res * 111000 * np.cos(np.deg2rad(lat.mean()))\n",
    "\n",
    "    print(f\"Approximate pixel size: {lat_res_m:.2f} meters (latitude), {lon_res_m:.2f} meters (longitude)\")\n",
    "\n",
    "def export_to_raster_rasterio(nc_file, output_tif):\n",
    "    # Open the NetCDF file\n",
    "    dataset = nc.Dataset(nc_file, mode='r')\n",
    "\n",
    "    # Extract the variables\n",
    "    gamma0_vv = dataset.variables['Gamma0_VV'][:]\n",
    "    gamma0_vh = dataset.variables['Gamma0_VH'][:]\n",
    "    lat = dataset.variables['lat'][:]\n",
    "    lon = dataset.variables['lon'][:]\n",
    "\n",
    "    # Close the NetCDF file\n",
    "    dataset.close()\n",
    "\n",
    "    # Define raster metadata\n",
    "    transform = rasterio.transform.from_bounds(lon.min(), lat.min(), lon.max(), lat.max(),\n",
    "                                               gamma0_vv.shape[1], gamma0_vv.shape[0])\n",
    "\n",
    "    # Define raster profile (metadata)\n",
    "    profile = {\n",
    "        'driver': 'GTiff',\n",
    "        'dtype': 'float32',\n",
    "        'nodata': None,\n",
    "        'count': 2,  # Two bands\n",
    "        'height': gamma0_vv.shape[0],\n",
    "        'width': gamma0_vv.shape[1],\n",
    "        'crs': 'EPSG:4326',  # Assuming lat/lon WGS84\n",
    "        'transform': transform\n",
    "    }\n",
    "\n",
    "    # Save data to GeoTIFF\n",
    "    with rasterio.open(output_tif, 'w', **profile) as dst:\n",
    "        dst.write(gamma0_vv.astype(np.float32), 1)  # First band\n",
    "        dst.write(gamma0_vh.astype(np.float32), 2)  # Second band\n",
    "\n",
    "    print(f\"Raster saved as {output_tif}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'SabineRS'\n",
    "file_dir = f'/home/clay/Documents/{project}/Sentinel-1/GRD/ASCENDING/136/93/10_netcdfs'\n",
    "grd_files = sorted([os.path.join(file_dir, f'{file}') for file in os.listdir(file_dir) if file.endswith('.nc')]) # need to test NetCDF export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset(grd_files[-1])\n",
    "nc_vars = data.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_nc_file(grd_files[0])\n",
    "check_spatial_resolution(grd_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_composite_bands_to_nc(nc_file):\n",
    "    # Open the NetCDF file in append mode\n",
    "    dataset = nc.Dataset(nc_file, mode='r+')\n",
    "\n",
    "    # Extract the Gamma0 backscatter values\n",
    "    vv = dataset.variables['Gamma0_VV'][:].astype(np.float32)\n",
    "    vh = dataset.variables['Gamma0_VH'][:].astype(np.float32)\n",
    "\n",
    "    # Normalize the backscatter data using min-max normalization\n",
    "    def normalize(data):\n",
    "        min_val = np.nanmin(data)\n",
    "        max_val = np.nanmax(data)\n",
    "        return (data - min_val) / (max_val - min_val + 1e-8)  # Avoid division by zero\n",
    "\n",
    "    vv_norm = normalize(vv)\n",
    "    vh_norm = normalize(vh)\n",
    "\n",
    "    # Compute indices using normalized values\n",
    "\n",
    "    # VH/VV Ratio (VH_VV)\n",
    "    vh_vv = vh_norm / (vv_norm + 1e-8)\n",
    "\n",
    "    # Normalized Difference Polarization Index (NDPI)\n",
    "    ndpi = (vv_norm - vh_norm) / (vv_norm + vh_norm + 1e-8)\n",
    "\n",
    "    # Normalized VH Index (NVHI)\n",
    "    nvhi = vh_norm / (vh_norm + vv_norm + 1e-8)\n",
    "\n",
    "    # Normalized VV Index (NVVI)\n",
    "    nvvi = vv_norm / (vv_norm + vh_norm + 1e-8)\n",
    "\n",
    "    # Radar Vegetation Index (RVI)\n",
    "    rvi = (4 * vh_norm) / (vh_norm + vv_norm + 1e-8)\n",
    "\n",
    "    # Define new variables for computed indices in the NetCDF file\n",
    "    indices = {\n",
    "        \"VH_VV\": vh_vv,\n",
    "        \"NDPI\": ndpi,\n",
    "        \"NVHI\": nvhi,\n",
    "        \"NVVI\": nvvi,\n",
    "        \"RVI\": rvi\n",
    "    }\n",
    "\n",
    "    for index_name, index_data in indices.items():\n",
    "        if index_name not in dataset.variables:\n",
    "            var = dataset.createVariable(index_name, np.float32, ('lat', 'lon'), fill_value=np.nan)\n",
    "            var[:] = index_data\n",
    "            var.units = \"unitless\"\n",
    "            var.description = f\"{index_name} computed index\"\n",
    "            print(f\"Added {index_name} to NetCDF file\")\n",
    "\n",
    "    # Close the dataset\n",
    "    dataset.close()\n",
    "\n",
    "    print(f\"Composite bands successfully added to {nc_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_file = grd_files[0]\n",
    "\n",
    "compute_sar_indices_with_normalization(nc_file, nc_file.replace('nc', 'tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_visualize_bands(tif_file):\n",
    "    # Open the GeoTIFF file\n",
    "    with rasterio.open(tif_file) as src:\n",
    "        num_bands = src.count  # Get the number of bands\n",
    "        print(f\"Total bands in the raster: {num_bands}\")\n",
    "\n",
    "        # Loop through each band and visualize it\n",
    "        for band_id in range(1, num_bands + 1):\n",
    "            band = src.read(band_id)  # Read the band\n",
    "\n",
    "            # Handle nodata values and replace them with NaN for visualization\n",
    "            band = np.where(band == src.nodata, np.nan, band)\n",
    "\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(band, cmap='gray', interpolation='nearest')\n",
    "            plt.colorbar(label=f'Band {band_id}')\n",
    "            plt.title(f'Visualization of Band {band_id}')\n",
    "            plt.xlabel('Columns')\n",
    "            plt.ylabel('Rows')\n",
    "            plt.show()\n",
    "\n",
    "        # Check metadata of the raster\n",
    "        print(\"\\nRaster Metadata:\")\n",
    "        print(src.profile)\n",
    "\n",
    "check_and_visualize_bands(nc_file.replace('nc', 'tif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s1(aoi, start_date, end_date, orbit):\n",
    "    ## Sentinel-1 ImageCollection\n",
    "    s1 = (ee.ImageCollection('COPERNICUS/S1_GRD')\n",
    "               .filterBounds(aoi)\n",
    "               .filterDate(ee.Date(start_date), ee.Date(end_date))\n",
    "               .map(lambda img: img.set('date', ee.Date(img.date()).format('YYYYMMdd')))\n",
    "               .filter(ee.Filter.eq('orbitProperties_pass', orbit))\n",
    "               .select(['VV', 'VH'])\n",
    "               .sort('date')\n",
    "    )\n",
    "\n",
    "    s1 = s1.map(lambda img: img.clip(aoi))\n",
    "\n",
    "    return s1\n",
    "def get_s2_sr_cld_col(aoi, start_date, end_date, cloud_filter):\n",
    "    # Import and filter S2 SR.\n",
    "    s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date)\n",
    "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', cloud_filter)))\n",
    "\n",
    "    # Import and filter s2cloudless.\n",
    "    s2_cloudless_col = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date))\n",
    "\n",
    "    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n",
    "    combined_coll = ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n",
    "        'primary': s2_sr_col,\n",
    "        'secondary': s2_cloudless_col,\n",
    "        'condition': ee.Filter.equals(**{\n",
    "            'leftField': 'system:index',\n",
    "            'rightField': 'system:index'\n",
    "        })\n",
    "    }))\n",
    "\n",
    "    return combined_coll.map(lambda img: img.clip(aoi))\n",
    "\n",
    "def add_cloud_bands(img):\n",
    "    # Get s2cloudless image, subset the probability band.\n",
    "    cld_prb = ee.Image(img.get('s2cloudless')).select('probability')\n",
    "\n",
    "    # Condition s2cloudless by the probability threshold value.\n",
    "    is_cloud = cld_prb.gt(CLD_PRB_THRESH).rename('clouds')\n",
    "\n",
    "    # Add the cloud probability layer and cloud mask as image bands.\n",
    "    return img.addBands(ee.Image([cld_prb, is_cloud]))\n",
    "\n",
    "def add_shadow_bands(img):\n",
    "    # Identify water pixels from the SCL band.\n",
    "    not_water = img.select('SCL').neq(6)\n",
    "\n",
    "    # Identify dark NIR pixels that are not water (potential cloud shadow pixels).\n",
    "    SR_BAND_SCALE = 1e4\n",
    "    dark_pixels = img.select('B8').lt(NIR_DRK_THRESH*SR_BAND_SCALE).multiply(not_water).rename('dark_pixels')\n",
    "\n",
    "    # Determine the direction to project cloud shadow from clouds (assumes UTM projection).\n",
    "    shadow_azimuth = ee.Number(90).subtract(ee.Number(img.get('MEAN_SOLAR_AZIMUTH_ANGLE')));\n",
    "\n",
    "    # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST input.\n",
    "    cld_proj = (img.select('clouds').directionalDistanceTransform(shadow_azimuth, CLD_PRJ_DIST*10)\n",
    "        .reproject(**{'crs': img.select(0).projection(), 'scale': 100})\n",
    "        .select('distance')\n",
    "        .mask()\n",
    "        .rename('cloud_transform'))\n",
    "\n",
    "    # Identify the intersection of dark pixels with cloud shadow projection.\n",
    "    shadows = cld_proj.multiply(dark_pixels).rename('shadows')\n",
    "\n",
    "    # Add dark pixels, cloud projection, and identified shadows as image bands.\n",
    "    return img.addBands(ee.Image([dark_pixels, cld_proj, shadows]))\n",
    "\n",
    "def add_cld_shdw_mask(img):\n",
    "    # Add cloud component bands.\n",
    "    img_cloud = add_cloud_bands(img)\n",
    "\n",
    "    # Add cloud shadow component bands.\n",
    "    img_cloud_shadow = add_shadow_bands(img_cloud)\n",
    "\n",
    "    # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0.\n",
    "    is_cld_shdw = img_cloud_shadow.select('clouds').add(img_cloud_shadow.select('shadows')).gt(0)\n",
    "\n",
    "    # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input.\n",
    "    # 20 m scale is for speed, and assumes clouds don't require 10 m precision.\n",
    "    is_cld_shdw = (is_cld_shdw.focalMin(2).focalMax(BUFFER*2/20)\n",
    "        .reproject(**{'crs': img.select([0]).projection(), 'scale': 20})\n",
    "        .rename('cloudmask'))\n",
    "\n",
    "    # Add the final cloud-shadow mask to the image.\n",
    "    return img.addBands(is_cld_shdw)\n",
    "\n",
    "def apply_cld_shdw_mask(img):\n",
    "    # Subset the cloudmask band and invert it so clouds/shadow are 0, else 1.\n",
    "    not_cld_shdw = img.select('cloudmask').Not()\n",
    "\n",
    "    # Subset reflectance bands and update their masks, return the result.\n",
    "    return img.select('B.*').updateMask(not_cld_shdw)\n",
    "\n",
    "def export_image_to_drive(image, description, aoi):\n",
    "    \"\"\"\n",
    "    Export a single image to Google Drive.\n",
    "\n",
    "    Args:\n",
    "        image: ee.Image, the image to be exported.\n",
    "        description: str, unique description for the export task.\n",
    "        aoi: ee.Geometry, the area of interest for the export.\n",
    "    \"\"\"\n",
    "\n",
    "    image = image.select(['B2', 'B3', 'B4', 'B8'])\n",
    "    # Setup the export task\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image=image,\n",
    "        description=description,\n",
    "        region=aoi,  # Make sure the geometry (aoi) is defined earlier\n",
    "        fileFormat='GeoTIFF',\n",
    "        scale=10  # Adjust the scale as needed\n",
    "    )\n",
    "    task.start()\n",
    "    print(f'Exporting {description} to Drive...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s2_10m_target_indices(image):\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    ndwi = image.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
    "\n",
    "    return image.addBands([ndvi, ndwi])\n",
    "\n",
    "def s1_target_indices(image):\n",
    "    vh_vv = image.expression(\n",
    "        'VH / VV',\n",
    "        {\n",
    "            'VV': image.select('VV'),\n",
    "            'VH': image.select('VH')\n",
    "        }\n",
    "    ).rename('VH_VV')\n",
    "\n",
    "    ndpi = image.expression(\n",
    "        '(VV - VH) / (VV + VH)',\n",
    "        {\n",
    "            'VV': image.select('VV'),\n",
    "            'VH': image.select('VH')\n",
    "        }\n",
    "    ).rename('NDPI')\n",
    "\n",
    "    nvhi = image.expression(\n",
    "        'VH / (VH + VV)',\n",
    "        {\n",
    "            'VV': image.select('VV'),\n",
    "            'VH': image.select('VH')\n",
    "        }\n",
    "    ).rename('NVHI')\n",
    "\n",
    "    nvvi = image.expression(\n",
    "        'VV / (VV + VH)',\n",
    "        {\n",
    "            'VV': image.select('VV'),\n",
    "            'VH': image.select('VH')\n",
    "        }\n",
    "    ).rename('NVVI')\n",
    "\n",
    "    rvi = image.expression(\n",
    "        '(4 * VH) / (VH + VV)',\n",
    "        {\n",
    "            'VV': image.select('VV'),\n",
    "            'VH': image.select('VH')\n",
    "        }\n",
    "    ).rename('RVI')\n",
    "\n",
    "    return image.addBands([vh_vv, ndpi, nvhi, nvvi, rvi])\n",
    "\n",
    "\n",
    "def extract_valid_bounds_to_epsg4326(raster_path):\n",
    "    \"\"\"Extracts the bounding box of valid (non-NaN) data from a raster and converts it to EPSG:4326.\"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Read the raster data\n",
    "        data = src.read(1)  # Assuming a single band\n",
    "        transform = src.transform  # Affine transform of the raster\n",
    "        src_crs = src.crs  # Source CRS of the raster\n",
    "\n",
    "        # Create a mask for valid (non-NaN) pixels\n",
    "        valid_mask = ~np.isnan(data)\n",
    "\n",
    "        # Find the row and column indices of valid pixels\n",
    "        valid_rows, valid_cols = np.where(valid_mask)\n",
    "\n",
    "        if valid_rows.size == 0 or valid_cols.size == 0:\n",
    "            raise ValueError(\"No valid data in the raster.\")\n",
    "\n",
    "        # Calculate the geographic coordinates of the valid bounds\n",
    "        min_row, max_row = valid_rows.min(), valid_rows.max()\n",
    "        min_col, max_col = valid_cols.min(), valid_cols.max()\n",
    "\n",
    "        # Use the transform to convert row/col to geographic bounds\n",
    "        min_x, min_y = rasterio.transform.xy(transform, min_row, min_col, offset=\"ul\")\n",
    "        max_x, max_y = rasterio.transform.xy(transform, max_row, max_col, offset=\"ul\")\n",
    "\n",
    "        # Bounds in the source CRS\n",
    "        bounds_src_crs = (min_x, min_y, max_x, max_y)\n",
    "\n",
    "        # Transform bounds to EPSG:4326\n",
    "        transformer = Transformer.from_crs(src_crs, \"EPSG:4326\", always_xy=True)\n",
    "        min_x_4326, min_y_4326 = transformer.transform(min_x, min_y)\n",
    "        max_x_4326, max_y_4326 = transformer.transform(max_x, max_y)\n",
    "\n",
    "        bounds_epsg4326 = (min_x_4326, min_y_4326, max_x_4326, max_y_4326)\n",
    "        bbox = ee.Geometry.BBox(bounds_epsg4326[0], bounds_epsg4326[1], bounds_epsg4326[2], bounds_epsg4326[3])\n",
    "\n",
    "    return bbox\n",
    "\n",
    "def get_date(image):\n",
    "    return ee.Feature(None, {'date': image.date().format('YYYY-MM-dd')})\n",
    "\n",
    "def mosaic_images_for_date(date, sentinel1_col, sentinel2_col):\n",
    "    date_filter = ee.Filter.date(date, ee.Date(date).advance(1, 'day'))\n",
    "    \n",
    "    # Try to get Sentinel-1 mosaic; return None if no images available\n",
    "    s1_filtered = sentinel1_col.filter(date_filter)\n",
    "    s1_mosaic = ee.Algorithms.If(s1_filtered.size().gt(0), s1_filtered.mosaic(), None)\n",
    "    \n",
    "    # Try to get Sentinel-2 mosaic; return None if no images available\n",
    "    s2_filtered = sentinel2_col.filter(date_filter)\n",
    "    s2_mosaic = ee.Algorithms.If(s2_filtered.size().gt(0), s2_filtered.mosaic(), None)\n",
    "    \n",
    "    return ee.Dictionary({\n",
    "        'date': date,\n",
    "        'S1': s1_mosaic,\n",
    "        'S2': s2_mosaic\n",
    "    })\n",
    "\n",
    "## Function to add RGB images to the map.\n",
    "def add_rgb_to_map(image, map_object, coll):\n",
    "\n",
    "    date = ee.Date(image.get('date')).format('YYYY-MM-dd').getInfo()\n",
    "    for band in coll.first().bandNames().getInfo(): ## all images if small enough image collection\n",
    "        map_object.addLayer(image, {'min': 0, 'max': 2000, 'bands': ['B4', 'B3', 'B2']}, f'{date}_rgb')\n",
    "\n",
    "## Function to add spectral indices images to the map.\n",
    "def add_ind_to_map(image, map_object, band):\n",
    "\n",
    "    date = ee.Date(image.get('date')).format('YYYY-MM-dd').getInfo()\n",
    "    if band =='NDWI':\n",
    "        map_object.addLayer(image, {'min': -1, 'max': 1, 'bands': band, 'palette': cm.palettes.ndvi}, f'{date}_{band}')\n",
    "    elif band =='NDVI': \n",
    "        map_object.addLayer(image, {'min': -1, 'max': 1, 'bands': band, 'palette': cm.palettes.ndwi}, f'{date}_{band}')\n",
    "\n",
    "## Function to add spectral indices images to the map.\n",
    "def add_sar_to_map(image, map_object, target_band):\n",
    "\n",
    "    date = ee.Date(image.get('date')).format('YYYY-MM-dd').getInfo()\n",
    "    map_object.addLayer(image, {'min': -50, 'max': 1, 'bands': target_band}, f'{date}_{target_band}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read in baseline wrapped interferogram to extract bbox for GEE image search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = '/home/clay/Documents/SabineRS/Sentinel-1/InSAR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insar_dir = os.path.join(work_dir, 'interferometry')\n",
    "geo_im = [os.path.join(insar_dir, f'work/merged/{file}') for file in os.listdir(os.path.join(insar_dir, f'work/merged')) if '.geo.vrt' in file][0]\n",
    "aoi = extract_valid_bounds_to_epsg4326(geo_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Sentinel imagery from GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_cloud_cov = 20\n",
    "START_DATE = '2019-10-01'\n",
    "END_DATE = '2024-10-01'\n",
    "CLD_PRB_THRESH = 40\n",
    "NIR_DRK_THRESH = 0.15\n",
    "CLD_PRJ_DIST = 2\n",
    "BUFFER = 100\n",
    "ORBIT = 'ASCENDING'\n",
    "\n",
    "s2_coll = get_s2_sr_cld_col(aoi, START_DATE, END_DATE, s2_cloud_cov)\n",
    "s2_cm = (s2_coll.map(add_cld_shdw_mask).map(apply_cld_shdw_mask).map(s2_10m_target_indices)).select(['NDVI', 'NDWI'])       # cloud masked sentinel-2 10-meter ndvi and ndwi bands\n",
    "\n",
    "s1 = get_s1(aoi, START_DATE, END_DATE, ORBIT)                           # 10-meter GRD\n",
    "s1_all = (s1.map(s1_target_indices))                            # should be the 7 bands needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mosaic images with matching dates\n",
    "- Common cells for GEE Sentinel imagery typically smaller than that of ASF/Copernicus\n",
    "- Could result in multiple images for a single day\n",
    "- Iterate through the information or each of the images in the S1 and S2 collections, mosaic matching dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_date_list = s2_cm.map(get_date).aggregate_array('date').getInfo()\n",
    "s1_date_list = s1_all.map(get_date).aggregate_array('date').getInfo()\n",
    "all_dates = sorted(list(set(s1_date_list + s2_date_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of mosaicked images for all dates\n",
    "mosaic_dict = {}\n",
    "\n",
    "for date in all_dates:\n",
    "    mosaics = mosaic_images_for_date(date, s1_all, s2_cm)\n",
    "    mosaic_dict[date] = mosaics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporally register images together for more accurate voting\n",
    "- Different relook frequencies lead to epochs on different dates. Need to match up the dates as close as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out entries with valid S1 data within GEE without pulling to client-side\n",
    "valid_s1_data = {date: mosaics for date, mosaics in mosaic_dict.items() if mosaics.get('S1').getInfo()}\n",
    "valid_date_list = [key for key in valid_s1_data.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use this to visualize the Mosaics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "Map.centerObject(aoi, 12)\n",
    "\n",
    "for date in valid_date_list[:10]:\n",
    "    \n",
    "    sar_im = ee.Image(valid_s1_data[date].get('S1'))\n",
    "\n",
    "    # add_ind_to_map(rgb_im, Map, 'NDWI')\n",
    "    add_sar_to_map(sar_im, Map, 'VV', date)\n",
    "\n",
    "Map.addLayerControl(position = 'topright')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = valid_s1_data[date].get('S1')\n",
    "display(im.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_bounds = []\n",
    "\n",
    "for date in valid_s1_data.keys():\n",
    "    im = ee.Image(valid_s1_data[date].get('S1'))\n",
    "    im_bounds.append(im.geometry().getInfo()['coordinates'])\n",
    "\n",
    "im_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otsu threshold\n",
    "- Need to upsample the GRD images to ~20-meter resolution to match with interferograms\n",
    "- Otsu on all 20-meter SAR bands\n",
    "- Otsu on NDVI and NDWI 10-meter bands\n",
    "- Majority voting with SAR, refinement with NDVI and NDWI\n",
    "- Final shoul give water mask for each registered pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
