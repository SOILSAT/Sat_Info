{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up notebook for processing Sentinel-1 ISCE Bursts teken from the ASF Vertex website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing needed libraries for the entire notebook in one go\n",
    "%matplotlib inline\n",
    "%matplotlib widget\n",
    "from pathlib import Path\n",
    "from dateutil.parser import parse as parse_date\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from osgeo import gdal, osr\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Union\n",
    "from mintpy.cli import view, tsview\n",
    "\n",
    "# only need these two if you plan on searching andrequesting for data from within this notebook\n",
    "# in my opinion, while it may take longer, it is much easier to use the ASF Vertex Website\n",
    "# that said, if you are monitoring a reoccuring site and just need more imagery, searching using the notebook would be best\n",
    "import asf_search as asf\n",
    "import hyp3_sdk as sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters for search and storage\n",
    "- edit to include flightDirection and perpendicular baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_dir(project_name):\n",
    "    \"\"\"\n",
    "    This function reads in a string that you wish to make your working directory \n",
    "    for the InSAR project, and creates a data directory to store the data from ASF\n",
    "    \"\"\"\n",
    "\n",
    "    work_dir = Path.cwd() / project_name\n",
    "    data_dir = work_dir / 'data'\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return work_dir, data_dir\n",
    "\n",
    "def get_sbas_pairs(asf_user, asf_pass, start_date, end_date, max_temp_baseline, aoi, pol): # add perpendicular baseline options - smaller baseline may lead to better interferogram formation\n",
    "    \"\"\"\n",
    "    This function reads in a start and date for image searching,\n",
    "    as well as a maximum temporal baseline between images.\n",
    "\n",
    "    It should be noted that smaller temporal baselines tend to present\n",
    "    more coherence, with a closure phase closer to 0 when multilooking\n",
    "    \n",
    "    asf_user = username for NASA earth data login\n",
    "    asf_pass = password for NASA earth data login\n",
    "    start_date = 'YYYY-MM-DD'\n",
    "    start_date = 'YYYY-MM-DD'\n",
    "    max_temp_baseline = integer, greater than 5 as that is the shortest S1 revisit possible\n",
    "    aoi = the drawn aoi, scroll down\n",
    "    polarization = asf.POLARIZATION.VV or asf.POLARIZATION.VH\n",
    "    \"\"\"\n",
    "    \n",
    "    session = asf.ASFSession()\n",
    "    session.auth_with_creds(asf_user, asf_pass)\n",
    "\n",
    "    start = parse_date(start_date + ' 00:00:00Z')\n",
    "    end = parse_date(end_date + ' 00:00:00Z')\n",
    "    \n",
    "    search_results = asf.search(\n",
    "        platform = asf.PLATFORM.SENTINEL1,\n",
    "        polarization = pol,\n",
    "        intersectsWith= aoi,\n",
    "        start = start,\n",
    "        end = end,\n",
    "        processingLevel= asf.PRODUCT_TYPE.BURST,\n",
    "        beamMode= asf.BEAMMODE.IW\n",
    "        # direction=direction\n",
    "    )\n",
    "    \n",
    "    baseline_results = asf.baseline_search.stack_from_product(search_results[-1])\n",
    "\n",
    "    cols = list(baseline_results[0].properties.keys()) + ['geometry', ]\n",
    "    data = [list(scene.properties.values()) + [scene.geometry, ] for scene in baseline_results]\n",
    "\n",
    "    stack = pd.DataFrame(data, columns=cols)\n",
    "    stack['startTime'] = stack.startTime.apply(parse_date)\n",
    "\n",
    "    stack = stack.loc[(start <= stack.startTime) & (stack.startTime <= end)]\n",
    "\n",
    "    sbas_pairs = set()\n",
    "\n",
    "    for ref, rt in stack.loc[::-1, ['sceneName', 'temporalBaseline']].itertuples(index=False):\n",
    "        secondaries = stack.loc[\n",
    "            (stack.sceneName != ref)\n",
    "            & (stack.temporalBaseline - rt <= max_temp_baseline)\n",
    "            & (stack.temporalBaseline - rt > 0)\n",
    "        ]\n",
    "        for sec in secondaries.sceneName:\n",
    "            sbas_pairs.add((ref, sec))\n",
    "\n",
    "    print(sbas_pairs)\n",
    "    return sbas_pairs\n",
    "\n",
    "def order_pairs(proj_name, usr, passwrd, water_mask, multilook, sbas_pairs):\n",
    "    \"\"\"\n",
    "    This function reads in a start and date for image searching,\n",
    "    as well as a maximum temporal baseline between images.\n",
    "\n",
    "    It should be noted that smaller temporal baselines tend to present\n",
    "    more coherence, with a closure phase closer to 0 when multilooking\n",
    "    \n",
    "    proj_name = name of your project as a string, make it specific as you may need multiple projects\n",
    "    usr = NASA earthdata username\n",
    "    passwrd = NASA earthdata password\n",
    "    water_mask = False or True, True will mask out incoherent water bodies\n",
    "    multilook = '20x4' resulting in 160m/pixel, '10x2' resulting in 80m/pixel, or '5x1' resulting in 40m/pixel are the only options\n",
    "    \"\"\"\n",
    "    \n",
    "    hyp3 = sdk.HyP3(username = usr, password = passwrd)\n",
    "\n",
    "    jobs = sdk.Batch()\n",
    "\n",
    "    for pair in list(sbas_pairs):\n",
    "        jobs += hyp3.submit_insar_isce_burst_job(\n",
    "            granule1 = pair[0],\n",
    "            granule2 = pair[1],\n",
    "            apply_water_mask = water_mask,\n",
    "            name = proj_name,\n",
    "            looks = multilook ### I need to look more into this. Can I extract the closure phase from these looks? If not must create interferograms manually so I can extract the needed info\n",
    "        )\n",
    "    \n",
    "    jobs = hyp3.watch(jobs)\n",
    "\n",
    "    now = datetime.now()\n",
    "    start_today = datetime(now.year, now.month, now.day)\n",
    "\n",
    "    jobs = hyp3.find_jobs(name = proj_name, start=start_today)\n",
    "\n",
    "    insar_products = jobs.download_files(data_dir)\n",
    "    insar_products = [sdk.util.extract_zipped_product(ii) for ii in insar_products]\n",
    "\n",
    "    return insar_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir, data_dir = project_dir('Sentinel-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw Area of Interest for your data search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "\n",
    "## interactive map for you to draw a polygon to signify your aoi\n",
    "\n",
    "## Create a map centered at a specific location\n",
    "m = geemap.Map(center=[20, 0], zoom=2, basemap='ROADMAP')\n",
    "\n",
    "## Add drawing tools\n",
    "m.add_draw_control()\n",
    "\n",
    "## Display the map\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature you just drew\n",
    "draw_features = m.draw_features[0]\n",
    "\n",
    "# extract the vertices pf the feature\n",
    "vertices = [(coords[0], coords[1]) for i, coords in enumerate(draw_features.getInfo()['geometry']['coordinates'][0])]\n",
    "\n",
    "# create POLYGON string to use when searching asf for imagery\n",
    "aoi = \"POLYGON((\" + \", \".join([f'{northing} {easting}' for northing, easting in vertices[:]]) +\"))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find sbas isce burst pairs for insar time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbas_pairs = get_sbas_pairs(user name, password,'2024-01-01', '2024-03-01', 48, aoi, asf.POLARIZATION.VV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download isce burst interferograms for time-series processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insar_product = order_pairs(request/project name,user name, password, True, '5x1', sbas_pairs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
