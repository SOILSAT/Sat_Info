{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for implementing ISCE2 interferometry to form Interferograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nbviewer.org/github/isce-framework/isce2-docs/blob/master/Notebooks/UNAVCO_2020/TOPS/topsApp.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, some helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing needed libraries for the entire notebook in one go\n",
    "# %matplotlib inline\n",
    "# %matplotlib widget\n",
    "import os\n",
    "from dateutil.parser import parse as parse_date\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from osgeo import gdal, osr\n",
    "import matplotlib.pyplot as plt\n",
    "import eof\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_dir(work_dir):\n",
    "    \"\"\"\n",
    "    This function reads in a string that you wish to make your working directory \n",
    "    for the InSAR project, and creates a data directory to store the data for ISCE2 and mintpy\n",
    "    work-dir = str\n",
    "        path to the directory created in 01_get_slc.ipynb\n",
    "    \"\"\"\n",
    "\n",
    "    #creates file on your desktop containing the work of this notebook\n",
    "    os.makedirs(work_dir, exist_ok=True)\n",
    "    \n",
    "    # file inside work_dir for isce2 interferometry\n",
    "    if_dir = os.path.join(work_dir,'InSAR/interferometry')\n",
    "    os.makedirs(if_dir, exist_ok=True)\n",
    "    \n",
    "    # file inside work_dir for mintpy time-series\n",
    "    ts_dir = os.path.join(work_dir,'InSAR/time_series')\n",
    "    os.makedirs(ts_dir, exist_ok=True)\n",
    "    \n",
    "\n",
    "    xmls_dir = os.path.join(if_dir,'xmls')\n",
    "    os.makedirs(xmls_dir, exist_ok=True)\n",
    "    \n",
    "    xmldirectories=[]\n",
    "    for dir in ['topsApp', 'reference', 'secondary']:\n",
    "        dirpath = os.path.join(xmls_dir, dir)\n",
    "        os.makedirs(dirpath, exist_ok=True)\n",
    "        xmldirectories.append(dirpath)\n",
    "\n",
    "    ifdirectories=[]\n",
    "    for dir in ['reference', 'secondary', 'orbits', 'work']:\n",
    "        dirpath = os.path.join(if_dir, dir)\n",
    "        os.makedirs(dirpath, exist_ok=True)\n",
    "        ifdirectories.append(dirpath)\n",
    "\n",
    "    tsdirectories=[]\n",
    "    for dir in ['baselines', 'reference', 'merged', 'secondaries', 'mintpy']:\n",
    "        dirpath = os.path.join(ts_dir, dir)\n",
    "        os.makedirs(dirpath, exist_ok=True)\n",
    "        if dir == 'merged':\n",
    "                geomref_dir = os.path.join(dirpath,'geom_reference')\n",
    "                os.makedirs(geomref_dir, exist_ok=True)\n",
    "\n",
    "                interfer_dir = os.path.join(dirpath,'interferograms')\n",
    "                os.makedirs(interfer_dir, exist_ok=True)\n",
    "\n",
    "                tsdirectories.append(geomref_dir)\n",
    "                tsdirectories.append(interfer_dir)\n",
    "\n",
    "        tsdirectories.append(dirpath)\n",
    "\n",
    "    return work_dir, ifdirectories, tsdirectories, xmldirectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create the reference and secondary .xml files needed for ISCE2 interferometry\n",
    "# function to write the \n",
    "def ref_sec_xml(slc_zips_list, slc_zips_dirs):\n",
    "    for i in range(len(slc_zips_dirs)):\n",
    "        for j, type in enumerate(['reference', 'secondary']):\n",
    "            imset = ET.Element('component', name=type)\n",
    "            safe = ET.SubElement(imset, 'property', name='safe').text = slc_zips_dirs[i]\n",
    "            out_dir =ET.SubElement(imset, 'property', name='output directory').text = ifdirectories[j]\n",
    "            orbit_dir =ET.SubElement(imset, 'property', name='orbit directory').text = ifdirectories[2]\n",
    "            roi = ET.SubElement(imset, 'property', name='region of interest').text = str(isce_aoi)\n",
    "            tree = ET.ElementTree(imset)\n",
    "            tree.write(os.path.join(xmldirectories[j+1], f'{slc_zips_list[i][17:25]}{type[:3]}.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topsApp_xml(xmlname, do_iono, do_unwrap, isce_aoi):\n",
    "    \"\"\"\n",
    "    Create a topsApp XML configuration file for Sentinel-1 InSAR processing.\n",
    "\n",
    "    Parameters:\n",
    "        xmlname (str): Name of the output XML file.\n",
    "        do_iono (str): 'True' or 'False', to enable or disable ionospheric correction.\n",
    "        do_unwrap (str): 'True' or 'False', to enable or disable phase unwrapping\n",
    "        isce_aoi (list): Bounding box for processing [S, N, W, E].\n",
    "    \"\"\"\n",
    "\n",
    "    data = ET.Element('topsApp')\n",
    "    tinsar = ET.SubElement(data, 'component', name='topsinsar')\n",
    "\n",
    "    # Sensor and DEM settings\n",
    "    ET.SubElement(tinsar, 'property', name='sensor name').text = 'SENTINEL1'\n",
    "    # ET.SubElement(tinsar, 'property', name='useHighResolutionDemOnly').text = str(True)\n",
    "    # ET.SubElement(tinsar, 'property', name='demFilename').text = '/path/to/dem.tif'\n",
    "    # ET.SubElement(tinsar, 'property', name='geocode demfilename').text = '/path/to/geocode_dem.tif'\n",
    "\n",
    "    # Reference and Secondary catalogs\n",
    "    ref_xmlcomp = ET.SubElement(tinsar, 'component', name='reference')\n",
    "    ET.SubElement(ref_xmlcomp, 'catalog').text = os.path.join(xmldirectories[1], f\"{xmlname[:8]}ref.xml\")\n",
    "    sec_xmlcomp = ET.SubElement(tinsar, 'component', name='secondary')\n",
    "    ET.SubElement(sec_xmlcomp, 'catalog').text = os.path.join(xmldirectories[2], f\"{xmlname[9:17]}sec.xml\")\n",
    "\n",
    "    # General processing settings\n",
    "    ET.SubElement(tinsar, 'property', name='swaths').text = str([3])\n",
    "    ET.SubElement(tinsar, 'property', name='azimuth looks').text = str(1)\n",
    "    ET.SubElement(tinsar, 'property', name='range looks').text = str(5)\n",
    "    ET.SubElement(tinsar, 'property', name='region of interest').text = str(isce_aoi)\n",
    "    ET.SubElement(tinsar, 'property', name='filter strength').text = str(0.2)\n",
    "\n",
    "    # Unwrapping settings\n",
    "    ET.SubElement(tinsar, 'property', name='do unwrap').text = str(do_unwrap)\n",
    "    ET.SubElement(tinsar, 'property', name='unwrapper name').text = 'snaphu_mcf'\n",
    "    # ET.SubElement(tinsar, 'property', name='do unwrap 2 stage').text = str(False)\n",
    "    # ET.SubElement(tinsar, 'property', name='unwrapper 2stage name').text = 'REDARC0'\n",
    "    # ET.SubElement(tinsar, 'property', name='SOLVER_2STAGE').text = 'pulp'\n",
    "\n",
    "    # ESD settings\n",
    "    ET.SubElement(tinsar, 'property', name='do ESD').text = str(True)\n",
    "    ET.SubElement(tinsar, 'property', name='ESD azimuth looks').text = str(1)\n",
    "    ET.SubElement(tinsar, 'property', name='ESD range looks').text = str(5)\n",
    "    ET.SubElement(tinsar, 'property', name='ESD coherence threshold').text = str(0.85)\n",
    "    ET.SubElement(tinsar, 'property', name='extra ESD cycles').text = str(1)\n",
    "\n",
    "    # Dense offset settings\n",
    "    ET.SubElement(tinsar, 'property', name='do dense offsets').text = str(True)\n",
    "    ET.SubElement(tinsar, 'property', name='Ampcor window width').text = str(64)\n",
    "    ET.SubElement(tinsar, 'property', name='Ampcor window height').text = str(64)\n",
    "    ET.SubElement(tinsar, 'property', name='Ampcor search window width').text = str(20)\n",
    "    ET.SubElement(tinsar, 'property', name='Ampcor search window height').text = str(20)\n",
    "    ET.SubElement(tinsar, 'property', name='Ampcor skip width').text = str(32)\n",
    "    ET.SubElement(tinsar, 'property', name='Ampcor skip height').text = str(32)\n",
    "    ET.SubElement(tinsar, 'property', name='Ampcor margin').text = str(50)\n",
    "    ET.SubElement(tinsar, 'property', name='Ampcor oversampling factor').text = str(32)\n",
    "    ET.SubElement(tinsar, 'property', name='Range shift').text = str(0)\n",
    "    ET.SubElement(tinsar, 'property', name='Azimuth shift').text = str(0)\n",
    "    ET.SubElement(tinsar, 'property', name='SNR Threshold factor').text = str(8.0)\n",
    "\n",
    "    # Water masking\n",
    "    # ET.SubElement(tinsar, 'property', name='apply water mask').text = str(True)\n",
    "    # ET.SubElement(tinsar, 'property', name='water mask file name').text = '/path/to/water_mask.wbd'\n",
    "\n",
    "    # Ionospheric correction\n",
    "    if do_iono == 'True':\n",
    "        ET.SubElement(tinsar, 'property', name='do ionosphere correction').text = do_iono\n",
    "        ET.SubElement(tinsar, 'property', name='apply ionosphere correction').text = do_iono\n",
    "        ET.SubElement(tinsar, 'property', name='start ionosphere step').text = 'subband'\n",
    "        ET.SubElement(tinsar, 'property', name='end ionosphere step').text = 'esd'\n",
    "        ET.SubElement(tinsar, 'property', name='height of ionosphere layer in km').text = str(200.0)\n",
    "        ET.SubElement(tinsar, 'property', name='apply polynomial fit before filtering ionosphere phase').text = str(True)\n",
    "        ET.SubElement(tinsar, 'property', name='maximum window size for filtering ionosphere phase').text = str(200)\n",
    "        ET.SubElement(tinsar, 'property', name='minimum window size for filtering ionosphere phase').text = str(100)\n",
    "        ET.SubElement(tinsar, 'property', name='maximum window size for filtering ionosphere azimuth shift').text = str(150)\n",
    "        ET.SubElement(tinsar, 'property', name='minimum window size for filtering ionosphere azimuth shift').text = str(75)\n",
    "        ET.SubElement(tinsar, 'property', name='correct phase error caused by ionosphere azimuth shift').text = str(2)\n",
    "\n",
    "    # Save XML\n",
    "    tree = ET.ElementTree(data)\n",
    "    tree.write(os.path.join(xmldirectories[0], xmlname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# took these from UNAVCO for plotting the results from topsApp\n",
    "\n",
    "# Utility to plot a 2D array\n",
    "def plotdata(GDALfilename, band=1,\n",
    "             title=None,colormap='gray',\n",
    "             aspect=1, background=None,\n",
    "             datamin=None, datamax=None,\n",
    "             interpolation='nearest',\n",
    "             nodata = None,\n",
    "             draw_colorbar=True, colorbar_orientation=\"horizontal\"):\n",
    "    \n",
    "    # Read the data into an array\n",
    "    ds = gdal.Open(GDALfilename, gdal.GA_ReadOnly)\n",
    "    data = ds.GetRasterBand(band).ReadAsArray()\n",
    "    transform = ds.GetGeoTransform()\n",
    "    ds = None\n",
    "    \n",
    "    try:\n",
    "        if nodata is not None:\n",
    "            data[data == nodata] = np.nan\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    # getting the min max of the axes\n",
    "    firstx = transform[0]\n",
    "    firsty = transform[3]\n",
    "    deltay = transform[5]\n",
    "    deltax = transform[1]\n",
    "    lastx = firstx+data.shape[1]*deltax\n",
    "    lasty = firsty+data.shape[0]*deltay\n",
    "    ymin = np.min([lasty,firsty])\n",
    "    ymax = np.max([lasty,firsty])\n",
    "    xmin = np.min([lastx,firstx])\n",
    "    xmax = np.max([lastx,firstx])\n",
    "\n",
    "    # put all zero values to nan and do not plot nan\n",
    "    if background is None:\n",
    "        try:\n",
    "            data[data==0]=np.nan\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 16))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.imshow(data, vmin = datamin, vmax=datamax,\n",
    "                    cmap=colormap, extent=[xmin,xmax,ymin,ymax],\n",
    "                    interpolation=interpolation)\n",
    "    ax.set_title(title)\n",
    "    if draw_colorbar is not None:\n",
    "        cbar = fig.colorbar(cax,orientation=colorbar_orientation)\n",
    "    ax.set_aspect(aspect)    \n",
    "    plt.show()\n",
    "    \n",
    "    # clearing the data\n",
    "    data = None\n",
    "\n",
    "# Utility to plot interferograms\n",
    "def plotcomplexdata(GDALfilename,\n",
    "                    title=None, aspect=1,\n",
    "                    datamin=None, datamax=None,\n",
    "                    interpolation='nearest',\n",
    "                    draw_colorbar=None, colorbar_orientation=\"horizontal\"):\n",
    "    # Load the data into numpy array\n",
    "    ds = gdal.Open(GDALfilename, gdal.GA_ReadOnly)\n",
    "    slc = ds.GetRasterBand(1).ReadAsArray()\n",
    "    transform = ds.GetGeoTransform()\n",
    "    ds = None\n",
    "    \n",
    "    # getting the min max of the axes\n",
    "    firstx = transform[0]\n",
    "    firsty = transform[3]\n",
    "    deltay = transform[5]\n",
    "    deltax = transform[1]\n",
    "    lastx = firstx+slc.shape[1]*deltax\n",
    "    lasty = firsty+slc.shape[0]*deltay\n",
    "    ymin = np.min([lasty,firsty])\n",
    "    ymax = np.max([lasty,firsty])\n",
    "    xmin = np.min([lastx,firstx])\n",
    "    xmax = np.max([lastx,firstx])\n",
    "\n",
    "    # put all zero values to nan and do not plot nan\n",
    "    try:\n",
    "        slc[slc==0]=np.nan\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 16))\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    cax1=ax.imshow(np.abs(slc), vmin = datamin, vmax=datamax,\n",
    "                   cmap='gray', extent=[xmin,xmax,ymin,ymax],\n",
    "                   interpolation=interpolation)\n",
    "    ax.set_title(title + \" (amplitude)\")\n",
    "    if draw_colorbar is not None:\n",
    "        cbar1 = fig.colorbar(cax1,orientation=colorbar_orientation)\n",
    "    ax.set_aspect(aspect)\n",
    "\n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    cax2 =ax.imshow(np.angle(slc), cmap='rainbow',\n",
    "                    vmin=-np.pi, vmax=np.pi,\n",
    "                    extent=[xmin,xmax,ymin,ymax],\n",
    "                    interpolation=interpolation)\n",
    "    ax.set_title(title + \" (phase [rad])\")\n",
    "    if draw_colorbar is not None:\n",
    "        cbar2 = fig.colorbar(cax2, orientation=colorbar_orientation)\n",
    "    ax.set_aspect(aspect)\n",
    "    plt.show()\n",
    "    \n",
    "    # clearing the data\n",
    "    slc = None\n",
    "\n",
    "# Utility to plot multiple similar arrays\n",
    "def plotstackdata(GDALfilename_wildcard, band=1,\n",
    "                  title=None, colormap='gray',\n",
    "                  aspect=1, datamin=None, datamax=None,\n",
    "                  interpolation='nearest',\n",
    "                  draw_colorbar=True, colorbar_orientation=\"horizontal\"):\n",
    "    # get a list of all files matching the filename wildcard criteria\n",
    "    GDALfilenames = glob.glob(GDALfilename_wildcard)\n",
    "    \n",
    "    # initialize empty numpy array\n",
    "    data = None\n",
    "    for GDALfilename in GDALfilenames:\n",
    "        ds = gdal.Open(GDALfilename, gdal.GA_ReadOnly)\n",
    "        data_temp = ds.GetRasterBand(band).ReadAsArray()   \n",
    "        ds = None\n",
    "        \n",
    "        if data is None:\n",
    "            data = data_temp\n",
    "        else:\n",
    "            data = np.vstack((data,data_temp))\n",
    "\n",
    "    # put all zero values to nan and do not plot nan\n",
    "    try:\n",
    "        data[data==0]=np.nan\n",
    "    except:\n",
    "        pass            \n",
    "            \n",
    "    fig = plt.figure(figsize=(18, 16))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.imshow(data, vmin = datamin, vmax=datamax,\n",
    "                    cmap=colormap, interpolation=interpolation)\n",
    "    ax.set_title(title)\n",
    "    if draw_colorbar is not None:\n",
    "        cbar = fig.colorbar(cax,orientation=colorbar_orientation)\n",
    "    ax.set_aspect(aspect)    \n",
    "    plt.show() \n",
    "\n",
    "    # clearing the data\n",
    "    data = None\n",
    "\n",
    "# Utility to plot multiple simple complex arrays\n",
    "def plotstackcomplexdata(GDALfilename_wildcard,\n",
    "                         title=None, aspect=1,\n",
    "                         datamin=None, datamax=None,\n",
    "                         interpolation='nearest',\n",
    "                         draw_colorbar=True, colorbar_orientation=\"horizontal\"):\n",
    "    # get a list of all files matching the filename wildcard criteria\n",
    "    GDALfilenames = glob.glob(GDALfilename_wildcard)\n",
    "    print(GDALfilenames)\n",
    "    # initialize empty numpy array\n",
    "    data = None\n",
    "    for GDALfilename in GDALfilenames:\n",
    "        ds = gdal.Open(GDALfilename, gdal.GA_ReadOnly)\n",
    "        data_temp = ds.GetRasterBand(1).ReadAsArray()\n",
    "        ds = None\n",
    "        \n",
    "        if data is None:\n",
    "            data = data_temp\n",
    "        else:\n",
    "            data = np.vstack((data,data_temp))\n",
    "\n",
    "    # put all zero values to nan and do not plot nan\n",
    "    try:\n",
    "        data[data==0]=np.nan\n",
    "    except:\n",
    "        pass              \n",
    "            \n",
    "    fig = plt.figure(figsize=(18, 16))\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    cax1=ax.imshow(np.abs(data), vmin=datamin, vmax=datamax,\n",
    "                   cmap='gray', interpolation='nearest')\n",
    "    ax.set_title(title + \" (amplitude)\")\n",
    "    if draw_colorbar is not None:\n",
    "        cbar1 = fig.colorbar(cax1,orientation=colorbar_orientation)\n",
    "    ax.set_aspect(aspect)\n",
    "\n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    cax2 =ax.imshow(np.angle(data), cmap='rainbow',\n",
    "                            interpolation='nearest')\n",
    "    ax.set_title(title + \" (phase [rad])\")\n",
    "    if draw_colorbar is not None:\n",
    "        cbar2 = fig.colorbar(cax2,orientation=colorbar_orientation)\n",
    "    ax.set_aspect(aspect)\n",
    "    plt.show() \n",
    "    \n",
    "    # clearing the data\n",
    "    data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish working directory and data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish working directories, and locate Sentinel-1 SLC .zip files\n",
    "proj_dir = '/home/clay/Documents/SabineRS'\n",
    "work_dir = os.path.join(proj_dir, 'Sentinel-1')\n",
    "work_dir, ifdirectories, tsdirectories, xmldirectories = project_dir(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming you have downloaded .zip files covering your AOI from ASF Vertex\n",
    "# enter the file directory below\n",
    "slc_zips = os.path.join(work_dir, 'SLC/ASCENDING/136/93')\n",
    "\n",
    "slc_zips_list = sorted(os.listdir(slc_zips), key=lambda x: datetime.strptime(x[17:25], '%Y%m%d'))\n",
    "slc_zips_dirs = [os.path.join(slc_zips, slc) for slc in slc_zips_list]\n",
    "slc_zips_dates = [slc[17:25] for slc in slc_zips_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get bbox drawn in 01_get_slc.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "isce_aoi_file = open(os.path.join(proj_dir, 'isceaoi.txt'), 'r+')\n",
    "aoi = isce_aoi_file.read()\n",
    "isce_aoi = [float(num) for num in re.findall(r'[-+]?\\d*\\.\\d+', aoi)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get s-1 orbit files (.EOF) using sentineleof library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below downloads orbit files for your S1 SLC imagery to orbits_dir created with project_dir\n",
    "for i,slc in enumerate(slc_zips_list):\n",
    "    eof.download.download_eofs(\n",
    "        orbit_dts=slc_zips_dates[i],  # slc date in str YYYYMMDD format\n",
    "        missions=['S1A', 'S1B'],        # gets both S1 missions, third was just launched (2024) so may need updating\n",
    "        sentinel_file=slc,              # image name\n",
    "        save_dir=ifdirectories[2],      # orbits_dir\n",
    "        orbit_type='precise'            # can be 'precise' or 'restituted'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sentinel-1 SLC .xml files\n",
    "- One reference and one secondary for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_sec_xml(slc_zips_list, slc_zips_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create topsApp.xml file\n",
    "- look into computing baselines, running dense offsets for wrapped and unwrapped ifgs, water masking, shadow masking, and ionosphere correction\n",
    "- one for each interferogram in each triplet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order of importance\n",
    "1. water mask in radar and for mintpy (wbd.py)\n",
    "3. compute baselines\n",
    "4.  automation for all SLCs (including removing old data and organizing to mintpy standards)\n",
    "5. shadow masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, need to get baseline wrapped geocoded ifg\n",
    "# will be used to get sentinel-2 imagery for water mask\n",
    "# stores these in xmldirectories[0]\n",
    "\n",
    "do_iono = 'True'    # most times C-band is unaffected by ionosphere, but can be included in some cases where TEC varies\n",
    "do_unwrap = 'False' # choice between geocoded wrapped ifg or unwrapped ifg\n",
    "\n",
    "# create the xml\n",
    "topsApp_xml(f'{slc_zips_list[0][17:25]}_{slc_zips_list[1][17:25]}topsApp.xml', do_iono, do_unwrap, isce_aoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# topsApp interferometry (finally!)\n",
    "- Need to split interferogram processing into three steps\n",
    "1. preprocess to filter\n",
    "2. apply water mask\n",
    "3. unwrap to endup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that you have isce installed and what version\n",
    "\n",
    "import isce\n",
    "isce.version.release_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is used to change directory into the storage directory for all interferograms\n",
    "# should be used, else will save results to github repo\n",
    "os.chdir(ifdirectories[3])\n",
    "print(ifdirectories[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run isce2 up to the unwrapping stage, this will provide the wrapped interferogram. The boundings of this wrapped interferogram will then be used to retrieve the needed Sentinel-1 and Sentinel-2 imagery for the water mask model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline interferogram and water mask creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the reference interferogram and SLC for mintpy\n",
    "# run in steps from preprocess to filter\n",
    "\n",
    "xml_path = os.path.join(xmldirectories[0] , sorted(os.listdir(xmldirectories[0]), key=lambda x: datetime.strptime(x[:8], '%Y%m%d'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!topsApp.py {xml_path} --steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quickly visualize the filtered amplitude and the filtered wrapped ifg\n",
    "\n",
    "plotcomplexdata('merged/filt_topophase.flat.geo.vrt', \n",
    "                title=\"MERGED FILT IFG \", aspect=1,\n",
    "                datamin=0, datamax=10000, draw_colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the time-series mode or median water mask created in the watermask workflow (02b and 02c). This should allow more accurate water masking of the same area as the ifg than what is currently possible with the outdated DEMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the water mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remake the xmls to contain ionosphere correction (if you want)\n",
    "# look into tropospheric correction, per Liao et al. 2020 \n",
    "# stores these in xmldirectories[0]\n",
    "\n",
    "# do_iono = 'True'\n",
    "\n",
    "# for i, m in enumerate(slc_zips_list):\n",
    "#     if i < len(slc_zips_list) - 4:\n",
    "#         for date in [f'{m[17:25]}_{slc_zips_list[i+1][17:25]}', f'{m[17:25]}_{slc_zips_list[i+2][17:25]}', f'{m[17:25]}_{slc_zips_list[i+3][17:25]}']:\n",
    "#             topsApp_xml(f'{date}topsApp.xml', do_iono, isce_aoi)\n",
    "\n",
    "#     elif i == len(slc_zips_list) - 3:\n",
    "#         for date in [f'{m[17:25]}_{slc_zips_list[i+1][17:25]}', f'{m[17:25]}_{slc_zips_list[i+2][17:25]}']:\n",
    "#             topsApp_xml(f'{date}topsApp.xml', do_iono, isce_aoi)\n",
    "\n",
    "#     elif i == len(slc_zips_list) - 2:\n",
    "#         topsApp_xml(f\"{m[17:25]}_{slc_zips_list[i+1][17:25]}topsApp.xml\", do_iono, isce_aoi)\n",
    "\n",
    "#     elif i == len(slc_zips_list) - 1:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have loaded the water mask in this notebook, use isce2 to apply the water mask to the wrapped ifg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first create appropriate XMLs\n",
    "# this is for all ifgs\n",
    "\n",
    "do_iono = 'True'\n",
    "do_unwrap = 'True'\n",
    "\n",
    "for i, m in enumerate(slc_zips_list):\n",
    "    if i < len(slc_zips_list) - 4:\n",
    "        for date in [f'{m[17:25]}_{slc_zips_list[i+1][17:25]}', f'{m[17:25]}_{slc_zips_list[i+2][17:25]}', f'{m[17:25]}_{slc_zips_list[i+3][17:25]}']:\n",
    "            topsApp_xml(f'{date}topsApp.xml', do_iono, do_unwrap, isce_aoi)\n",
    "\n",
    "    elif i == len(slc_zips_list) - 3:\n",
    "        for date in [f'{m[17:25]}_{slc_zips_list[i+1][17:25]}', f'{m[17:25]}_{slc_zips_list[i+2][17:25]}']:\n",
    "            topsApp_xml(f'{date}topsApp.xml', do_iono, do_unwrap, isce_aoi)\n",
    "\n",
    "    elif i == len(slc_zips_list) - 2:\n",
    "        topsApp_xml(f\"{m[17:25]}_{slc_zips_list[i+1][17:25]}topsApp.xml\", do_iono, do_unwrap, isce_aoi)\n",
    "\n",
    "    elif i == len(slc_zips_list) - 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!topsApp.py {xml_path} --start='startup' --end='filter'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the water masked wrapped ifg, you can now proceed with unwrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step processing here\n",
    "# do unwrapping to the finish\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secondary interferogram(s) generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, reuse the watermask and bulk process the secondary ifg's needed for the insar time series. This replicates the above water masking, but for each subsequent ifg in the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secondary interferograms\n",
    "# step processing to unwrap again\n",
    "\n",
    "for xml in sorted(os.listdir(xmldirectories[0]), key=lambda x: datetime.strptime(x[:8], '%Y%m%d'))[1:]:\n",
    "    xml_path = os.path.join(xmldirectories[0] , xml)\n",
    "    insar = TopsInSAR(name=\"topsApp\", cmdline=xml_path)\n",
    "    insar.configure()\n",
    "    insar.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step processing here\n",
    "#do preprocess to filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use wbd.py or waterMask.py to retrieve and download needed watermask\n",
    "# apply watermask (using isce2, or manually with gdal and rasterio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue with InSAR using the water masked data for unwrapping\n",
    "# do unwrap to endup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can run these steps separately if you want more info on where process may be failing\n",
    "\n",
    "# insar = TopsInSAR(name=\"topsApp\", cmdline=xml_path)\n",
    "# insar.configure()\n",
    "# insar.startup()\n",
    "# insar.runComputeBaseline()\n",
    "# insar.verifyDEM()\n",
    "# insar.verifyGeocodeDEM()\n",
    "# insar.runTopo()\n",
    "# insar.runSubsetOverlaps()\n",
    "# insar.runCoarseOffsets()\n",
    "# insar.runCoarseResamp()\n",
    "# insar.runOverlapIfg()\n",
    "# insar.runPrepESD()\n",
    "# insar.runESD()\n",
    "# insar.runRangeCoreg()\n",
    "# insar.runFineOffsets()\n",
    "# insar.runFineResamp()\n",
    "# insar.runIon()\n",
    "# insar.runBurstIfg()\n",
    "# insar.runMergeBursts()\n",
    "# #add dense offsets here for wrapped phase if you'd like\n",
    "# insar.runFilter()\n",
    "# insar.runUnwrapper()    # can also run 2stage unwrapper and dump to pickle if you want\n",
    "# insar.runGeocode(insar.geocode_list, insar.do_unwrap, insar.geocode_bbox)\n",
    "# insar.runDenseOffsets()\n",
    "# insar.runOffsetFilter()\n",
    "# insar.runGeocode(insar.off_geocode_list, True, insar.geocode_bbox, True)\n",
    "# insar.endup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps include:\n",
    "- runPreprocessor\n",
    "- runComputeBaseline\n",
    "- verifyDEM\n",
    "- verifyGeocodeDEM\n",
    "- runTopo\n",
    "- runSubsetOverlaps\n",
    "- runCoarseOffsets\n",
    "- runCoarseResamp\n",
    "- runOverlapIfg\n",
    "- runPrepESD\n",
    "- runESD\n",
    "- runRangeCoreg\n",
    "- runFineOffsets\n",
    "- runFineResamp\n",
    "- runIon\n",
    "- runBurstIfg\n",
    "- runMergeBursts\n",
    "- runFilter\n",
    "- runGeocode\n",
    "- runDenseOffsets\n",
    "- runOffsetFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate baseline file for interferograms\n",
    "- uses isce2/contrib/stack/topsStack/computeBaseline.py, you will need to provide your path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrange file directories for use in MintPy\n",
    "- https://github.com/insarlab/MintPy-tutorial/blob/main/workflows/smallbaselineApp.ipynb\n",
    "- reference the Fernandina example set\n",
    "- for 'reference' and 'merged/reference' files, only needed from first ifg\n",
    "- remove files not needed in mintpy to save storage space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEED TO FIGURE THIS OUT FIRST, AUTOMATION ALREADY WORKS BUT OVERWRITES ITSELF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate smallbaselineApp files needed for MintPy time series (might have to run this in mintpy environment)\n",
    "- need prep_isce and load_data from MintPy\n",
    "- https://mintpy.readthedocs.io/en/stable/dir_structure/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mintpy needs\n",
    "\n",
    "# mintpy.load.processor        = isce\n",
    "# ##---------for ISCE only:\n",
    "# mintpy.load.metaFile         = $DATA_DIR/GalapagosSenDT128/reference/IW*.xml\n",
    "# mintpy.load.baselineDir      = $DATA_DIR/GalapagosSenDT128/baselines\n",
    "# ##---------interferogram datasets:\n",
    "# mintpy.load.unwFile          = $DATA_DIR/GalapagosSenDT128/merged/interferograms/*/filt_*.unw\n",
    "# mintpy.load.corFile          = $DATA_DIR/GalapagosSenDT128/merged/interferograms/*/filt_*.cor\n",
    "# mintpy.load.connCompFile     = $DATA_DIR/GalapagosSenDT128/merged/interferograms/*/filt_*.unw.conncomp\n",
    "# ##---------geometry datasets:\n",
    "# mintpy.load.demFile          = $DATA_DIR/GalapagosSenDT128/merged/geom_reference/hgt.rdr\n",
    "# mintpy.load.lookupYFile      = $DATA_DIR/GalapagosSenDT128/merged/geom_reference/lat.rdr\n",
    "# mintpy.load.lookupXFile      = $DATA_DIR/GalapagosSenDT128/merged/geom_reference/lon.rdr\n",
    "# mintpy.load.incAngleFile     = $DATA_DIR/GalapagosSenDT128/merged/geom_reference/los.rdr\n",
    "# mintpy.load.azAngleFile      = $DATA_DIR/GalapagosSenDT128/merged/geom_reference/los.rdr\n",
    "# mintpy.load.shadowMaskFile   = $DATA_DIR/GalapagosSenDT128/merged/geom_reference/shadowMask.rdr\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
