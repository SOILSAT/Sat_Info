{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to test intake and labeling of unseen data\n",
    "- will try new surveys to continuously improve model accuracy\n",
    "- will try new S2 and Planet images to test accuracy on unseen data. Need to get outlines of the NCF channels for these image searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import rasterio\n",
    "import pickle\n",
    "import numpy as np\n",
    "import ee\n",
    "import geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize(project='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize an array\n",
    "def normalize(array):\n",
    "    return (array - np.nanmin(array)) / (np.nanmax(array) - np.nanmin(array))\n",
    "\n",
    "def extract_raster_data(pair_tuple):\n",
    "    images_data = []\n",
    "\n",
    "    for paths in pair_tuple:\n",
    "        bathy_path = paths[1]\n",
    "        s2_path = paths[0]\n",
    "\n",
    "        # --- Step 1: Open Bathymetry Raster ---\n",
    "        with rasterio.open(bathy_path) as bathy:\n",
    "            bathy_data = bathy.read(1)  # Bathymetry data (band 1)\n",
    "            bathy_nodata = bathy.nodata  # NoData value\n",
    "            bathy_transform = bathy.transform\n",
    "            bathy_shape = bathy.shape\n",
    "\n",
    "        # --- Step 2: Open Sentinel-2 Raster ---\n",
    "        with rasterio.open(s2_path) as s2:\n",
    "            if s2.shape != bathy_shape or s2.transform != bathy_transform:\n",
    "                raise ValueError(\n",
    "                    f\"Inconsistent shapes or transforms:\\n\"\n",
    "                    f\"Bathymetry Shape: {bathy_shape}, Sentinel-2 Shape: {s2.shape}.\\n\"\n",
    "                    f\"Bathymetry Transform: {bathy_transform}, Sentinel-2 Transform: {s2.transform}.\\n\"\n",
    "                    f\"Ensure rasters have identical extents and resolutions.\"\n",
    "                )\n",
    "\n",
    "            # Read Sentinel-2 bands\n",
    "            bands = {\n",
    "                \"red\": normalize(s2.read(3)),\n",
    "                \"green\": normalize(s2.read(2)),\n",
    "                \"blue\": normalize(s2.read(1)),\n",
    "                \"nir\": normalize(s2.read(4))\n",
    "            }\n",
    "\n",
    "            s2_nodata = s2.nodata  # Sentinel-2 NoData value\n",
    "\n",
    "        # --- Step 3: Flatten Bands ---\n",
    "        flat_bathy = bathy_data.flatten()\n",
    "        flat_bands = {key: band.flatten() for key, band in bands.items()}\n",
    "\n",
    "        # --- Step 4: Mask NoData Values ---\n",
    "        valid_mask = (\n",
    "            ~np.isnan(flat_bathy) &  # Valid bathy pixels\n",
    "            (flat_bathy != bathy_nodata)  # Exclude bathy NoData\n",
    "        )\n",
    "\n",
    "        for band in flat_bands.values():\n",
    "            valid_mask &= (band != s2_nodata)  # Exclude Sentinel-2 NoData\n",
    "\n",
    "        # Apply the mask\n",
    "        valid_bathy = flat_bathy[valid_mask].reshape(-1, 1)  # Reshape bathy to (n_pixels, 1)\n",
    "        valid_features = np.column_stack([band[valid_mask] for band in flat_bands.values()])\n",
    "\n",
    "        # --- Step 5: Combine Features and Targets ---\n",
    "        # combined_features = np.concatenate((valid_bathy, valid_features), axis=1)  # Combine bathy and S2\n",
    "        images_data.append((valid_features, valid_bathy.flatten()))  # Flatten bathy for targets\n",
    "\n",
    "    return images_data\n",
    "\n",
    "def survey_name_type(surveynames):\n",
    "    \"\"\"\n",
    "    Will take in the list of surveynames and extract the NCF channel ID and the survey type\n",
    "    \"\"\"\n",
    "    surveytypes = ['AD', 'BD', 'CS', 'PA', 'PR', 'XA', 'XB', 'XC', 'OT', 'DS']\n",
    "\n",
    "    extracted_parts = [re.match(r'^(.*?)_\\d{8}', path).group(1) for path in surveynames if re.match(r'^(.*?)_\\d{8}', path)]\n",
    "    channel_ids = [re.sub(r'^.*?_DIS_', '', path) for path in extracted_parts]\n",
    "\n",
    "    isolated_survey_types = []\n",
    "    for path in surveynames:\n",
    "        for type in surveytypes:\n",
    "            if type in path:\n",
    "                isolated_survey_types.append(type)\n",
    "                break  # Stop checking after the first match\n",
    "\n",
    "    return channel_ids, isolated_survey_types\n",
    "\n",
    "def create_composite_bands_with_existing(flattened_s2):\n",
    "    if flattened_s2.shape[1] != 4:\n",
    "        raise ValueError(\"Input array must have 4 columns representing B, G, R, NIR bands.\")\n",
    "\n",
    "    # Split the bands\n",
    "    blue = flattened_s2[:, 0]\n",
    "    green = flattened_s2[:, 1]\n",
    "\n",
    "    # Compute composite bands\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        bluegreen = np.divide(blue, green, out=np.zeros_like(blue), where=green != 0)\n",
    "        greenblue = np.divide(green, blue, out=np.zeros_like(green), where=blue != 0)\n",
    "        stumpf = np.divide(\n",
    "            np.log(blue + 1e-6), np.log(green + 1e-6), out=np.zeros_like(blue), where=(green > 0) & (blue > 0)\n",
    "        )\n",
    "\n",
    "    # Normalize composite bands\n",
    "    bluegreen = normalize(bluegreen)\n",
    "    greenblue = normalize(greenblue)\n",
    "    stumpf = normalize(stumpf)\n",
    "\n",
    "    # Combine all bands\n",
    "    combined_array = np.hstack((flattened_s2, bluegreen[:, None], greenblue[:, None], stumpf[:, None]))\n",
    "\n",
    "    return combined_array\n",
    "\n",
    "def get_pixel_positions(raster_path):\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Get the affine transformation of the raster\n",
    "        transform = src.transform\n",
    "        \n",
    "        # Read the first band to determine valid (non-NaN) pixels\n",
    "        band_data = src.read(1, masked=True)  # Read the first band as a masked array\n",
    "        valid_mask = ~band_data.mask          # Valid pixels where mask is False\n",
    "\n",
    "        # Get raster dimensions\n",
    "        height, width = src.height, src.width\n",
    "\n",
    "        # Create arrays of pixel indices\n",
    "        row_indices, col_indices = np.meshgrid(np.arange(height), np.arange(width), indexing=\"ij\")\n",
    "\n",
    "        # Compute x, y positions using the affine transform\n",
    "        xs, ys = rasterio.transform.xy(transform, row_indices, col_indices, offset='center')\n",
    "        xs = np.array(xs).flatten()\n",
    "        ys = np.array(ys).flatten()\n",
    "\n",
    "        # Filter x, y positions to include only valid pixels\n",
    "        valid_positions = np.column_stack((xs[valid_mask.flatten()], ys[valid_mask.flatten()]))\n",
    "\n",
    "    return valid_positions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO INCLUDE PICKLE FILE PATHS FOR ENCODERS\n",
    "# NEED TO INCLUDE A SIMILAR NAMING SYSTEM AS THE EHYDRO SURVEYS \n",
    "# \n",
    "\n",
    "\n",
    "def prepare_new_data(surveynames, pickle_files):\n",
    "    \"\"\"\n",
    "    This function will take in new Sentinel-2 .tif files from GEE (R, G, B, NIR) and\n",
    "    create a dataframe in the format needed for input into the bathymetry model\n",
    "\n",
    "    surveynames: list\n",
    "        list of strings containing the names of th\n",
    "\n",
    "    pickle_files: list\n",
    "        list of strings \n",
    "    \"\"\"\n",
    "    images = [os.path.join(NEW_DIR, f'{name}.tif') for name in surveynames]\n",
    "\n",
    "    images_data = extract_raster_data(images)\n",
    "\n",
    "    good_pairs = []\n",
    "    goodnames = []\n",
    "    for name, pairs in zip(surveynames, images_data):\n",
    "        if pairs[0].shape[0] != 0:\n",
    "            good_pairs.append(pairs)\n",
    "            goodnames.append(name)\n",
    "\n",
    "    ncf_channels, survey_types = survey_name_type(goodnames)\n",
    "    all_bands = [create_composite_bands_with_existing(pair[0]) for pair in good_pairs]\n",
    "    pixel_positions = [get_pixel_positions(pair[0]) for pair in good_pairs]\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    # Iterate through the names and corresponding data\n",
    "    for i, name in enumerate(goodnames):\n",
    "        # Extract data for the current iteration\n",
    "        bands = all_bands[i]               # Shape (n_pixels, 7)\n",
    "        positions = pixel_positions[i]     # Shape (n_pixels, 2)\n",
    "        bathymetry = good_pairs[i][1]      # Shape (n_pixels,)\n",
    "\n",
    "        # Create a dataframe directly using a dictionary comprehension\n",
    "        data[name] = pd.DataFrame({\n",
    "            \"Blue\": bands[:, 0],\n",
    "            \"Green\": bands[:, 1],\n",
    "            \"Red\": bands[:, 2],\n",
    "            \"NIR\": bands[:, 3],\n",
    "            \"Blue/Green\": bands[:, 4],\n",
    "            \"Green/Blue\": bands[:, 5],\n",
    "            \"Stumpf\": bands[:, 6],\n",
    "            \"X\": positions[:, 0],\n",
    "            \"Y\": positions[:, 1],\n",
    "            \"Channel_Name\": [ncf_channels[i]] * len(bands),  # Repeating value directly\n",
    "            \"Survey_Type\": [survey_types[i]] * len(bands),   # Repeating value directly\n",
    "            \"Bathymetry\": bathymetry\n",
    "        })\n",
    "\n",
    "        for col in ['Channel_Name', 'Survey_Type']:\n",
    "            pkl_file = open(os.path.join(WORK_DIR, f'{col}_label_encoders.pkl'), 'rb')\n",
    "            encoder= pickle.load(pkl_file) \n",
    "            pkl_file.close()\n",
    "\n",
    "            data[name][col] = encoder.transform(data[name][col])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to new S2 rasters for labeling\n",
    "# going\n",
    "\n",
    "NEW_DIR = \n",
    "\n",
    "surveynames =\n",
    "filepaths = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
