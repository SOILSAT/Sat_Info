{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is going to download eHydro bathymetry data from the USACE ArcGIS REST repository, as well as retrieve cloud masked imagery of the same location, at the same time, for training of Satellite Derived Bathymetry model(s) for the National Channel Framework (NCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import ee\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from rasterio.mask import mask\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import fiona\n",
    "from scipy.interpolate import griddata\n",
    "from pyproj import Proj, transform\n",
    "from pyproj import Transformer\n",
    "from shapely.geometry import Point, Polygon, MultiPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize(project = '') ##enter your project name here as a string to initialize exchanges with ee api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gee_search_dates(time):\n",
    "    date_obj = datetime.utcfromtimestamp(time / 1000)\n",
    "    return ((date_obj - timedelta(days=1)).strftime('%Y-%m-%d'), (date_obj + timedelta(days=1)).strftime('%Y-%m-%d'))\n",
    "\n",
    "def ehydro_date_convert(time):\n",
    "    return datetime.utcfromtimestamp(time / 1000).strftime('%Y-%m-%d')\n",
    "\n",
    "def download_file(url, destination):\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    with open(destination, 'wb') as file, tqdm(\n",
    "        desc=f\"Downloading {os.path.basename(destination)}\",\n",
    "        total=total_size,\n",
    "        unit='B',\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "    ) as bar:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            file.write(chunk)\n",
    "            bar.update(len(chunk))\n",
    "\n",
    "def get_s2_sr_cld_col(aoi, start_date, end_date, cloud_filter):\n",
    "    # Import and filter S2 SR.\n",
    "    s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date)\n",
    "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', cloud_filter)))\n",
    "\n",
    "    # Import and filter s2cloudless.\n",
    "    s2_cloudless_col = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date))\n",
    "\n",
    "    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n",
    "    combined_coll = ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n",
    "        'primary': s2_sr_col,\n",
    "        'secondary': s2_cloudless_col,\n",
    "        'condition': ee.Filter.equals(**{\n",
    "            'leftField': 'system:index',\n",
    "            'rightField': 'system:index'\n",
    "        })\n",
    "    }))\n",
    "\n",
    "    return combined_coll\n",
    "\n",
    "def interpolate_bathymetry(surveyname, resolution, storage_dir):\n",
    "    folder_path = os.path.join(DOWNLOAD_DIR, surveyname)\n",
    "    input_shapefile = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.gdb')][0]\n",
    "    output_raster = \"/tmp/bathy_interp.tif\"  # Output raster file path\n",
    "    clipped_raster = '/tmp/bath_clip.tif'\n",
    "    resampled_raster = os.path.join(storage_dir, f'{surveyname}.tif')\n",
    "    z_field = \"depthMean\"  # Attribute containing bathymetry or depth values\n",
    "    resolution = 10  # Desired pixel resolution in meters\n",
    "\n",
    "    gdf = gpd.read_file(input_shapefile, layer=\"Bathymetry_Vector\")\n",
    "    xmin, ymin, xmax, ymax = gdf.total_bounds  # Get the extent of the layer\n",
    "\n",
    "    # Calculate raster width and height\n",
    "    width = round((xmax - xmin) / resolution)\n",
    "    height = round((ymax - ymin) / resolution)\n",
    "\n",
    "    # --- Step 3: Create the Raster Using gdal.Grid ---\n",
    "    gdal.Grid(\n",
    "        output_raster,                # Output raster path\n",
    "        input_shapefile,              # Input vector data\n",
    "        format=\"GTiff\",               # Output file format\n",
    "        algorithm=\"invdist\",          # Interpolation method (IDW)\n",
    "        zfield=z_field,               # Attribute containing bathymetry values\n",
    "        outputBounds=[xmin, ymin, xmax, ymax],  # Set bounds\n",
    "        width=width,                  # Number of columns\n",
    "        height=height,                # Number of rows\n",
    "        layers=\"Bathymetry_Vector\",   # Specify the layer\n",
    "        z_multiply=-1                 # Flip depths to negative\n",
    "    )\n",
    "    \n",
    "    # --- Step 4: Clip the Raster to the GDF Geometry ---\n",
    "    # Combine all geometries into a single boundary\n",
    "    geometry = [gdf.geometry.union_all()]\n",
    "\n",
    "    # Open the created raster and clip it using the GDF boundary\n",
    "    with rasterio.open(output_raster) as src:\n",
    "        clipped_image, clipped_transform = mask(\n",
    "            src, geometry, crop=True, nodata=np.nan\n",
    "        )\n",
    "        clipped_meta = src.meta.copy()\n",
    "        clipped_meta.update({\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"height\": clipped_image.shape[1],\n",
    "            \"width\": clipped_image.shape[2],\n",
    "            \"transform\": clipped_transform,\n",
    "            \"nodata\": np.nan\n",
    "        })\n",
    "\n",
    "    # Save the clipped raster to a new file\n",
    "    with rasterio.open(clipped_raster, \"w\", **clipped_meta) as dst:\n",
    "        dst.write(clipped_image[0], 1)  # Access first band\n",
    "\n",
    "    # --- Step 5: Resample the Clipped Raster to 10m Resolution ---\n",
    "    gdal.Warp(\n",
    "        resampled_raster,       # Output resampled raster path\n",
    "        clipped_raster,         # Input clipped raster\n",
    "        xRes=resolution,              # Set pixel size in x direction\n",
    "        yRes=resolution,              # Set pixel size in y direction\n",
    "        resampleAlg=gdal.GRA_Bilinear, # Bilinear interpolation for resampling\n",
    "        targetAlignedPixels=True,     # Align pixels to the grid\n",
    "        dstNodata=np.nan              # Set NoData value to NaN\n",
    "    )\n",
    "\n",
    "    os.remove(output_raster)\n",
    "    os.remove(clipped_raster)\n",
    "    print(f\"Resampled raster saved to: {resampled_raster}\")\n",
    "\n",
    "\n",
    "# Densify lines and extract points\n",
    "def extract_points_from_contours(gdf, spacing, z_field):\n",
    "    points = []\n",
    "    depths = []\n",
    "    for idx, row in gdf.iterrows():\n",
    "        line = row.geometry\n",
    "        depth = row[z_field]\n",
    "        # Sample points along the line at a regular interval\n",
    "        for i in np.arange(0, line.length, spacing):\n",
    "            point = line.interpolate(i)  # Interpolate point at distance `i`\n",
    "            points.append(point)\n",
    "            depths.append(depth)\n",
    "    return points, depths\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query bathy data\n",
    "AVAILABLE FIELD NAMES:\n",
    "- Field Name: OBJECTID, Type: esriFieldTypeOID\n",
    "- Field Name: surveyjobidpk, Type: esriFieldTypeString\n",
    "- Field Name: sdsid, Type: esriFieldTypeString\n",
    "- Field Name: sdsfeaturename, Type: esriFieldTypeString\n",
    "- Field Name: sdsmetadataid, Type: esriFieldTypeString\n",
    "- Field Name: surveytype, Type: esriFieldTypeString\n",
    "- Field Name: channelareaidfk, Type: esriFieldTypeString\n",
    "- Field Name: dateuploaded, Type: esriFieldTypeDate\n",
    "- Field Name: usacedistrictcode, Type: esriFieldTypeString\n",
    "- Field Name: surveydatestart, Type: esriFieldTypeDate\n",
    "- Field Name: surveydateend, Type: esriFieldTypeDate\n",
    "- Field Name: sourcedatalocation, Type: esriFieldTypeString\n",
    "- Field Name: sourceprojection, Type: esriFieldTypeString\n",
    "- Field Name: mediaidfk, Type: esriFieldTypeString\n",
    "- Field Name: projectedarea, Type: esriFieldTypeDouble\n",
    "- Field Name: sdsfeaturedescription, Type: esriFieldTypeString\n",
    "- Field Name: dateloadedenterprise, Type: esriFieldTypeDate\n",
    "- Field Name: datenotified, Type: esriFieldTypeDate\n",
    "- Field Name: sourcedatacontent, Type: esriFieldTypeString\n",
    "- Field Name: plotsheetlocation, Type: esriFieldTypeString\n",
    "- Field Name: sourceagency, Type: esriFieldTypeString\n",
    "- Field Name: globalid, Type: esriFieldTypeGlobalID\n",
    "- Field Name: Shape__Area, Type: esriFieldTypeDouble\n",
    "- Field Name: Shape__Length, Type: esriFieldTypeDouble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the model, will probably want to include options for with:\n",
    "- usace district\n",
    "- time of year (date and season)\n",
    "- NCF ID\n",
    "- survey type (single vs dual beam; XC, BD, AD, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate search parameters for eHydro\n",
    "\n",
    "s2_cloud_cov = 20 ## percentage of clouds in sentinel-2 multispectral imagery, less means you see more surface\n",
    "search_date = '2018-01-01'  # Date threshold, getting data from 2018 to present\n",
    "usace_code = \"CESWG\"        # Galveston District (for now)\n",
    "\n",
    "NUM_OF_QUERIES = 3          # number of iterations for the request to run\n",
    "QUERY_TIME_DELAY = 2        # query time delay in seconds, used when requesting all features\n",
    "URL = \"https://services7.arcgis.com/n1YM8pTrFmm7L4hs/ArcGIS/rest/services/eHydro_Survey_Data/FeatureServer/0/query\"\n",
    "DOWNLOAD_DIR = f'/home/clay/Documents/SDB/{usace_code}/bathy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the initial query\n",
    "params = {\n",
    "    'where': f\"surveydatestart >= '{search_date}' AND usacedistrictcode='{usace_code}'\",\n",
    "    'outFields': '*',  # Retrieve all fields\n",
    "    'resultRecordCount': 2000,  # Maximum records per request\n",
    "    'resultOffset': 0,  # Starting offset\n",
    "    'f': 'json',  # Output format\n",
    "    'outSR': '4326',  # Spatial reference\n",
    "}\n",
    "\n",
    "all_features = []\n",
    "\n",
    "for i in range(NUM_OF_QUERIES):\n",
    "    response = requests.get(URL, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        features = data.get('features', [])\n",
    "        if not features:\n",
    "            break\n",
    "        all_features.extend(features)\n",
    "        params['resultOffset'] += params['resultRecordCount']\n",
    "        print(f\"Retrieved {len(features)} features.\")\n",
    "        time.sleep(QUERY_TIME_DELAY)  # Delay of 1 second\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extract date and aoi from the surveys for GEE\n",
    "- plan is to iterate through the queries (probably by district code) and check to see if GEE has a corresponding Sentinel-2 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "geeinfo = {}\n",
    "dates = []\n",
    "for feature in all_features:\n",
    "    dates.append(ehydro_date_convert(feature['attributes']['surveydatestart']))\n",
    "    area = ee.Geometry.Polygon(feature['geometry']['rings'][0])\n",
    "\n",
    "    date_tuple = get_gee_search_dates(feature['attributes']['surveydatestart'])\n",
    "\n",
    "    geeinfo[feature['attributes']['surveyjobidpk']] = [area, date_tuple]\n",
    "surveykeys = list(geeinfo.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Iterate through responses and check if GEE has corresponding image(s)\n",
    "- if not, the response will be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for survey, items in geeinfo.items():\n",
    "    aoi = items[0]\n",
    "    dates = items[1]\n",
    "\n",
    "    coll = get_s2_sr_cld_col(aoi, dates[0], dates[1], s2_cloud_cov)\n",
    "\n",
    "    if coll.size().getInfo() > 0:\n",
    "        geeinfo[survey].append(coll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all surveys that have initial images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodsurveys = []\n",
    "for survey, items in geeinfo.items():\n",
    "    if len(items) > 2:\n",
    "        goodsurveys.append(survey)\n",
    "\n",
    "if len(goodsurveys) == 0:\n",
    "    print('No appropriate images were found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Extract the eHydro bathy data download urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bathyinfo = {}\n",
    "for i, feature in enumerate(all_features):\n",
    "    bathyinfo[surveykeys[i]] = feature['attributes']['sourcedatalocation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Download the eHydro data locally for training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "for survey in goodsurveys:\n",
    "    file_path = os.path.join(DOWNLOAD_DIR, f\"{survey}.zip\")\n",
    "    try:\n",
    "        download_file(bathyinfo[survey], file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {bathyinfo[survey]}: {e}\")\n",
    "\n",
    "print('='*250)\n",
    "print(\"All files downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unzip downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipnames = [f[:-4] for f in os.listdir(DOWNLOAD_DIR) if f.endswith('.zip')]\n",
    "if len(zipnames) > 0:\n",
    "    for name in zipnames:\n",
    "        zipfile_path = os.path.join(DOWNLOAD_DIR, f'{name}.zip')\n",
    "        with zipfile.ZipFile(zipfile_path,'r') as zip_ref:\n",
    "            zip_ref.extractall(zipfile_path[:-4])\n",
    "            os.remove(zipfile_path)\n",
    "    surveynames = [f for f in os.listdir(DOWNLOAD_DIR) if not f.startswith('.')]\n",
    "else:\n",
    "    surveynames = [f for f in os.listdir(DOWNLOAD_DIR) if not f.startswith('.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the .gdb files from the eHydro data\n",
    "- will use the Bathymetry_Vector multipolygon shapefile to create bathymetry rasters at 10-meter spatial resolution to match with Sentinel-2. Each polygon in the shapefiles represents a mean depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdbinfo = {}\n",
    "for name in surveynames:\n",
    "    folder_path = os.path.join(DOWNLOAD_DIR, name)\n",
    "    gdb_file = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.gdb')][0]\n",
    "    layers = fiona.listlayers(gdb_file)\n",
    "    bathyvector = gpd.read_file(gdb_file, layer='Bathymetry_Vector')\n",
    "    # contours = gpd.read_file(gdb_file, layer=\"ElevationContour_ALL\")\n",
    "\n",
    "    gdbinfo[name] = bathyvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_natural_neighbor_with_mask(gdf, output_file, resolution=10):\n",
    "    \"\"\"\n",
    "    Test Natural Neighbor Interpolation with masking to polygon boundaries.\n",
    "    Save the raster output reprojected to EPSG:4326.\n",
    "\n",
    "    Args:\n",
    "        gdf (GeoDataFrame): Input GeoDataFrame with 'geometry' and 'depthMean' columns.\n",
    "        output_file (str): Path to save the generated raster (GeoTIFF).\n",
    "        resolution (int): Resolution of the output raster (e.g., 10 for 10m).\n",
    "\n",
    "    Returns:\n",
    "        None: Saves raster to the specified file.\n",
    "    \"\"\"\n",
    "    if gdf.crs is None or not gdf.crs.is_projected:\n",
    "        raise ValueError(\"GeoDataFrame must have a defined and projected CRS.\")\n",
    "\n",
    "    # Step 1: Prepare the data for interpolation\n",
    "    gdf[\"centroid\"] = gdf.geometry.centroid\n",
    "    x = gdf.centroid.x.values\n",
    "    y = gdf.centroid.y.values\n",
    "    z = gdf[\"depthMean\"].values\n",
    "\n",
    "    # Step 2: Determine the bounds and grid for rasterization\n",
    "    xmin, ymin, xmax, ymax = gdf.total_bounds\n",
    "    grid_x, grid_y = np.meshgrid(\n",
    "        np.arange(xmin, xmax, resolution),\n",
    "        np.arange(ymin, ymax, resolution)\n",
    "    )\n",
    "\n",
    "    # Step 3: Perform Natural Neighbor Interpolation\n",
    "    raster = griddata(\n",
    "        points=(x, y),  # Input points\n",
    "        values=z,       # Depth values at input points\n",
    "        xi=(grid_x, grid_y),  # Grid coordinates\n",
    "        method=\"nearest\"      # Natural Neighbor interpolation\n",
    "    )\n",
    "\n",
    "    # Step 4: Create raster transform\n",
    "    transform = from_origin(xmin, ymax, resolution, resolution)\n",
    "\n",
    "    # Step 5: Create a mask from polygon geometries\n",
    "    mask = rasterize(\n",
    "        [(geom, 1) for geom in gdf.geometry],\n",
    "        out_shape=raster.shape,\n",
    "        transform=transform,\n",
    "        fill=0,\n",
    "        dtype=\"uint8\",\n",
    "    )\n",
    "    # Apply mask: Set values outside the polygons to NaN\n",
    "    raster = np.where(mask == 1, raster, np.nan)\n",
    "\n",
    "    # Step 6: Reproject the raster in memory to EPSG:4326\n",
    "    src_crs = gdf.crs\n",
    "    dst_crs = \"EPSG:4326\"\n",
    "\n",
    "    # Define destination raster dimensions (same resolution, different CRS)\n",
    "    with rasterio.Env():\n",
    "        dst_transform, width, height = rasterio.warp.calculate_default_transform(\n",
    "            src_crs, dst_crs, raster.shape[1], raster.shape[0], *gdf.total_bounds\n",
    "        )\n",
    "        dst_raster = np.empty((height, width), dtype=\"float32\")\n",
    "\n",
    "        reproject(\n",
    "            source=raster,\n",
    "            destination=dst_raster,\n",
    "            src_transform=transform,\n",
    "            src_crs=src_crs,\n",
    "            dst_transform=dst_transform,\n",
    "            dst_crs=dst_crs,\n",
    "            resampling=Resampling.bilinear,\n",
    "        )\n",
    "\n",
    "    # Step 7: Save the reprojected raster to GeoTIFF\n",
    "    with rasterio.open(\n",
    "        output_file,\n",
    "        \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=dst_raster.shape[0],\n",
    "        width=dst_raster.shape[1],\n",
    "        count=1,\n",
    "        dtype=\"float32\",\n",
    "        crs=dst_crs,\n",
    "        transform=dst_transform,\n",
    "        nodata=np.nan,\n",
    "    ) as dst:\n",
    "        dst.write(dst_raster, 1)\n",
    "\n",
    "    print(f\"Reprojected raster saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_natural_neighbor_with_mask(gdbinfo[surveynames[500]], f'/home/clay/Documents/SDB/test_{surveynames[500]}.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(f'/home/clay/Documents/SDB/test_{surveynames[-2]}.tif') as src:\n",
    "    raster = src.read(1)\n",
    "\n",
    "plt.imshow(raster, cmap='viridis', extent=(xmin, xmax, ymin, ymax))\n",
    "plt.colorbar(label=\"Depth (ft)\")\n",
    "plt.title(\"Rasterized Depth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the .xyz file from each download and apply kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyzinfo={}\n",
    "for name in surveynames:\n",
    "    folder_path = os.path.join(DOWNLOAD_DIR, name)\n",
    "    xyzfile = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.XYZ')][0]\n",
    "    gdb_file = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.gdb')][0]\n",
    "    layers = fiona.listlayers(gdb_file)\n",
    "    bathyvector = gpd.read_file(gdb_file, layer='Bathymetry_Vector')\n",
    "\n",
    "    xyzinfo[name] = [xyzfile, bathyvector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the XYZ data\n",
    "survey = surveynames[950]\n",
    "xyzdata = pd.read_csv(xyzinfo[survey][0], sep='\\\\s+', header=None, names=[\"x\", \"y\", \"z\"])\n",
    "\n",
    "# Load the AOI GeoDataFrame (multipolygon shapefiles)\n",
    "aoi_gdf = xyzinfo[survey][1]\n",
    "aoi_gdf = aoi_gdf.to_crs(xyzinfo[survey][1].crs)  # Ensure AOI and .xyz share the same CRS\n",
    "\n",
    "# Step 2: Clip the .xyz data to the AOI polygons\n",
    "geometry = [Point(x, y) for x, y in zip(xyzdata[\"x\"], xyzdata[\"y\"])]\n",
    "xyz_gdf = gpd.GeoDataFrame(xyzdata, geometry=geometry, crs=xyzinfo[survey][1].crs)\n",
    "clipped_xyz_gdf = gpd.clip(xyz_gdf, aoi_gdf)  # Clip .xyz points to AOI polygons\n",
    "\n",
    "# Extract the clipped points\n",
    "clipped_xyz = clipped_xyz_gdf[[\"x\", \"y\", \"z\"]]\n",
    "\n",
    "# Step 3: Define the grid for interpolation\n",
    "resolution = 10 * 3.28084  # Convert 10 meters to feet\n",
    "x_min, x_max = clipped_xyz[\"x\"].min(), clipped_xyz[\"x\"].max()\n",
    "y_min, y_max = clipped_xyz[\"y\"].min(), clipped_xyz[\"y\"].max()\n",
    "\n",
    "x_grid = np.arange(x_min, x_max + resolution, resolution)\n",
    "y_grid = np.arange(y_min, y_max + resolution, resolution)\n",
    "grid_x, grid_y = np.meshgrid(x_grid, y_grid)\n",
    "\n",
    "# Step 4: Perform Interpolation\n",
    "raster = griddata(\n",
    "    points=clipped_xyz[[\"x\", \"y\"]].values,  # Correct slicing for DataFrame columns\n",
    "    values=clipped_xyz[\"z\"].values,\n",
    "    xi=(grid_x, grid_y),\n",
    "    method=\"linear\"  # Interpolate between points\n",
    ")\n",
    "\n",
    "# Step 5: Mask the Raster with AOI Polygons\n",
    "# Rasterize the AOI polygons\n",
    "transform = from_origin(x_min, y_max, resolution, resolution)\n",
    "aoi_mask = rasterize(\n",
    "    [(geom, 1) for geom in aoi_gdf.geometry],\n",
    "    out_shape=raster.shape,\n",
    "    transform=transform,\n",
    "    fill=255,  # Outside AOI is 0\n",
    "    dtype=\"uint8\",\n",
    ")\n",
    "\n",
    "# Apply the mask: Set values outside AOI to NaN\n",
    "raster = np.where(aoi_mask == 1, raster, np.nan)\n",
    "\n",
    "# Step 6: Visualize the Raster\n",
    "plt.imshow(\n",
    "    raster,\n",
    "    extent=(x_min, x_max, y_min, y_max),\n",
    "    origin=\"lower\",\n",
    "    cmap=\"viridis\"\n",
    ")\n",
    "plt.colorbar(label=\"Depth (ft)\")\n",
    "plt.title(\"Rasterized Bathymetry (Clipped to AOI)\")\n",
    "plt.xlabel(\"X (ft)\")\n",
    "plt.ylabel(\"Y (ft)\")\n",
    "plt.show()\n",
    "\n",
    "# Step 7: Save and Reproject the Raster to EPSG:4326\n",
    "output_crs = \"EPSG:4326\"\n",
    "\n",
    "# First, calculate the transform for the target CRS\n",
    "dst_transform, width, height = calculate_default_transform(\n",
    "    xyzinfo[survey][1].crs,  # Original CRS of the .xyz data\n",
    "    output_crs,\n",
    "    raster.shape[1],  # Width in pixels\n",
    "    raster.shape[0],  # Height in pixels\n",
    "    *[x_min, y_min, x_max, y_max],  # Bounds of the original raster\n",
    ")\n",
    "\n",
    "# Create an empty array for the reprojected raster\n",
    "reprojected_raster = np.empty((height, width), dtype=\"float32\")\n",
    "\n",
    "# Perform the reprojection\n",
    "with rasterio.Env():\n",
    "    reproject(\n",
    "        source=raster,\n",
    "        destination=reprojected_raster,\n",
    "        src_transform=transform,\n",
    "        src_crs=xyzinfo[survey][1].crs,  # Original CRS\n",
    "        dst_transform=dst_transform,\n",
    "        dst_crs=output_crs,  # Target CRS\n",
    "        resampling=Resampling.bilinear,  # Choose resampling method\n",
    "    )\n",
    "\n",
    "# Step 8: Rasterize the AOI in EPSG:4326\n",
    "aoi_gdf_epsg4326 = aoi_gdf.to_crs(output_crs)  # Reproject AOI to EPSG:4326\n",
    "aoi_mask_epsg4326 = rasterize(\n",
    "    [(geom, 1) for geom in aoi_gdf_epsg4326.geometry],\n",
    "    out_shape=(height, width),\n",
    "    transform=dst_transform,\n",
    "    fill=0,  # Outside AOI is 0\n",
    "    dtype=\"uint8\",\n",
    ")\n",
    "\n",
    "# Apply the mask to the reprojected raster\n",
    "reprojected_raster = np.where(aoi_mask_epsg4326 == 1, reprojected_raster, np.nan)\n",
    "\n",
    "# Save the reprojected raster to GeoTIFF\n",
    "with rasterio.open(\n",
    "    f'/home/clay/Documents/SDB/test_{survey}_epsg4326_clipped.tif',\n",
    "    \"w\",\n",
    "    driver=\"GTiff\",\n",
    "    height=height,\n",
    "    width=width,\n",
    "    count=1,\n",
    "    dtype=\"float32\",\n",
    "    crs=output_crs,\n",
    "    transform=dst_transform,\n",
    "    nodata=np.nan,\n",
    ") as dst:\n",
    "    dst.write(reprojected_raster, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the XYZ data\n",
    "survey = surveynames[-20]\n",
    "xyzdata = pd.read_csv(xyzinfo[survey][0], sep='\\\\s+', header=None, names=[\"x\", \"y\", \"z\"])\n",
    "\n",
    "# Define the CRS (original)\n",
    "input_crs = xyzinfo[survey][1].crs\n",
    "\n",
    "# Step 1: Create a Convex Hull of the Points (Boundary)\n",
    "points = MultiPoint(xyzdata[[\"x\", \"y\"]].values)\n",
    "boundary = points.convex_hull  # Convex hull as a Shapely Polygon\n",
    "\n",
    "# Convert the boundary to GeoJSON (optional visualization)\n",
    "boundary_gdf = gpd.GeoDataFrame({\"geometry\": [boundary]}, crs=input_crs)\n",
    "\n",
    "# Step 2: Define the Grid\n",
    "resolution = 10 * 3.28084  # Convert 10 meters to feet\n",
    "x_min, x_max = xyzdata[\"x\"].min(), xyzdata[\"x\"].max()\n",
    "y_min, y_max = xyzdata[\"y\"].min(), xyzdata[\"y\"].max()\n",
    "\n",
    "x_grid = np.arange(x_min, x_max + resolution, resolution)\n",
    "y_grid = np.arange(y_min, y_max + resolution, resolution)\n",
    "grid_x, grid_y = np.meshgrid(x_grid, y_grid)\n",
    "\n",
    "# Step 3: Interpolate the Data\n",
    "raster = griddata(\n",
    "    points=xyzdata[[\"x\", \"y\"]].values,\n",
    "    values=xyzdata[\"z\"].values,\n",
    "    xi=(grid_x, grid_y),\n",
    "    method=\"nearest\"  # Interpolate between points\n",
    ")\n",
    "\n",
    "# Step 4: Rasterize the Boundary as a Mask\n",
    "transform = from_origin(x_min, y_max, resolution, resolution)\n",
    "boundary_mask = rasterize(\n",
    "    [(boundary, 1)],  # Use the convex hull \n",
    "    out_shape=raster.shape,\n",
    "    transform=transform,\n",
    "    fill=0,  # Outside boundary is 0\n",
    "    dtype=\"uint8\",\n",
    ")\n",
    "\n",
    "# Step 5: Apply the Mask to the Raster\n",
    "raster = np.where(boundary_mask == 1, raster, np.nan)  # Mask values outside the boundary\n",
    "\n",
    "# Step 6: Visualize the Raster\n",
    "plt.imshow(\n",
    "    raster,\n",
    "    extent=(x_min, x_max, y_min, y_max),\n",
    "    origin=\"lower\",\n",
    "    cmap=\"viridis\"\n",
    ")\n",
    "plt.colorbar(label=\"Depth (ft)\")\n",
    "plt.title(\"Rasterized Bathymetry (Clipped to Boundary)\")\n",
    "plt.xlabel(\"X (ft)\")\n",
    "plt.ylabel(\"Y (ft)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(\n",
    "    \"output_raster_with_boundary.tif\",\n",
    "    \"w\",\n",
    "    driver=\"GTiff\",\n",
    "    height=raster.shape[0],\n",
    "    width=raster.shape[1],\n",
    "    count=1,\n",
    "    dtype=\"float32\",\n",
    "    crs=input_crs,\n",
    "    transform=transform,\n",
    "    nodata=np.nan,\n",
    ") as dst:\n",
    "    dst.write(raster, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, go to 01b_get_s2.ipynb to use the extent of the valid data in the created bathymetry rasters to get cloud-masked Sentinel-2 L2A products from Google Earth Engine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
