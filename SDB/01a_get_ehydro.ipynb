{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is going to download eHydro bathymetry data from the USACE ArcGIS REST repository, as well as retrieve cloud masked imagery of the same location, at the same time, for training of Satellite Derived Bathymetry model(s) for the National Channel Framework (NCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import fiona\n",
    "import numpy as np\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import from_origin, from_bounds\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.mask import mask\n",
    "from datetime import datetime, timedelta\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import time\n",
    "import ee\n",
    "from osgeo import gdal\n",
    "import requests\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize(project = '') ##enter your project name here as a string to initialize exchanges with ee api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gee_search_dates(time):\n",
    "    date_obj = datetime.utcfromtimestamp(time / 1000)\n",
    "    return ((date_obj - timedelta(days=1)).strftime('%Y-%m-%d'), (date_obj + timedelta(days=1)).strftime('%Y-%m-%d'))\n",
    "\n",
    "def ehydro_date_convert(time):\n",
    "    return datetime.utcfromtimestamp(time / 1000).strftime('%Y-%m-%d')\n",
    "\n",
    "def download_file(url, destination):\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    with open(destination, 'wb') as file, tqdm(\n",
    "        desc=f\"Downloading {os.path.basename(destination)}\",\n",
    "        total=total_size,\n",
    "        unit='B',\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "    ) as bar:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            file.write(chunk)\n",
    "            bar.update(len(chunk))\n",
    "\n",
    "def get_s2_sr_cld_col(aoi, start_date, end_date, cloud_filter):\n",
    "    # Import and filter S2 SR.\n",
    "    s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date)\n",
    "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', cloud_filter)))\n",
    "\n",
    "    # Import and filter s2cloudless.\n",
    "    s2_cloudless_col = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date))\n",
    "\n",
    "    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n",
    "    combined_coll = ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n",
    "        'primary': s2_sr_col,\n",
    "        'secondary': s2_cloudless_col,\n",
    "        'condition': ee.Filter.equals(**{\n",
    "            'leftField': 'system:index',\n",
    "            'rightField': 'system:index'\n",
    "        })\n",
    "    }))\n",
    "\n",
    "    return combined_coll\n",
    "def export_rasterized_bathymetry_native_crs(gdf, outpath, resolution):\n",
    "    \"\"\"\n",
    "    Exports a rasterized bathymetry GeoDataFrame in its original CRS.\n",
    "\n",
    "    Args:\n",
    "        gdf: GeoDataFrame with bathymetry polygons and a \"depthMean\" column.\n",
    "        outpath: Output file path for the raster.\n",
    "    \"\"\"\n",
    "    # Get the bounding box and resolution\n",
    "    xmin, ymin, xmax, ymax = gdf.total_bounds\n",
    "\n",
    "    # Define the transform\n",
    "    transform = from_origin(xmin, ymax, resolution, resolution)\n",
    "\n",
    "    # Prepare raster shapes\n",
    "    shapes = [(geom, value) for geom, value in zip(gdf.geometry, gdf[\"depthMean\"])]\n",
    "\n",
    "    # Calculate the raster dimensions\n",
    "    height = int((ymax - ymin) / resolution)\n",
    "    width = int((xmax - xmin) / resolution)\n",
    "\n",
    "    # Rasterize the bathymetry data\n",
    "    raster = rasterize(\n",
    "        shapes,\n",
    "        out_shape=(height, width),\n",
    "        transform=transform,\n",
    "        fill=np.nan,  # No data outside polygons\n",
    "        dtype=\"float32\",\n",
    "    )\n",
    "\n",
    "    # Save the raster in its original CRS\n",
    "    with rasterio.open(\n",
    "        outpath,\n",
    "        \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=height,\n",
    "        width=width,\n",
    "        count=1,\n",
    "        dtype=\"float32\",\n",
    "        crs=gdf.crs,  # Keep the original CRS\n",
    "        transform=transform,\n",
    "        nodata=np.nan,\n",
    "    ) as dst:\n",
    "        dst.write(raster, 1)\n",
    "\n",
    "    print(f\"Raster in original CRS saved to {outpath}\")\n",
    "\n",
    "def visualize_raster(path):\n",
    "    with rasterio.open(path) as src:\n",
    "        bathy = src.read(1)\n",
    "        xmin, ymin, xmax, ymax = src.bounds\n",
    "    \n",
    "    plt.imshow(\n",
    "        bathy,\n",
    "        extent=(xmin, xmax, ymin, ymax),\n",
    "        origin=\"lower\",\n",
    "        cmap=\"viridis\"\n",
    "    )\n",
    "    plt.colorbar(label=\"Depth (Feet)\")\n",
    "    plt.title(\"Rasterized Bathymetry\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query bathy data\n",
    "AVAILABLE FIELD NAMES:\n",
    "- Field Name: OBJECTID, Type: esriFieldTypeOID\n",
    "- Field Name: surveyjobidpk, Type: esriFieldTypeString\n",
    "- Field Name: sdsid, Type: esriFieldTypeString\n",
    "- Field Name: sdsfeaturename, Type: esriFieldTypeString\n",
    "- Field Name: sdsmetadataid, Type: esriFieldTypeString\n",
    "- Field Name: surveytype, Type: esriFieldTypeString\n",
    "- Field Name: channelareaidfk, Type: esriFieldTypeString\n",
    "- Field Name: dateuploaded, Type: esriFieldTypeDate\n",
    "- Field Name: usacedistrictcode, Type: esriFieldTypeString\n",
    "- Field Name: surveydatestart, Type: esriFieldTypeDate\n",
    "- Field Name: surveydateend, Type: esriFieldTypeDate\n",
    "- Field Name: sourcedatalocation, Type: esriFieldTypeString\n",
    "- Field Name: sourceprojection, Type: esriFieldTypeString\n",
    "- Field Name: mediaidfk, Type: esriFieldTypeString\n",
    "- Field Name: projectedarea, Type: esriFieldTypeDouble\n",
    "- Field Name: sdsfeaturedescription, Type: esriFieldTypeString\n",
    "- Field Name: dateloadedenterprise, Type: esriFieldTypeDate\n",
    "- Field Name: datenotified, Type: esriFieldTypeDate\n",
    "- Field Name: sourcedatacontent, Type: esriFieldTypeString\n",
    "- Field Name: plotsheetlocation, Type: esriFieldTypeString\n",
    "- Field Name: sourceagency, Type: esriFieldTypeString\n",
    "- Field Name: globalid, Type: esriFieldTypeGlobalID\n",
    "- Field Name: Shape__Area, Type: esriFieldTypeDouble\n",
    "- Field Name: Shape__Length, Type: esriFieldTypeDouble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the model, will probably want to include options for with:\n",
    "- usace district\n",
    "- time of year (date and season)\n",
    "- NCF ID\n",
    "- survey type (single vs dual beam; XC, BD, AD, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate search parameters for eHydro\n",
    "\n",
    "s2_cloud_cov = 20 ## percentage of clouds in sentinel-2 multispectral imagery, less means you see more surface\n",
    "search_date = '2018-01-01'  # Date threshold, getting data from 2018 to present\n",
    "usace_code = \"CESWG\"        # Galveston District (for now)\n",
    "\n",
    "NUM_OF_QUERIES = 3          # number of iterations for the request to run\n",
    "QUERY_TIME_DELAY = 2        # query time delay in seconds, used when requesting all features\n",
    "URL = \"https://services7.arcgis.com/n1YM8pTrFmm7L4hs/ArcGIS/rest/services/eHydro_Survey_Data/FeatureServer/0/query\"\n",
    "DOWNLOAD_DIR = f'/home/clay/Documents/SDB/{usace_code}/bathy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the initial query\n",
    "params = {\n",
    "    'where': f\"surveydatestart >= '{search_date}' AND usacedistrictcode='{usace_code}'\",\n",
    "    'outFields': '*',  # Retrieve all fields\n",
    "    'resultRecordCount': 2000,  # Maximum records per request\n",
    "    'resultOffset': 0,  # Starting offset\n",
    "    'f': 'json',  # Output format\n",
    "    'outSR': '4326',  # Spatial reference\n",
    "}\n",
    "\n",
    "all_features = []\n",
    "\n",
    "for i in range(NUM_OF_QUERIES):\n",
    "    response = requests.get(URL, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        features = data.get('features', [])\n",
    "        if not features:\n",
    "            break\n",
    "        all_features.extend(features)\n",
    "        params['resultOffset'] += params['resultRecordCount']\n",
    "        print(f\"Retrieved {len(features)} features.\")\n",
    "        time.sleep(QUERY_TIME_DELAY)  # Delay of 1 second\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extract date and aoi from the surveys for GEE\n",
    "- plan is to iterate through the queries (probably by district code) and check to see if GEE has a corresponding Sentinel-2 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "geeinfo = {}\n",
    "dates = []\n",
    "for feature in all_features:\n",
    "    dates.append(ehydro_date_convert(feature['attributes']['surveydatestart']))\n",
    "    area = ee.Geometry.Polygon(feature['geometry']['rings'][0])\n",
    "\n",
    "    date_tuple = get_gee_search_dates(feature['attributes']['surveydatestart'])\n",
    "\n",
    "    geeinfo[feature['attributes']['surveyjobidpk']] = [area, date_tuple]\n",
    "surveykeys = list(geeinfo.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Iterate through responses and check if GEE has corresponding image(s)\n",
    "- if not, the response will be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for survey, items in geeinfo.items():\n",
    "    aoi = items[0]\n",
    "    dates = items[1]\n",
    "\n",
    "    coll = get_s2_sr_cld_col(aoi, dates[0], dates[1], s2_cloud_cov)\n",
    "\n",
    "    if coll.size().getInfo() > 0:\n",
    "        geeinfo[survey].append(coll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all surveys that have initial images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodsurveys = []\n",
    "for survey, items in geeinfo.items():\n",
    "    if len(items) > 2:\n",
    "        goodsurveys.append(survey)\n",
    "\n",
    "if len(goodsurveys) == 0:\n",
    "    print('No appropriate images were found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Extract the eHydro bathy data download urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bathyinfo = {}\n",
    "for i, feature in enumerate(all_features[:10]):\n",
    "    bathyinfo[surveykeys[i]] = feature['attributes']['sourcedatalocation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Download the eHydro data locally for training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "for survey in goodsurveys:\n",
    "    file_path = os.path.join(DOWNLOAD_DIR, f\"{survey}.zip\")\n",
    "    try:\n",
    "        download_file(bathyinfo[survey], file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {bathyinfo[survey]}: {e}\")\n",
    "\n",
    "print('='*250)\n",
    "print(\"All files downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unzip downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipnames = [f[:-4] for f in os.listdir(DOWNLOAD_DIR) if f.endswith('.zip')]\n",
    "if len(zipnames) > 0:\n",
    "    for name in zipnames:\n",
    "        zipfile_path = os.path.join(DOWNLOAD_DIR, f'{name}.zip')\n",
    "        with zipfile.ZipFile(zipfile_path,'r') as zip_ref:\n",
    "            zip_ref.extractall(zipfile_path[:-4])\n",
    "            os.remove(zipfile_path)\n",
    "    surveynames = [f for f in os.listdir(DOWNLOAD_DIR) if not f.startswith('.')]\n",
    "else:\n",
    "    surveynames = [f for f in os.listdir(DOWNLOAD_DIR) if not f.startswith('.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the .gdb file, specifically the \"Bethymetry_Vector\" layer and the \"depthMean\" and \"geometry\" columns\n",
    "- gets bathymetry raster in the native crs within eHydro\n",
    "- Sentinel-2 retreival notebook will get the bbox and convert to EPSG:4326 for image searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdbinfo={}\n",
    "output_dir = DOWNLOAD_DIR + '_rasters'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for name in surveynames:\n",
    "    folder_path = os.path.join(DOWNLOAD_DIR, name)\n",
    "    gdbfile = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.gdb')][0]\n",
    "    layers = fiona.listlayers(gdbfile)\n",
    "\n",
    "    gdf = gpd.read_file(gdbfile, layer='Bathymetry_Vector')\n",
    "\n",
    "    outfile = os.path.join(output_dir, f\"{name}.tif\")\n",
    "\n",
    "    export_rasterized_bathymetry_native_crs(gdf, outfile, 32.8084)  # 32.8084 ft roughly equal to 10 meters\n",
    "    gdbinfo[name] = [gdf, outfile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in gdbinfo.keys():\n",
    "#     visualize_raster(gdbinfo[key][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, go to 01b_get_s2.ipynb to use the extent of the valid data in the created bathymetry rasters to get cloud-masked Sentinel-2 L2A products from Google Earth Engine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
