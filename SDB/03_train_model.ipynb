{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be used to develop and compare regression models to correlate the eHydro bathymetric surveys with cloud-masked Sentinel-2 surface refelctances. These models will hopefully provide USACE and the eHydro program with a new, robust, accurate tool for unmanned bathymetric estiamtes. This will be possible at 10-meter resolution at a frequency of up to 5 days.\n",
    "- First starting with XGBoost, RF, and SVM-RBF regressors in the SWG. May try some NN as well\n",
    "- band maths here with the green and blue bands (short wavelengths penetrate water columns more)\n",
    "- include some metadata (AD, CX, BD? Single vs dual beam?)? Will look into more that may be beneficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import rasterio\n",
    "from rasterio.warp import reproject, Resampling, calculate_default_transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize an array\n",
    "def normalize(array):\n",
    "    return (array - np.nanmin(array)) / (np.nanmax(array) - np.nanmin(array))\n",
    "\n",
    "# Function to read .tif files\n",
    "def read_tif(file_path):\n",
    "    with rasterio.open(file_path) as src:\n",
    "        array = src.read()  # Read all bands\n",
    "        profile = src.profile  # Get metadata (optional, for reference)\n",
    "    return array, profile\n",
    "\n",
    "def extract_raster_data(pair_tuple):\n",
    "    images_data = []\n",
    "\n",
    "    for paths in pair_tuple:\n",
    "        bathy_path = paths[1]\n",
    "        s2_path = paths[0]\n",
    "\n",
    "        # --- Step 1: Open Bathymetry Raster ---\n",
    "        with rasterio.open(bathy_path) as bathy:\n",
    "            bathy_data = bathy.read(1)  # Bathymetry data (band 1)\n",
    "            bathy_nodata = bathy.nodata  # NoData value\n",
    "            bathy_transform = bathy.transform\n",
    "            bathy_shape = bathy.shape\n",
    "\n",
    "        # --- Step 2: Open Sentinel-2 Raster ---\n",
    "        with rasterio.open(s2_path) as s2:\n",
    "            if s2.shape != bathy_shape or s2.transform != bathy_transform:\n",
    "                raise ValueError(\n",
    "                    f\"Inconsistent shapes or transforms:\\n\"\n",
    "                    f\"Bathymetry Shape: {bathy_shape}, Sentinel-2 Shape: {s2.shape}.\\n\"\n",
    "                    f\"Bathymetry Transform: {bathy_transform}, Sentinel-2 Transform: {s2.transform}.\\n\"\n",
    "                    f\"Ensure rasters have identical extents and resolutions.\"\n",
    "                )\n",
    "\n",
    "            # Read Sentinel-2 bands\n",
    "            bands = {\n",
    "                \"red\": normalize(s2.read(3)),\n",
    "                \"green\": normalize(s2.read(2)),\n",
    "                \"blue\": normalize(s2.read(1)),\n",
    "                \"nir\": normalize(s2.read(4))\n",
    "            }\n",
    "            s2_nodata = s2.nodata  # Sentinel-2 NoData value\n",
    "\n",
    "        # --- Step 3: Flatten Bands ---\n",
    "        flat_bathy = bathy_data.flatten()\n",
    "        flat_bands = {key: band.flatten() for key, band in bands.items()}\n",
    "\n",
    "        # --- Step 4: Mask NoData Values ---\n",
    "        valid_mask = (\n",
    "            ~np.isnan(flat_bathy) &  # Valid bathy pixels\n",
    "            (flat_bathy != bathy_nodata)  # Exclude bathy NoData\n",
    "        )\n",
    "\n",
    "        for band in flat_bands.values():\n",
    "            valid_mask &= (band != s2_nodata)  # Exclude Sentinel-2 NoData\n",
    "\n",
    "        # Apply the mask\n",
    "        valid_bathy = flat_bathy[valid_mask].reshape(-1, 1)  # Reshape bathy to (n_pixels, 1)\n",
    "        valid_features = np.column_stack([band[valid_mask] for band in flat_bands.values()])\n",
    "\n",
    "        # --- Step 5: Combine Features and Targets ---\n",
    "        combined_features = np.concatenate((valid_bathy, valid_features), axis=1)  # Combine bathy and S2\n",
    "        images_data.append((combined_features, valid_bathy.flatten()))  # Flatten bathy for targets\n",
    "\n",
    "    return images_data\n",
    "\n",
    "def prepare_data(pairs):\n",
    "    X = []\n",
    "    y = []\n",
    "    for features, targets in pairs:\n",
    "        X.append(features[:,1:])  # Keep features from this pair\n",
    "        y.append(targets)   # Keep corresponding targets\n",
    "    return np.vstack(X), np.hstack(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2_PATH = '/home/clay/Documents/SDB/CESWG/processed/S2'\n",
    "BATHY_PATH = '/home/clay/Documents/SDB/CESWG/processed/Bathy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paths to each image for each eHydro-Sentinel2 image pair\n",
    "\n",
    "images = []\n",
    "for name in [f[:-4] for f in os.listdir(BATHY_PATH) if f.endswith('.tif')]:\n",
    "    images.append((os.path.join(S2_PATH, f'{name}.tif'), os.path.join(BATHY_PATH, f'{name}.tif')))\n",
    "\n",
    "images_data = extract_raster_data(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel-2 band manipulation and including other data (good reference is Chybicki et al. 2023)\n",
    "- Blue Green ratios (Blue/Green, Green/Blue, looking for others)\n",
    "- Stumpf log ratio of blue green (https://aslopubs.onlinelibrary.wiley.com/doi/10.4319/lo.2003.48.1_part_2.0547)\n",
    "- Coordinates\n",
    "- NCF channel ID name\n",
    "- Survey type\n",
    "- Single vs Double beam\n",
    "- Spectral indices?? (NDVI and NDWI, NDWI could make sense but would leave this to the end)\n",
    "\n",
    "\n",
    "The Chybicki 2023 paper had models perform extremely well when including all bands, the Stumpf log ratio, and the UTM coordinates. I think including more blue-green ratios and the survey type as well will increase my accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blue_green_ratios(pairs):\n",
    "    s2 = pairs[0][0][:, 1:]     # in order B, G, R, NIR\n",
    "    bathy = pairs[0][1]\n",
    "\n",
    "    bluegreen = images_data[0][0][:, 1] / images_data[0][0][:, 2] \n",
    "    greenblue = images_data[0][0][:, 2] / images_data[0][0][:, 1] \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create simple ratios of blue/green and green/blue\n",
    "# blue penetrates, while green attenuates\n",
    "# can check correlation between features and apply PCA if needed\n",
    "\n",
    "bluegreen = images_data[0][0][:, 1] / images_data[0][0][:, 2] \n",
    "greenblue = images_data[0][0][:, 2] / images_data[0][0][:, 1] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stumpf log ratio\n",
    "lograt = np.log(images_data[0][0][:, 1]) / np.log(images_data[0][0][:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates (of survey or S2, they should match)\n",
    "# extract UTM coords\n",
    "\n",
    "file_name = [os.path.join(S2_PATH, f) for f in os.listdir(S2_PATH)][0]\n",
    "with rasterio.open(file_name) as src:\n",
    "            band1 = src.read(1)\n",
    "            print('Band1 has shape', band1.shape)\n",
    "            height = band1.shape[0]\n",
    "            width = band1.shape[1]\n",
    "            cols, rows = np.meshgrid(np.arange(width), np.arange(height))\n",
    "            xs, ys = rasterio.transform.xy(src.transform, rows, cols)\n",
    "            lons= np.array(xs)\n",
    "            lats = np.array(ys)\n",
    "            print('lons shape', lons.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NCF Channel ID from the file names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survey type from the name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single vs double beam?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the correlation between each feature\n",
    "\n",
    "df = pd.DataFrame(X_train, columns=['Blue', 'Green', 'Red', 'NIR'])\n",
    "df['Bathymetry'] = y_train\n",
    "\n",
    "# Correlation matrix\n",
    "print(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for test_train_split\n",
    "- k-fold segmentation for training?\n",
    "- tiling of images or whole images?\n",
    "- try 3 regression models for now: SVM, RF, and XGBoost\n",
    "- may try ElasticNet from cuML, and some shallow NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define split ratios\n",
    "train_ratio = 0.7  # 70% for training\n",
    "val_ratio = 0.2    # 20% for validation\n",
    "test_ratio = 0.1   # 10% for testing\n",
    "\n",
    "train_pairs, temp_pairs = train_test_split(images_data, test_size=(1 - train_ratio), random_state=42)\n",
    "val_pairs, test_pairs = train_test_split(temp_pairs, test_size=(test_ratio / (val_ratio + test_ratio)), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for each split\n",
    "X_train, y_train = prepare_data(train_pairs)\n",
    "X_val, y_val = prepare_data(val_pairs)\n",
    "X_test, y_test = prepare_data(test_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define and configure the XGBoost regressor\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=200,      # Number of trees\n",
    "    learning_rate=0.1,     # Learning rate\n",
    "    max_depth=6,           # Maximum tree depth\n",
    "    random_state=42        # Random seed for reproducibility\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],  # For validation during training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, xgb_predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, xgb_predictions))\n",
    "mae = mean_absolute_error(y_test, xgb_predictions)\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. RF Regression:\n",
    "- R2 Score: 0.3354\n",
    "- RMSE: 12.8882\n",
    "- MAE: 9.9499"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, rf_predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, rf_predictions))\n",
    "mae = mean_absolute_error(y_test, rf_predictions)\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. SVM regression:\n",
    "- R2 Score: \n",
    "- RMSE: \n",
    "- MAE: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine Model\n",
    "svm_model = SVR()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "\n",
    "r2 = r2_score(y_test, svm_predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, svm_predictions))\n",
    "mae = mean_absolute_error(y_test, svm_predictions)\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
