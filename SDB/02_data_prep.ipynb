{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use this notebook to extract some of the needed data for training the model. Assuming the bathy data is downloaded from 01_get_data.ipynb, and the imagery is downloaded from 01b_get_s2_SAFE.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling, transform_bounds, transform as rio_transform\n",
    "from rasterio import Affine\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_acolite_images(rhow_paths, rrs_paths, spm_tur_paths):\n",
    "    def mask_image(image_path):\n",
    "        with rasterio.open(image_path) as src:\n",
    "            meta = src.meta.copy()\n",
    "            meta['descriptions'] = src.descriptions\n",
    "            bands = [src.read(i) for i in range(1, src.count + 1)]\n",
    "            max_val = bands[0].max()\n",
    "            masked_bands = [np.where(band == max_val, np.nan, band) for band in bands]\n",
    "        return masked_bands, meta\n",
    "\n",
    "    def process_and_write(paths):\n",
    "        masked_files = []\n",
    "        for path in paths:\n",
    "            masked_bands, meta = mask_image(path)\n",
    "            meta['count'] = len(masked_bands)\n",
    "            mask_path = path.replace('stacked', 'masked')\n",
    "            os.makedirs(os.path.dirname(mask_path), exist_ok=True)\n",
    "            meta['dtype'] = 'float32'\n",
    "            with rasterio.open(mask_path, 'w', **meta) as dst:\n",
    "                for i, band in enumerate(masked_bands, start=1):\n",
    "                    dst.write(band.astype(np.float32), i)\n",
    "                    # Reassign original band description if available\n",
    "                    if meta.get('descriptions') and len(meta['descriptions']) >= i:\n",
    "                        dst.set_band_description(i, meta['descriptions'][i-1])\n",
    "            masked_files.append(mask_path)\n",
    "        return masked_files\n",
    "\n",
    "    masked_rhow_files = process_and_write(rhow_paths)\n",
    "    masked_rrs_files = process_and_write(rrs_paths)\n",
    "    masked_spm_files = process_and_write(spm_tur_paths)\n",
    "    \n",
    "    return masked_rhow_files, masked_rrs_files, masked_spm_files\n",
    "\n",
    "def reproject_acolite(bathy_raster, paths, target_resolution_m=10):\n",
    "    \"\"\"\n",
    "    Reprojects a list of rasters (paths) to a common grid defined by the union \n",
    "    of their extents in the target CRS (from bathy_raster) using a target resolution\n",
    "    (in meters, then converted to feet). The output rasters are saved to disk with \n",
    "    'masked' replaced by 'projected' in their filenames.\n",
    "    \n",
    "    Parameters:\n",
    "        bathy_raster (str): File path to a bathy raster whose CRS will be used.\n",
    "        paths (list of str): List of file paths to the input rasters.\n",
    "        target_resolution_m (float): Desired resolution in meters. (Default: 10)\n",
    "        \n",
    "    Returns:\n",
    "        out_paths (list of str): List of reprojected raster file paths.\n",
    "        dst_transform (Affine): The common affine transform used.\n",
    "        width (int): Width (in pixels) of the common grid.\n",
    "        height (int): Height (in pixels) of the common grid.\n",
    "    \"\"\"\n",
    "    # Get the target CRS from the bathy raster.\n",
    "    with rasterio.open(bathy_raster) as bathy_src:\n",
    "        target_crs = bathy_src.crs\n",
    "\n",
    "    # Convert target resolution to feet.\n",
    "    meter_to_feet = 3.28084\n",
    "    target_res = target_resolution_m * meter_to_feet\n",
    "\n",
    "    # Compute the union bounds (in target CRS) of all input rasters.\n",
    "    union_xmin, union_ymin, union_xmax, union_ymax = None, None, None, None\n",
    "    for path in paths:\n",
    "        with rasterio.open(path) as src:\n",
    "            # Transform the source bounds to the target CRS.\n",
    "            src_bounds = src.bounds\n",
    "            dst_bounds = transform_bounds(\n",
    "                src.crs, target_crs,\n",
    "                src_bounds.left, src_bounds.bottom,\n",
    "                src_bounds.right, src_bounds.top,\n",
    "                densify_pts=21  # densify to improve accuracy on curved transforms\n",
    "            )\n",
    "            # dst_bounds is (xmin, ymin, xmax, ymax)\n",
    "            if union_xmin is None:\n",
    "                union_xmin, union_ymin, union_xmax, union_ymax = dst_bounds\n",
    "            else:\n",
    "                union_xmin = min(union_xmin, dst_bounds[0])\n",
    "                union_ymin = min(union_ymin, dst_bounds[1])\n",
    "                union_xmax = max(union_xmax, dst_bounds[2])\n",
    "                union_ymax = max(union_ymax, dst_bounds[3])\n",
    "\n",
    "    # Define the common affine transform.\n",
    "    # In raster space, the transform is typically defined as:\n",
    "    # Affine(pixel_width, 0, x_min, 0, -pixel_height, y_max)\n",
    "    dst_transform = Affine(target_res, 0, union_xmin,\n",
    "                           0, -target_res, union_ymax)\n",
    "    \n",
    "    # Compute the dimensions of the common grid.\n",
    "    width = int(np.ceil((union_xmax - union_xmin) / target_res))\n",
    "    height = int(np.ceil((union_ymax - union_ymin) / target_res))\n",
    "\n",
    "    out_paths = []\n",
    "    # Reproject each raster to the common grid.\n",
    "    for path in paths:\n",
    "        with rasterio.open(path) as src:\n",
    "            meta = src.meta.copy()\n",
    "            meta['descriptions'] = src.descriptions\n",
    "            source_nodata = src.nodata if src.nodata is not None else np.nan\n",
    "            \n",
    "            # Update metadata for the new common grid.\n",
    "            meta.update({\n",
    "                \"crs\": target_crs,\n",
    "                \"transform\": dst_transform,\n",
    "                \"width\": width,\n",
    "                \"height\": height,\n",
    "                \"dtype\": \"float32\",\n",
    "                \"nodata\": source_nodata\n",
    "            })\n",
    "            \n",
    "            # Prepare an array to hold all bands.\n",
    "            count = src.count\n",
    "            dest_array = np.empty((count, height, width), dtype=src.dtypes[0])\n",
    "            \n",
    "            # Reproject each band.\n",
    "            for i in range(1, count + 1):\n",
    "                band = src.read(i)\n",
    "                dest = np.empty((height, width), dtype=src.dtypes[0])\n",
    "                reproject(\n",
    "                    source=band,\n",
    "                    destination=dest,\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    dst_transform=dst_transform,\n",
    "                    dst_crs=target_crs,\n",
    "                    resampling=Resampling.bilinear,\n",
    "                    src_nodata=source_nodata,\n",
    "                    dst_nodata=source_nodata\n",
    "                )\n",
    "                dest_array[i - 1, :, :] = dest\n",
    "\n",
    "        # Build output file path (e.g., replacing 'masked' with 'projected').\n",
    "        out_path = path.replace('masked', 'projected')\n",
    "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "        with rasterio.open(out_path, 'w', **meta) as dst:\n",
    "            dst.write(dest_array.astype(np.float32))\n",
    "            for i, desc in enumerate(meta.get('descriptions', []), start=1):\n",
    "                dst.set_band_description(i, desc)\n",
    "        out_paths.append(out_path)\n",
    "    \n",
    "    return out_paths\n",
    "\n",
    "def visualize_rasters(raster_path, hydro_path, spm_path):\n",
    "    import math\n",
    "    import matplotlib.gridspec as gridspec\n",
    "    \"\"\"\n",
    "    Visualize all bands from a masked tif file (rhow or Rrs) along with the bathymetry raster,\n",
    "    and additionally visualize the two-band SPM_TUR file on the last row.\n",
    "    \n",
    "    Parameters:\n",
    "        raster_path (str): File path of the masked rhow or Rrs tif file.\n",
    "        hydro_path (str): File path of the bathymetry tif.\n",
    "        spm_path (str): File path of the SPM_TUR tif file (assumed to contain two bands).\n",
    "    \"\"\"\n",
    "    # Read main raster bands and metadata\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        meta = src.meta.copy()\n",
    "        masked_bands = [src.read(i) for i in range(1, src.count + 1)]\n",
    "        band_names = src.descriptions\n",
    "\n",
    "    # Read bathymetry band\n",
    "    with rasterio.open(hydro_path) as src_hydro:\n",
    "        hydro_band = src_hydro.read(1)\n",
    "    \n",
    "    # Read SPM_TUR bands (assumed two bands)\n",
    "    with rasterio.open(spm_path) as src_spm:\n",
    "        spm_bands = [src_spm.read(i) for i in range(1, src_spm.count + 1)]\n",
    "        spm_band_names = src_spm.descriptions\n",
    "\n",
    "    # Set up grid for main group (masked bands plus bathymetry)\n",
    "    n_main = len(masked_bands) + 1  # main bands + bathy\n",
    "    n_cols = 4\n",
    "    n_rows_main = math.ceil(n_main / n_cols)\n",
    "    total_rows = n_rows_main + 1  # extra row for spm_tur\n",
    "\n",
    "    fig = plt.figure(figsize=(5 * n_cols, 4 * total_rows))\n",
    "    gs = gridspec.GridSpec(total_rows, n_cols)\n",
    "\n",
    "    # Plot main bands\n",
    "    for idx, band in enumerate(masked_bands):\n",
    "        ax = fig.add_subplot(gs[idx])\n",
    "        im = ax.imshow(band, cmap='viridis')\n",
    "        if band_names is not None and idx < len(band_names) and band_names[idx]:\n",
    "            ax.set_title(f\"Wavelength: {band_names[idx]} mm\")\n",
    "        else:\n",
    "            ax.set_title(f\"Band {idx + 1}\")\n",
    "        plt.colorbar(im, ax=ax)\n",
    "\n",
    "    # Plot bathymetry in the next available slot in the main group\n",
    "    ax_bathy = fig.add_subplot(gs[len(masked_bands)])\n",
    "    im_bathy = ax_bathy.imshow(hydro_band, cmap='viridis')\n",
    "    ax_bathy.set_title(\"Hydro Survey\")\n",
    "    plt.colorbar(im_bathy, ax=ax_bathy)\n",
    "\n",
    "    # Turn off any empty main group axes\n",
    "    for j in range(n_main, n_rows_main * n_cols):\n",
    "        ax = fig.add_subplot(gs[j])\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Center the SPM_TUR bands in the final row\n",
    "    spm_count = len(spm_bands)\n",
    "    offset = (n_cols - spm_count) // 2\n",
    "    for col in range(n_cols):\n",
    "        ax_spm = fig.add_subplot(gs[n_rows_main, col])\n",
    "        if offset <= col < offset + spm_count:\n",
    "            idx = col - offset\n",
    "            im_spm = ax_spm.imshow(spm_bands[idx], cmap='viridis')\n",
    "            if spm_band_names is not None and idx < len(spm_band_names) and spm_band_names[idx]:\n",
    "                ax_spm.set_title(spm_band_names[idx])\n",
    "            else:\n",
    "                ax_spm.set_title(f\"SPM_TUR Band {idx + 1}\")\n",
    "            plt.colorbar(im_spm, ax=ax_spm)\n",
    "        else:\n",
    "            ax_spm.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def resample_bathy_to_acolite(bathy_raster, sentinel_raster, output_path):\n",
    "    # Open the sentinel raster to get its spatial resolution and CRS\n",
    "    with rasterio.open(sentinel_raster) as sentinel_src:\n",
    "        sentinel_transform = sentinel_src.transform\n",
    "        sentinel_crs = sentinel_src.crs\n",
    "        sentinel_width = sentinel_src.width\n",
    "        sentinel_height = sentinel_src.height\n",
    "\n",
    "    # Open the bathymetry raster and create an empty array with the sentinel's shape\n",
    "    with rasterio.open(bathy_raster) as bathy_src:\n",
    "        resampled_bathy = np.empty((sentinel_height, sentinel_width), dtype=bathy_src.dtypes[0])\n",
    "        \n",
    "        # Resample the bathymetry raster to match the sentinel raster's resolution and CRS\n",
    "        reproject(\n",
    "            source=rasterio.band(bathy_src, 1),  # Only the first band is used\n",
    "            destination=resampled_bathy,\n",
    "            src_transform=bathy_src.transform,\n",
    "            src_crs=bathy_src.crs,\n",
    "            dst_transform=sentinel_transform,\n",
    "            dst_crs=sentinel_crs,\n",
    "            dst_width=sentinel_width,\n",
    "            dst_height=sentinel_height,\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "        \n",
    "        # Update metadata for the output raster\n",
    "        bathy_meta = bathy_src.meta.copy()\n",
    "        bathy_meta.update({\n",
    "            \"transform\": sentinel_transform,\n",
    "            \"crs\": sentinel_crs,\n",
    "            \"width\": sentinel_width,\n",
    "            \"height\": sentinel_height,\n",
    "            \"dtype\": bathy_src.dtypes[0]\n",
    "        })\n",
    "\n",
    "    # Save the resampled bathymetry raster to the provided output location\n",
    "    with rasterio.open(output_path, \"w\", **bathy_meta) as dst:\n",
    "        dst.write(resampled_bathy, 1)\n",
    "\n",
    "def clip_acolite_by_bathy(file_list):\n",
    "    # first file is the bathymetry raster\n",
    "    bathy_raster = file_list[0]\n",
    "    \n",
    "    # Read bathymetry data and compute valid mask once.\n",
    "    with rasterio.open(bathy_raster) as bathy_src:\n",
    "        bathy_data = bathy_src.read(1)  # Assumes single-band bathy\n",
    "        valid_bathy_mask = ~np.isnan(bathy_data)\n",
    "        bathy_transform = bathy_src.transform\n",
    "        bathy_crs = bathy_src.crs\n",
    "\n",
    "    # Loop over the last three rasters in the file_list.\n",
    "    for sentinel_raster in file_list[-3:]:\n",
    "        with rasterio.open(sentinel_raster) as sentinel_src:\n",
    "            # Save band descriptions before processing\n",
    "            band_descriptions = sentinel_src.descriptions\n",
    "            # Ensure CRS and transform match\n",
    "            if sentinel_src.crs != bathy_crs or sentinel_src.transform != bathy_transform:\n",
    "                raise ValueError(\"Sentinel-2 raster must already be aligned with bathymetry raster.\")\n",
    "            sentinel_data = sentinel_src.read()  # Read all bands\n",
    "            # Create a mask for valid sentinel pixels (exclude zero values in first band)\n",
    "            valid_sentinel_mask = sentinel_data[0, :, :] != 0\n",
    "            # Combine the two masks\n",
    "            combined_mask = valid_bathy_mask & valid_sentinel_mask\n",
    "            # Apply mask to all bands in sentinel_data\n",
    "            clipped_sentinel_data = np.where(combined_mask, sentinel_data, np.nan)\n",
    "            # Copy metadata and update as needed\n",
    "            sentinel_meta = sentinel_src.meta.copy()\n",
    "            sentinel_meta.update({\n",
    "                \"dtype\": \"float32\",\n",
    "                \"nodata\": np.nan\n",
    "            })\n",
    "        \n",
    "        # Define output path; update the folder name.\n",
    "        if 'median_acolite' in sentinel_raster:\n",
    "            output_sentinel = sentinel_raster.replace(\"median_acolite\", \"clipped_acolite\")\n",
    "            out_str = re.sub(r'_\\d{2}_\\d{2}_\\d{2}(?=\\.tif$)', '', output_sentinel)\n",
    "        elif 'projected_acolite' in sentinel_raster:\n",
    "            output_sentinel = sentinel_raster.replace(\"projected_acolite\", \"clipped_acolite\")\n",
    "            out_str = re.sub(r'_\\d{2}_\\d{2}_\\d{2}(?=\\.tif$)', '', output_sentinel)\n",
    "\n",
    "        os.makedirs(os.path.dirname(out_str), exist_ok=True)\n",
    "        with rasterio.open(out_str, \"w\", **sentinel_meta) as dst:\n",
    "            dst.write(clipped_sentinel_data.astype(np.float32))\n",
    "            # Preserve original band descriptions\n",
    "            for i, desc in enumerate(band_descriptions, start=1):\n",
    "                dst.set_band_description(i, desc)\n",
    "\n",
    "def clip_bathy_with_acolite_nan(bathy_path, acolite_path, out_path):\n",
    "    \"\"\"\n",
    "    Clip 'bathy_path' by the valid pixels of 'acolite_path'.\n",
    "    Both rasters must already match exactly in dimensions, transform, and CRS.\n",
    "    ACOLITE's NoData is assumed to be NaN outside coverage.\n",
    "    \"\"\"\n",
    "    with rasterio.open(bathy_path) as bathy_src, rasterio.open(acolite_path) as aco_src:\n",
    "        # 1) Check alignment\n",
    "        if (bathy_src.width != aco_src.width) or (bathy_src.height != aco_src.height):\n",
    "            raise ValueError(\"ERROR: Rasters have different dimensions.\")\n",
    "        if bathy_src.transform != aco_src.transform:\n",
    "            raise ValueError(\"ERROR: Rasters have different transforms.\")\n",
    "        if bathy_src.crs != aco_src.crs:\n",
    "            raise ValueError(\"ERROR: Rasters have different CRS.\")\n",
    "\n",
    "        # 2) Read data\n",
    "        bathy_data = bathy_src.read(1)    # First band of bathy\n",
    "        acolite_data = aco_src.read(1)   # First band of ACOLITE\n",
    "\n",
    "        # 3) Build a valid mask where ACOLITE is finite (non-NaN)\n",
    "        valid_mask = np.isfinite(acolite_data)\n",
    "\n",
    "        # 4) Apply the mask: keep bathy where valid_mask==True, else set NaN\n",
    "        clipped_bathy = np.where(valid_mask, bathy_data, np.nan)\n",
    "\n",
    "        # 5) Update metadata for float32 + NaN\n",
    "        out_meta = bathy_src.meta.copy()\n",
    "        out_meta.update({\n",
    "            \"dtype\": \"float32\",\n",
    "            \"nodata\": np.nan,  \n",
    "            \"count\": 1\n",
    "        })\n",
    "\n",
    "    # 6) Write the clipped bathy\n",
    "    with rasterio.open(out_path, \"w\", **out_meta) as dst:\n",
    "        dst.write(clipped_bathy.astype(np.float32), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    return (array - np.nanmin(array)) / (np.nanmax(array) - np.nanmin(array))\n",
    "\n",
    "def extract_raster_data(paths):\n",
    "    images_data = []\n",
    "\n",
    "    bathy_path = paths[0]\n",
    "    reflectance_path = paths[1]\n",
    "    tur_spm_path = paths[2]\n",
    "\n",
    "    # --- Step 1: Open Bathymetry Raster ---\n",
    "    with rasterio.open(bathy_path) as bathy:\n",
    "        bathy_data = bathy.read(1)  # Bathymetry data (band 1)\n",
    "        bathy_nodata = bathy.nodata  # NoData value\n",
    "        bathy_transform = bathy.transform\n",
    "        bathy_shape = bathy.shape\n",
    "\n",
    "    # --- Step 2: Open Reflectnace Raster ---\n",
    "    with rasterio.open(reflectance_path) as reflect_src:    \n",
    "        if reflect_src.shape != bathy_shape or reflect_src.transform != bathy_transform:\n",
    "            raise ValueError(\n",
    "                f\"Inconsistent shapes or transforms:\\n\"\n",
    "                f\"Bathymetry Shape: {bathy_shape}, Sentinel-2 Shape: {reflect_src.shape}.\\n\"\n",
    "                f\"Bathymetry Transform: {bathy_transform}, Sentinel-2 Transform: {reflect_src.transform}.\\n\"\n",
    "                f\"Ensure rasters have identical extents and resolutions.\"\n",
    "            )\n",
    "        \n",
    "        # Read Sentinel-2 reflect_bands\n",
    "        reflect_bands = {\n",
    "            \"1610_norm\": normalize(reflect_src.read(1)),       # SWIR1, B11\n",
    "            \"2186_norm\": normalize(reflect_src.read(2)),       # SWIR2, B12\n",
    "            \"442_norm\": normalize(reflect_src.read(3)),        # Aerosols, B1\n",
    "            \"492_norm\": normalize(reflect_src.read(4)),        # Blue, B2\n",
    "            \"559_norm\": normalize(reflect_src.read(5)),        # Green, B3\n",
    "            \"665_norm\": normalize(reflect_src.read(6)),        # Red, B4\n",
    "            \"704_norm\": normalize(reflect_src.read(7)),        # Red Edge 1, B5\n",
    "            \"739_norm\": normalize(reflect_src.read(8)),        # Red Edge 2, B6\n",
    "            \"780_norm\": normalize(reflect_src.read(9)),        # Red Edge 3, B7\n",
    "            \"833_norm\": normalize(reflect_src.read(10)),       # NIR, B8\n",
    "            \"864_norm\": normalize(reflect_src.read(11)),       # Red Edge 4, B8A\n",
    "            \"stumpf\": normalize(np.log(reflect_src.read(4)) / np.log(reflect_src.read(5))),\n",
    "            \"nsmi\": normalize((reflect_src.read(6) + reflect_src.read(5) - reflect_src.read(4)) / (reflect_src.read(6) + reflect_src.read(5) + reflect_src.read(4))),    # normalized suspended material index, Red+Green-Blue / Red+Green+Blue\n",
    "            'ndssi': normalize((reflect_src.read(4) - reflect_src.read(10))/ (reflect_src.read(4) + reflect_src.read(10))),      # normalized difference suspended sediment index, Blue-NIR / Blue+NIR\n",
    "            \"ndti\": normalize((reflect_src.read(6) - reflect_src.read(5)) / (reflect_src.read(6) + reflect_src.read(5)))          # normalized differnce tubridity index, Red-Green / Red + Green\n",
    "            }\n",
    "        Rrs_nodata = reflect_src.nodata  # Sentinel-2 NoData value\n",
    "\n",
    "    with rasterio.open(tur_spm_path) as tur_spm_src:    \n",
    "        if tur_spm_src.shape != bathy_shape or tur_spm_src.transform != bathy_transform:\n",
    "            raise ValueError(\n",
    "                f\"Inconsistent shapes or transforms:\\n\"\n",
    "                f\"Bathymetry Shape: {bathy_shape}, Sentinel-2 Shape: {tur_spm_src.shape}.\\n\"\n",
    "                f\"Bathymetry Transform: {bathy_transform}, Sentinel-2 Transform: {tur_spm_src.transform}.\\n\"\n",
    "                f\"Ensure rasters have identical extents and resolutions.\"\n",
    "            )\n",
    "        \n",
    "        tur_spm_bands = {\n",
    "            \"SPM\": normalize(tur_spm_src.read(1)),       \n",
    "            \"TUR\": normalize(tur_spm_src.read(2))\n",
    "            }\n",
    "        tur_spm_nodata = tur_spm_src.nodata  # tur_spm NoData value\n",
    "\n",
    "        # --- Step 3: Flatten Bands ---\n",
    "        flat_bathy = bathy_data.flatten()\n",
    "        flat_bands = {**{key: band.flatten() for key, band in reflect_bands.items()},\n",
    "                  **{key: band.flatten() for key, band in tur_spm_bands.items()}}\n",
    "        # flat_bands = {key: band.flatten() for key, band in reflect_bands.items()}\n",
    "\n",
    "\n",
    "        # --- Step 4: Mask NoData Values ---\n",
    "        valid_mask = (\n",
    "            ~np.isnan(flat_bathy) &  # Valid bathy pixels\n",
    "            (flat_bathy != bathy_nodata)  # Exclude bathy NoData\n",
    "        )\n",
    "\n",
    "        for band in flat_bands.values():\n",
    "            valid_mask &= (band != Rrs_nodata) & (band != tur_spm_nodata)  # Exclude Sentinel-2 and tur_spm NoData\n",
    "        \n",
    "        # Apply the mask\n",
    "        valid_bathy = flat_bathy[valid_mask].reshape(-1, 1)  # Reshape bathy to (n_pixels, 1)\n",
    "        valid_features = np.column_stack([band[valid_mask] for band in flat_bands.values()])\n",
    "\n",
    "        # --- Step 5: Combine Features and Targets ---\n",
    "        # combined_features = np.concatenate((valid_bathy, valid_features), axis=1)  # Combine bathy and S2\n",
    "        images_data.append((valid_features, valid_bathy.flatten()))  # Flatten bathy for targets\n",
    "\n",
    "        return images_data\n",
    "    \n",
    "def get_pixel_positions(raster_path):\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        # Get the affine transformation of the raster\n",
    "        transform = src.transform\n",
    "        \n",
    "        # Read the first band to determine valid (non-NaN) pixels\n",
    "        band_data = src.read(1, masked=True)  # Read the first band as a masked array\n",
    "        valid_mask = ~band_data.mask          # Valid pixels where mask is False\n",
    "\n",
    "        # Get raster dimensions\n",
    "        height, width = src.height, src.width\n",
    "\n",
    "        # Create arrays of pixel indices\n",
    "        row_indices, col_indices = np.meshgrid(np.arange(height), np.arange(width), indexing=\"ij\")\n",
    "\n",
    "        # Compute x, y positions using the affine transform\n",
    "        xs, ys = rasterio.transform.xy(transform, row_indices, col_indices, offset='center')\n",
    "        xs = np.array(xs).flatten()\n",
    "        ys = np.array(ys).flatten()\n",
    "\n",
    "        # Filter x, y positions to include only valid pixels\n",
    "        valid_positions = np.column_stack((xs[valid_mask.flatten()], ys[valid_mask.flatten()]))\n",
    "\n",
    "    return valid_positions\n",
    "\n",
    "def prepare_train_data(surveyinfo):\n",
    "    images_data = [extract_raster_data(paths) for paths in list(surveyinfo.values())]\n",
    "    ncf_channels = [name[:-9] for name in list(surveyinfo.keys())]\n",
    "    pixel_positions = [get_pixel_positions(paths[0]) for paths in list(surveyinfo.values())]\n",
    "\n",
    "    data = {}\n",
    "    for i, name in enumerate(list(surveyinfo.keys())):\n",
    "        # Extract data for the current iteration\n",
    "        bands = images_data[i]               # Shape (n_pixels, 11)\n",
    "        positions = pixel_positions[i]     # Shape (n_pixels, 2)\n",
    "    \n",
    "        data[name] = pd.DataFrame({\n",
    "                \"1610_norm\": bands[0][0][:, 0],\n",
    "                \"2186_norm\": bands[0][0][:, 1],\n",
    "                \"442_norm\": bands[0][0][:, 2],\n",
    "                \"492_norm\": bands[0][0][:, 3],\n",
    "                \"559_norm\": bands[0][0][:, 4],\n",
    "                \"665_norm\": bands[0][0][:, 5],\n",
    "                \"704_norm\": bands[0][0][:, 6],\n",
    "                \"739_norm\": bands[0][0][:, 7],\n",
    "                \"780_norm\": bands[0][0][:, 8],\n",
    "                \"833_norm\": bands[0][0][:, 9],\n",
    "                \"864_norm\": bands[0][0][:, 10],\n",
    "                \"stumpf\": bands[0][0][:, 11],\n",
    "                \"nsmi\": bands[0][0][:, 12],\n",
    "                'ndssi': bands[0][0][:, 13],\n",
    "                \"ndti\": bands[0][0][:, 14],\n",
    "                \"SPM\": bands[0][0][:, 15],\n",
    "                \"TUR\": bands[0][0][:, 16],\n",
    "                \"X\": positions[:, 0],\n",
    "                \"Y\": positions[:, 1],\n",
    "                \"Channel_Name\": [ncf_channels[i]] * len(bands[0][0]),  # Repeating value directly\n",
    "                \"Bathymetry\": bands[0][1]\n",
    "            })\n",
    "\n",
    "    combined_df = pd.concat(data.values(), ignore_index=True)\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    combined_df['Channel_Name_Encoded'] = encoder.fit_transform(combined_df['Channel_Name'])\n",
    "\n",
    "    output = open(os.path.join(WORK_DIR, 'Channel_Name_label_encoders.pkl'), 'wb')\n",
    "    pickle.dump(encoder, output)\n",
    "    output.close()\n",
    "    \n",
    "    # Drop original categorical columns\n",
    "    combined_df.drop(columns=['Channel_Name'], inplace=True)\n",
    "\n",
    "    combined_df.to_parquet(os.path.join(WORK_DIR,'SDB_data.parquet'), engine='pyarrow', index=False)\n",
    "    print(f\"Pixelwise training data saved to {os.path.join(WORK_DIR,'SDB_data.parquet')}\")\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/mnt/Crucial'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m S2_FINAL \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(FINAL_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m BATHY_FINAL \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(FINAL_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBathy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS2_MASK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(S2_PROJ, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(BATHY_PROJ, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/tools/miniforge3/envs/gis/lib/python3.10/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/tools/miniforge3/envs/gis/lib/python3.10/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/tools/miniforge3/envs/gis/lib/python3.10/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/tools/miniforge3/envs/gis/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/mnt/Crucial'"
     ]
    }
   ],
   "source": [
    "S2_PATH = '/mnt/Crucial/SDB/CESWG/stacked_acolite'\n",
    "BATHY_PATH = '/mnt/Crucial/SDB/CESWG/bathy_rasters'\n",
    "S2_MASK = S2_PATH.replace('stacked', 'masked')\n",
    "S2_PROJ = S2_PATH.replace('stacked', 'projected')\n",
    "BATHY_PROJ = BATHY_PATH.replace('rasters', 'proj')\n",
    "\n",
    "FINAL_PATH = '/home/clay/Documents/SDB/CESWG/processed'\n",
    "S2_FINAL = os.path.join(FINAL_PATH, 'S2')\n",
    "BATHY_FINAL = os.path.join(FINAL_PATH, 'Bathy')\n",
    "\n",
    "os.makedirs(S2_MASK, exist_ok=True)\n",
    "os.makedirs(S2_PROJ, exist_ok=True)\n",
    "os.makedirs(BATHY_PROJ, exist_ok=True)\n",
    "os.makedirs(FINAL_PATH, exist_ok=True)\n",
    "os.makedirs(S2_FINAL, exist_ok=True)\n",
    "os.makedirs(BATHY_FINAL, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveynames = [f[:-4] for f in os.listdir(BATHY_PATH) if f.endswith('.tif')]\n",
    "surveyinfo = {}\n",
    "for f in surveynames:\n",
    "    hydro_tif = os.path.join(BATHY_PATH, f\"{f}.tif\")\n",
    "    acolite_path = os.path.join(S2_PATH, f)\n",
    "    \n",
    "    if os.path.exists(acolite_path):\n",
    "        rhow_paths = [os.path.join(acolite_path, file) for file in os.listdir(acolite_path) if 'rhow' in file if file.endswith('.tif')]\n",
    "        Rrs_paths = [os.path.join(acolite_path, file) for file in os.listdir(acolite_path) if 'Rrs' in file if file.endswith('.tif')]\n",
    "        spm_tur_paths = [os.path.join(acolite_path, file) for file in os.listdir(acolite_path) if 'TUR_SPM' in file if file.endswith('.tif')]\n",
    "\n",
    "        surveyinfo[f] = [hydro_tif, rhow_paths, Rrs_paths, spm_tur_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust the acolite tif Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case I already ran it\n",
    "masked_surveyinfo = {}\n",
    "\n",
    "for f, paths in surveyinfo.items():\n",
    "    files = [file for file in os.listdir(os.path.join(S2_MASK, f)) if file.endswith('.tif')]\n",
    "    rhow_paths = []\n",
    "    rrs_paths = []\n",
    "    spm_tur_paths = []\n",
    "\n",
    "    for file in files:\n",
    "        if file.startswith('rhow'):\n",
    "            rhow_paths.append(os.path.join(S2_MASK, f, file))\n",
    "        elif file.startswith('Rrs'):\n",
    "            rrs_paths.append(os.path.join(S2_MASK, f, file))\n",
    "        else:\n",
    "            spm_tur_paths.append(os.path.join(S2_MASK, f, file))\n",
    "    \n",
    "    masked_surveyinfo[f] = rhow_paths, rrs_paths, spm_tur_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_surveyinfo = {}\n",
    "\n",
    "for f, paths in surveyinfo.items():\n",
    "    hydro_tif, rhow_paths, Rrs_paths, spm_tur_paths = paths\n",
    "    masked_surveyinfo[f] = mask_acolite_images(rhow_paths, Rrs_paths, spm_tur_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove the ACOLITE tifs that have no data (only Nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_nan_masked_surveyinfo = {}\n",
    "\n",
    "for survey, file_tuple in masked_surveyinfo.items():\n",
    "    filtered_groups = []\n",
    "    for group in file_tuple:\n",
    "        filtered_files = []\n",
    "        for file_path in group:\n",
    "            with rasterio.open(file_path) as src:\n",
    "                data = src.read()  # Read all bands\n",
    "            if not np.isnan(data).all():\n",
    "                filtered_files.append(file_path)\n",
    "        filtered_groups.append(filtered_files)\n",
    "    # Add survey only if at least one file has data in any group.\n",
    "    if any(filtered_groups):\n",
    "        non_nan_masked_surveyinfo[survey] = tuple(filtered_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare number of rasters with available data and total rasters\n",
    "display(len(non_nan_masked_surveyinfo))\n",
    "display(len(masked_surveyinfo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the masked results alongside the ehydro survey\n",
    "i = -3\n",
    "\n",
    "non_nan_masked_surveys = list(non_nan_masked_surveyinfo.keys())\n",
    "survey = non_nan_masked_surveys[i]\n",
    "\n",
    "rhow_paths, rrs_paths, spm_tur_paths = non_nan_masked_surveyinfo[survey]\n",
    "hydro_tif = surveyinfo[survey][0]\n",
    "\n",
    "visualize_rasters(rhow_paths[0], hydro_tif, spm_tur_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproject ACOLITE tif products to the eHydro CRS\n",
    "- need to work on preserving the spatial resolution of the original ACOLITE products (10 meter)\n",
    "- current methods resample to 10ft resolution\n",
    "- can do a crude one where I convert 10 meter to ft and directly pass?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case I already ran it\n",
    "reprojected_surveyinfo = {}\n",
    "\n",
    "for f, paths in non_nan_masked_surveyinfo.items():\n",
    "    files = [file for file in os.listdir(os.path.join(S2_PROJ, f)) if file.endswith('.tif')]\n",
    "    rhow_paths = []\n",
    "    rrs_paths = []\n",
    "    spm_tur_paths = []\n",
    "\n",
    "    for file in files:\n",
    "        if file.startswith('rhow'):\n",
    "            rhow_paths.append(os.path.join(S2_PROJ, f, file))\n",
    "        elif file.startswith('Rrs'):\n",
    "            rrs_paths.append(os.path.join(S2_PROJ, f, file))\n",
    "        else:\n",
    "            spm_tur_paths.append(os.path.join(S2_PROJ, f, file))\n",
    "    \n",
    "    reprojected_surveyinfo[f] = rhow_paths, rrs_paths, spm_tur_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reprojected_surveyinfo = {}\n",
    "\n",
    "for f, results in non_nan_masked_surveyinfo.items():\n",
    "    hydro_tif = surveyinfo[f][0]\n",
    "    rhow_results, Rrs_results, spm_tur_results = results\n",
    "    paths = []\n",
    "    for grp in [rhow_results, Rrs_results, spm_tur_results]:\n",
    "        paths.append(reproject_acolite(hydro_tif, grp, target_resolution_m=10))\n",
    "    reprojected_surveyinfo[f] = paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get median raster from the surveys that have multiple S2 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, results in reprojected_surveyinfo.items():\n",
    "    rhow_results, Rrs_results, spm_tur_results = results\n",
    "    groups = [(rhow_results, \"rhow\"), (Rrs_results, \"Rrs\"), (spm_tur_results, \"TUR_SPM\")]\n",
    "    \n",
    "    for group_files, prod in groups:\n",
    "        if len(group_files) > 1:\n",
    "            # Read all files into a stack\n",
    "            arrays = []\n",
    "            meta = None\n",
    "            band_descriptions = None\n",
    "            for path in group_files:\n",
    "                with rasterio.open(path) as src:\n",
    "                    if meta is None:\n",
    "                        meta = src.meta.copy()\n",
    "                        band_descriptions = src.descriptions\n",
    "                    arrays.append(src.read())  # shape: (bands, height, width)\n",
    "            arr_stack = np.stack(arrays, axis=0)  # shape: (n_files, bands, height, width)\n",
    "            median_arr = np.nanmedian(arr_stack, axis=0)  # shape: (bands, height, width)\n",
    "            \n",
    "            # Prepare output path: replace 'projected_acolite' with 'median_acolite'\n",
    "            # and change the product prefix in the filename.\n",
    "            out_path = group_files[0].replace(\"projected_acolite\", \"median_acolite\")\n",
    "            out_path = out_path.replace(prod, f\"median_{prod}\")\n",
    "            out_str = re.sub(r'_\\d{2}_\\d{2}_\\d{2}(?=\\.tif$)', '', out_path)\n",
    "            os.makedirs(os.path.dirname(out_str), exist_ok=True)\n",
    "            \n",
    "            # Update metadata if needed (ensure dtype and band count)\n",
    "            meta.update(dtype=\"float32\", count=median_arr.shape[0])\n",
    "            # Write the median raster keeping band descriptions\n",
    "            with rasterio.open(out_str, \"w\", **meta) as dst:\n",
    "                dst.write(median_arr.astype(np.float32))\n",
    "                for i, desc in enumerate(band_descriptions, start=1):\n",
    "                    dst.set_band_description(i, desc)\n",
    "            print(f\"Median {prod} raster for survey {f} saved to: {out_str}\")\n",
    "        else:\n",
    "            print(f\"Only one {prod} file for survey {f}; skipping median calculation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample bathy rasters from 10 ft resolution to same resolution as S2 rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect median rasters and singular rasters for resampling the bathy rasters\n",
    "# use set notation to remove the medians from the reprojected rasters\n",
    "proj_names = os.listdir(S2_PROJ)\n",
    "median_names = os.listdir(S2_PROJ.replace('projected', 'median'))\n",
    "names_only_proj = list(set(proj_names) - set(median_names))\n",
    "acolite_names = median_names + names_only_proj\n",
    "\n",
    "hydro_paths = [os.path.join(BATHY_PATH, f'{f}.tif') for f in acolite_names]\n",
    "median_paths = [os.path.join(S2_PROJ.replace('projected', 'median'), f) for f in median_names]\n",
    "proj_paths = [os.path.join(S2_PROJ, f) for f in names_only_proj]\n",
    "acolite_paths = median_paths + proj_paths\n",
    "\n",
    "resample_hydroinfo = {}\n",
    "for name, hydro, apath in zip(acolite_names, hydro_paths, acolite_paths):\n",
    "    resample_hydroinfo[name] = [hydro] + [os.path.join(apath, f) for f in os.listdir(apath) if f.endswith('tif')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_tifs = {}\n",
    "\n",
    "for f, paths in resample_hydroinfo.items():\n",
    "    resample_bathy_to_acolite(paths[0], paths[1], paths[0].replace('bathy_rasters', 'bathy_proj'))\n",
    "\n",
    "    resampled_tifs[f] = [paths[0].replace('bathy_rasters', 'bathy_proj')] + [paths[1], paths[2], paths[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clip the S2 rasters by the valid bathymetry pixels\n",
    "- need bounds of non np.nan pixels for clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, rasters in resampled_tifs.items():\n",
    "    clip_acolite_by_bathy(rasters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clip the bathymetry rasters by the valid cloud-masked S2 pixels\n",
    "- need bounds of valid pixels, seems like these will be values above 0.0 since no nan-value is applied in GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, rasters in resampled_tifs.items():\n",
    "    outpath = rasters[0].replace('proj', 'clipped')\n",
    "    os.makedirs(os.path.dirname(outpath), exist_ok=True)\n",
    "\n",
    "    if 'median_acolite' in rasters[1]:\n",
    "        rhow_path = rasters[1].replace(\"median_acolite\", \"clipped_acolite\")\n",
    "        rhow_str = re.sub(r'_\\d{2}_\\d{2}_\\d{2}(?=\\.tif$)', '', rhow_path)\n",
    "\n",
    "    elif 'projected_acolite' in rasters[1]:\n",
    "        rhow_path = rasters[1].replace(\"projected_acolite\", \"clipped_acolite\")\n",
    "        rhow_str = re.sub(r'_\\d{2}_\\d{2}_\\d{2}(?=\\.tif$)', '', rhow_path)\n",
    "\n",
    "    clip_bathy_with_acolite_nan(rasters[0], rhow_str, outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should be done with needed preprocessing, can now move to training the model on the data\n",
    "- will try traditional ML regression models, as well as CNN\n",
    "- May try majority voting of multiple training set models like in Tan et al. 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframe for training ML models on per-pixel basis, export to parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDE_BATHY = '/mnt/Crucial/SDB/CESWG/bathy_clipped'\n",
    "REDE_ACOLITE = '/mnt/Crucial/SDB/CESWG/clipped_acolite'\n",
    "WORK_DIR = '/mnt/Crucial/SDB/CESWG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDE_BATHY = '/home/clay/Documents/SDB/CESWG/bathy_clipped'\n",
    "REDE_ACOLITE = '/home/clay/Documents/SDB/CESWG/clipped_acolite'\n",
    "WORK_DIR = '/home/clay/Documents/SDB/CESWG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = os.listdir(REDE_BATHY)\n",
    "\n",
    "rhow_info = {}              # create a dictionary storing the data for rhow and tur_spm\n",
    "Rrs_info = {}               # create a dictionary storign the data for Rrs and tur_spm. May not use since it could be redundant, but nice to have\n",
    "for name in names:\n",
    "    bathy_path = os.path.join(REDE_BATHY, name)\n",
    "    rhow_path = [os.path.join(REDE_ACOLITE, name[:-4], f) for f in os.listdir(os.path.join(REDE_ACOLITE, name[:-4])) if 'rhow' in f][0]\n",
    "    rrs_path = [os.path.join(REDE_ACOLITE, name[:-4], f) for f in os.listdir(os.path.join(REDE_ACOLITE, name[:-4])) if 'Rrs' in f][0]\n",
    "    tur_spm_path = [os.path.join(REDE_ACOLITE, name[:-4], f) for f in os.listdir(os.path.join(REDE_ACOLITE, name[:-4])) if 'TUR_SPM' in f][0]\n",
    "\n",
    "    rhow_info[name[:-4]] = [bathy_path, rhow_path, tur_spm_path]\n",
    "    Rrs_info[name[:-4]] = [bathy_path, rrs_path, tur_spm_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_189386/330690023.py:2: RuntimeWarning: All-NaN slice encountered\n",
      "  return (array - np.nanmin(array)) / (np.nanmax(array) - np.nanmin(array))\n",
      "/tmp/ipykernel_189386/330690023.py:2: RuntimeWarning: invalid value encountered in divide\n",
      "  return (array - np.nanmin(array)) / (np.nanmax(array) - np.nanmin(array))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixelwise training data saved to /home/clay/Documents/SDB/CESWG/SDB_data.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1610_norm</th>\n",
       "      <th>2186_norm</th>\n",
       "      <th>442_norm</th>\n",
       "      <th>492_norm</th>\n",
       "      <th>559_norm</th>\n",
       "      <th>665_norm</th>\n",
       "      <th>704_norm</th>\n",
       "      <th>739_norm</th>\n",
       "      <th>780_norm</th>\n",
       "      <th>833_norm</th>\n",
       "      <th>...</th>\n",
       "      <th>stumpf</th>\n",
       "      <th>nsmi</th>\n",
       "      <th>ndssi</th>\n",
       "      <th>ndti</th>\n",
       "      <th>SPM</th>\n",
       "      <th>TUR</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Bathymetry</th>\n",
       "      <th>Channel_Name_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.897389</td>\n",
       "      <td>0.967754</td>\n",
       "      <td>0.760320</td>\n",
       "      <td>0.630682</td>\n",
       "      <td>0.722982</td>\n",
       "      <td>0.505699</td>\n",
       "      <td>0.972862</td>\n",
       "      <td>0.966278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397993</td>\n",
       "      <td>0.371699</td>\n",
       "      <td>0.133565</td>\n",
       "      <td>0.430897</td>\n",
       "      <td>0.491689</td>\n",
       "      <td>0.491689</td>\n",
       "      <td>3.236274e+06</td>\n",
       "      <td>1.381865e+07</td>\n",
       "      <td>14.372604</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.897389</td>\n",
       "      <td>0.967754</td>\n",
       "      <td>0.760320</td>\n",
       "      <td>0.509405</td>\n",
       "      <td>0.688707</td>\n",
       "      <td>0.608875</td>\n",
       "      <td>0.972862</td>\n",
       "      <td>0.966278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518798</td>\n",
       "      <td>0.547963</td>\n",
       "      <td>0.087404</td>\n",
       "      <td>0.569220</td>\n",
       "      <td>0.595376</td>\n",
       "      <td>0.595376</td>\n",
       "      <td>3.236306e+06</td>\n",
       "      <td>1.381865e+07</td>\n",
       "      <td>14.801007</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.947371</td>\n",
       "      <td>0.737859</td>\n",
       "      <td>0.884240</td>\n",
       "      <td>0.354741</td>\n",
       "      <td>0.582226</td>\n",
       "      <td>0.640859</td>\n",
       "      <td>0.736661</td>\n",
       "      <td>0.944633</td>\n",
       "      <td>0.947024</td>\n",
       "      <td>0.933258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646988</td>\n",
       "      <td>0.717626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659826</td>\n",
       "      <td>0.627736</td>\n",
       "      <td>0.627737</td>\n",
       "      <td>3.236339e+06</td>\n",
       "      <td>1.381865e+07</td>\n",
       "      <td>15.323374</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.943454</td>\n",
       "      <td>0.731772</td>\n",
       "      <td>0.887762</td>\n",
       "      <td>0.377076</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.592018</td>\n",
       "      <td>0.723197</td>\n",
       "      <td>0.937943</td>\n",
       "      <td>0.929376</td>\n",
       "      <td>0.873307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527334</td>\n",
       "      <td>0.617087</td>\n",
       "      <td>0.051151</td>\n",
       "      <td>0.682958</td>\n",
       "      <td>0.578378</td>\n",
       "      <td>0.578378</td>\n",
       "      <td>3.236372e+06</td>\n",
       "      <td>1.381865e+07</td>\n",
       "      <td>14.946900</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.897389</td>\n",
       "      <td>0.763548</td>\n",
       "      <td>0.760320</td>\n",
       "      <td>0.561001</td>\n",
       "      <td>0.331673</td>\n",
       "      <td>0.641276</td>\n",
       "      <td>0.743230</td>\n",
       "      <td>0.904535</td>\n",
       "      <td>0.706734</td>\n",
       "      <td>0.837527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251321</td>\n",
       "      <td>0.371542</td>\n",
       "      <td>0.136936</td>\n",
       "      <td>0.792293</td>\n",
       "      <td>0.628158</td>\n",
       "      <td>0.628158</td>\n",
       "      <td>3.236241e+06</td>\n",
       "      <td>1.381862e+07</td>\n",
       "      <td>16.153040</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124295</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.383646</td>\n",
       "      <td>0.383646</td>\n",
       "      <td>2.834474e+06</td>\n",
       "      <td>1.337846e+07</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124296</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.330307</td>\n",
       "      <td>0.330307</td>\n",
       "      <td>2.834507e+06</td>\n",
       "      <td>1.337846e+07</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124297</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.499987</td>\n",
       "      <td>0.499987</td>\n",
       "      <td>2.834539e+06</td>\n",
       "      <td>1.337846e+07</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124298</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.430120</td>\n",
       "      <td>0.430120</td>\n",
       "      <td>2.834572e+06</td>\n",
       "      <td>1.337846e+07</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124299</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.348462</td>\n",
       "      <td>0.348463</td>\n",
       "      <td>2.834474e+06</td>\n",
       "      <td>1.337843e+07</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2124300 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1610_norm  2186_norm  442_norm  492_norm  559_norm  665_norm  \\\n",
       "0         0.897389   0.967754  0.760320  0.630682  0.722982  0.505699   \n",
       "1         0.897389   0.967754  0.760320  0.509405  0.688707  0.608875   \n",
       "2         0.947371   0.737859  0.884240  0.354741  0.582226  0.640859   \n",
       "3         0.943454   0.731772  0.887762  0.377076  0.427083  0.592018   \n",
       "4         0.897389   0.763548  0.760320  0.561001  0.331673  0.641276   \n",
       "...            ...        ...       ...       ...       ...       ...   \n",
       "2124295        NaN        NaN       NaN       NaN       NaN       NaN   \n",
       "2124296        NaN        NaN       NaN       NaN       NaN       NaN   \n",
       "2124297        NaN        NaN       NaN       NaN       NaN       NaN   \n",
       "2124298        NaN        NaN       NaN       NaN       NaN       NaN   \n",
       "2124299        NaN        NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "         704_norm  739_norm  780_norm  833_norm  ...    stumpf      nsmi  \\\n",
       "0        0.972862  0.966278  1.000000  0.871044  ...  0.397993  0.371699   \n",
       "1        0.972862  0.966278  1.000000  0.883636  ...  0.518798  0.547963   \n",
       "2        0.736661  0.944633  0.947024  0.933258  ...  0.646988  0.717626   \n",
       "3        0.723197  0.937943  0.929376  0.873307  ...  0.527334  0.617087   \n",
       "4        0.743230  0.904535  0.706734  0.837527  ...  0.251321  0.371542   \n",
       "...           ...       ...       ...       ...  ...       ...       ...   \n",
       "2124295       NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "2124296       NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "2124297       NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "2124298       NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "2124299       NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "\n",
       "            ndssi      ndti       SPM       TUR             X             Y  \\\n",
       "0        0.133565  0.430897  0.491689  0.491689  3.236274e+06  1.381865e+07   \n",
       "1        0.087404  0.569220  0.595376  0.595376  3.236306e+06  1.381865e+07   \n",
       "2        0.000000  0.659826  0.627736  0.627737  3.236339e+06  1.381865e+07   \n",
       "3        0.051151  0.682958  0.578378  0.578378  3.236372e+06  1.381865e+07   \n",
       "4        0.136936  0.792293  0.628158  0.628158  3.236241e+06  1.381862e+07   \n",
       "...           ...       ...       ...       ...           ...           ...   \n",
       "2124295       NaN       NaN  0.383646  0.383646  2.834474e+06  1.337846e+07   \n",
       "2124296       NaN       NaN  0.330307  0.330307  2.834507e+06  1.337846e+07   \n",
       "2124297       NaN       NaN  0.499987  0.499987  2.834539e+06  1.337846e+07   \n",
       "2124298       NaN       NaN  0.430120  0.430120  2.834572e+06  1.337846e+07   \n",
       "2124299       NaN       NaN  0.348462  0.348463  2.834474e+06  1.337843e+07   \n",
       "\n",
       "         Bathymetry  Channel_Name_Encoded  \n",
       "0         14.372604                    16  \n",
       "1         14.801007                    16  \n",
       "2         15.323374                    16  \n",
       "3         14.946900                    16  \n",
       "4         16.153040                    16  \n",
       "...             ...                   ...  \n",
       "2124295   11.000000                   120  \n",
       "2124296   11.000000                   120  \n",
       "2124297   11.000000                   120  \n",
       "2124298   11.000000                   120  \n",
       "2124299   11.000000                   120  \n",
       "\n",
       "[2124300 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = prepare_train_data(Rrs_info)\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
