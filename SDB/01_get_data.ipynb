{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is going to download eHydro bathymetry data from the USACE ArcGIS REST repository, as well as retrieve cloud masked imagery of the same location, at the same time, for training of Satellite Derived Bathymetry model(s) for the National Channel Framework (NCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import ee\n",
    "import geemap\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize(project = '') ##enter your project name here as a string to initialize exchanges with ee api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUCNTIONS FROM https://developers.google.com/earth-engine/tutorials/community/sentinel-2-s2cloudless \n",
    "# USE FOR CLOUD MASKING\n",
    "\n",
    "def get_s2_sr_cld_col(aoi, start_date, end_date, cloud_filter):\n",
    "    # Import and filter S2 SR.\n",
    "    s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date)\n",
    "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', cloud_filter)))\n",
    "\n",
    "    # Import and filter s2cloudless.\n",
    "    s2_cloudless_col = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date))\n",
    "\n",
    "    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n",
    "    combined_coll = ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n",
    "        'primary': s2_sr_col,\n",
    "        'secondary': s2_cloudless_col,\n",
    "        'condition': ee.Filter.equals(**{\n",
    "            'leftField': 'system:index',\n",
    "            'rightField': 'system:index'\n",
    "        })\n",
    "    }))\n",
    "\n",
    "    return combined_coll.map(lambda img: img.clip(aoi))\n",
    "\n",
    "def add_cloud_bands(img):\n",
    "    # Get s2cloudless image, subset the probability band.\n",
    "    cld_prb = ee.Image(img.get('s2cloudless')).select('probability')\n",
    "\n",
    "    # Condition s2cloudless by the probability threshold value.\n",
    "    is_cloud = cld_prb.gt(CLD_PRB_THRESH).rename('clouds')\n",
    "\n",
    "    # Add the cloud probability layer and cloud mask as image bands.\n",
    "    return img.addBands(ee.Image([cld_prb, is_cloud]))\n",
    "\n",
    "def add_shadow_bands(img):\n",
    "    # Identify water pixels from the SCL band.\n",
    "    not_water = img.select('SCL').neq(6)\n",
    "\n",
    "    # Identify dark NIR pixels that are not water (potential cloud shadow pixels).\n",
    "    SR_BAND_SCALE = 1e4\n",
    "    dark_pixels = img.select('B8').lt(NIR_DRK_THRESH*SR_BAND_SCALE).multiply(not_water).rename('dark_pixels')\n",
    "\n",
    "    # Determine the direction to project cloud shadow from clouds (assumes UTM projection).\n",
    "    shadow_azimuth = ee.Number(90).subtract(ee.Number(img.get('MEAN_SOLAR_AZIMUTH_ANGLE')));\n",
    "\n",
    "    # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST input.\n",
    "    cld_proj = (img.select('clouds').directionalDistanceTransform(shadow_azimuth, CLD_PRJ_DIST*10)\n",
    "        .reproject(**{'crs': img.select(0).projection(), 'scale': 100})\n",
    "        .select('distance')\n",
    "        .mask()\n",
    "        .rename('cloud_transform'))\n",
    "\n",
    "    # Identify the intersection of dark pixels with cloud shadow projection.\n",
    "    shadows = cld_proj.multiply(dark_pixels).rename('shadows')\n",
    "\n",
    "    # Add dark pixels, cloud projection, and identified shadows as image bands.\n",
    "    return img.addBands(ee.Image([dark_pixels, cld_proj, shadows]))\n",
    "\n",
    "def add_cld_shdw_mask(img):\n",
    "    # Add cloud component bands.\n",
    "    img_cloud = add_cloud_bands(img)\n",
    "\n",
    "    # Add cloud shadow component bands.\n",
    "    img_cloud_shadow = add_shadow_bands(img_cloud)\n",
    "\n",
    "    # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0.\n",
    "    is_cld_shdw = img_cloud_shadow.select('clouds').add(img_cloud_shadow.select('shadows')).gt(0)\n",
    "\n",
    "    # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input.\n",
    "    # 20 m scale is for speed, and assumes clouds don't require 10 m precision.\n",
    "    is_cld_shdw = (is_cld_shdw.focalMin(2).focalMax(BUFFER*2/20)\n",
    "        .reproject(**{'crs': img.select([0]).projection(), 'scale': 20})\n",
    "        .rename('cloudmask'))\n",
    "\n",
    "    # Add the final cloud-shadow mask to the image.\n",
    "    return img.addBands(is_cld_shdw)\n",
    "\n",
    "def apply_cld_shdw_mask(img):\n",
    "    # Subset the cloudmask band and invert it so clouds/shadow are 0, else 1.\n",
    "    not_cld_shdw = img.select('cloudmask').Not()\n",
    "\n",
    "    # Subset reflectance bands and update their masks, return the result.\n",
    "    return img.select('B.*').updateMask(not_cld_shdw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gee_search_dates(time):\n",
    "    date_obj = datetime.utcfromtimestamp(time / 1000)\n",
    "    return ((date_obj - timedelta(days=1)).strftime('%Y-%m-%d'), (date_obj + timedelta(days=1)).strftime('%Y-%m-%d'))\n",
    "\n",
    "def ehydro_date_convert(time):\n",
    "    return datetime.utcfromtimestamp(time / 1000).strftime('%Y-%m-%d')\n",
    "\n",
    "def download_file(url, destination):\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    with open(destination, 'wb') as file, tqdm(\n",
    "        desc=f\"Downloading {os.path.basename(destination)}\",\n",
    "        total=total_size,\n",
    "        unit='B',\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "    ) as bar:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            file.write(chunk)\n",
    "            bar.update(len(chunk))\n",
    "\n",
    "def export_image_to_drive(image, description, aoi):\n",
    "    \"\"\"\n",
    "    Export a single image to Google Drive.\n",
    "\n",
    "    Args:\n",
    "        image: ee.Image, the image to be exported.\n",
    "        description: str, unique description for the export task.\n",
    "        aoi: ee.Geometry, the area of interest for the export.\n",
    "    \"\"\"\n",
    "\n",
    "    image = image.select(['B2', 'B3', 'B4', 'B8'])\n",
    "    # Setup the export task\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image=image,\n",
    "        description=description,\n",
    "        region=aoi,  # Make sure the geometry (aoi) is defined earlier\n",
    "        fileFormat='GeoTIFF',\n",
    "        scale=10  # Adjust the scale as needed\n",
    "    )\n",
    "    task.start()\n",
    "    print(f'Exporting {description} to Drive...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query bathy data\n",
    "AVAILABLE FIELD NAMES:\n",
    "- Field Name: OBJECTID, Type: esriFieldTypeOID\n",
    "- Field Name: surveyjobidpk, Type: esriFieldTypeString\n",
    "- Field Name: sdsid, Type: esriFieldTypeString\n",
    "- Field Name: sdsfeaturename, Type: esriFieldTypeString\n",
    "- Field Name: sdsmetadataid, Type: esriFieldTypeString\n",
    "- Field Name: surveytype, Type: esriFieldTypeString\n",
    "- Field Name: channelareaidfk, Type: esriFieldTypeString\n",
    "- Field Name: dateuploaded, Type: esriFieldTypeDate\n",
    "- Field Name: usacedistrictcode, Type: esriFieldTypeString\n",
    "- Field Name: surveydatestart, Type: esriFieldTypeDate\n",
    "- Field Name: surveydateend, Type: esriFieldTypeDate\n",
    "- Field Name: sourcedatalocation, Type: esriFieldTypeString\n",
    "- Field Name: sourceprojection, Type: esriFieldTypeString\n",
    "- Field Name: mediaidfk, Type: esriFieldTypeString\n",
    "- Field Name: projectedarea, Type: esriFieldTypeDouble\n",
    "- Field Name: sdsfeaturedescription, Type: esriFieldTypeString\n",
    "- Field Name: dateloadedenterprise, Type: esriFieldTypeDate\n",
    "- Field Name: datenotified, Type: esriFieldTypeDate\n",
    "- Field Name: sourcedatacontent, Type: esriFieldTypeString\n",
    "- Field Name: plotsheetlocation, Type: esriFieldTypeString\n",
    "- Field Name: sourceagency, Type: esriFieldTypeString\n",
    "- Field Name: globalid, Type: esriFieldTypeGlobalID\n",
    "- Field Name: Shape__Area, Type: esriFieldTypeDouble\n",
    "- Field Name: Shape__Length, Type: esriFieldTypeDouble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the model, will probably want to include options for with:\n",
    "- usace district\n",
    "- time of year (date and season)\n",
    "- NCF ID\n",
    "- survey type (single vs dual beam; XC, BD, AD, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate search parameters for eHydro\n",
    "\n",
    "s2_cloud_cov = 20 ## percentage of clouds in sentinel-2 multispectral imagery, less means you see more surface\n",
    "search_date = '2018-01-01'  # Date threshold, getting data from 2018 to present\n",
    "usace_code = \"CESWG\"        # Galveston District (for now)\n",
    "\n",
    "NUM_OF_QUERIES = 3          # number of iterations for the request to run\n",
    "QUERY_TIME_DELAY = 2        # query time delay in seconds, used when requesting all features\n",
    "URL = \"https://services7.arcgis.com/n1YM8pTrFmm7L4hs/ArcGIS/rest/services/eHydro_Survey_Data/FeatureServer/0/query\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the initial query\n",
    "params = {\n",
    "    'where': f\"surveydatestart >= '{search_date}' AND usacedistrictcode='{usace_code}'\",\n",
    "    'outFields': '*',  # Retrieve all fields\n",
    "    'resultRecordCount': 2000,  # Maximum records per request\n",
    "    'resultOffset': 0,  # Starting offset\n",
    "    'f': 'json',  # Output format\n",
    "    'outSR': '4326',  # Spatial reference\n",
    "}\n",
    "\n",
    "all_features = []\n",
    "\n",
    "for i in range(NUM_OF_QUERIES):\n",
    "    response = requests.get(URL, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        features = data.get('features', [])\n",
    "        if not features:\n",
    "            break\n",
    "        all_features.extend(features)\n",
    "        params['resultOffset'] += params['resultRecordCount']\n",
    "        print(f\"Retrieved {len(features)} features.\")\n",
    "        time.sleep(QUERY_TIME_DELAY)  # Delay of 1 second\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extract date and aoi from the surveys for GEE\n",
    "- plan is to iterate through the queries (probably by district code) and check to see if GEE has a corresponding Sentinel-2 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "geeinfo = {}\n",
    "dates = []\n",
    "for feature in all_features:\n",
    "    dates.append(ehydro_date_convert(feature['attributes']['surveydatestart']))\n",
    "    area = ee.Geometry.Polygon(feature['geometry']['rings'][0])\n",
    "\n",
    "    date_tuple = get_gee_search_dates(feature['attributes']['surveydatestart'])\n",
    "\n",
    "    geeinfo[feature['attributes']['surveyjobidpk']] = [area, date_tuple]\n",
    "surveykeys = list(geeinfo.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Iterate through responses and check if GEE has corresponding image(s)\n",
    "- if not, the response will be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for survey, items in geeinfo.items():\n",
    "    aoi = items[0]\n",
    "    dates = items[1]\n",
    "\n",
    "    # coll = get_sentinel_imagery(aoi, dates[0], dates[1], s2_cloud_cov)\n",
    "    coll = get_s2_sr_cld_col(aoi, dates[0], dates[1], s2_cloud_cov)\n",
    "\n",
    "    if coll.size().getInfo() > 0:\n",
    "        geeinfo[survey].append(coll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all surveys that have initial images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodsurveys = []\n",
    "for survey, items in geeinfo.items():\n",
    "    if len(items) > 2:\n",
    "        goodsurveys.append(survey)\n",
    "\n",
    "if len(goodsurveys) == 0:\n",
    "    print('No appropriate images were found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to cloud mask the acquired imagery, any and all non-cloudy pixels can be used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLD_PRB_THRESH = 40\n",
    "NIR_DRK_THRESH = 0.15\n",
    "CLD_PRJ_DIST = 2\n",
    "BUFFER = 100\n",
    "for survey in goodsurveys:\n",
    "    s2_sr_median = (geeinfo[survey][2].map(add_cld_shdw_mask)\n",
    "                             .map(apply_cld_shdw_mask)\n",
    "                             .median())\n",
    "    geeinfo[survey].append(s2_sr_median)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Extract the eHydro bathy data download urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bathyinfo = {}\n",
    "for i, feature in enumerate(all_features):\n",
    "    bathyinfo[surveykeys[i]] = feature['attributes']['sourcedatalocation']\n",
    "\n",
    "display(len(bathyinfo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Download the eHydro data locally for training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = '/mnt/d/eHydro/bathy'\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "for survey in goodsurveys:\n",
    "    file_path = os.path.join(download_dir, f\"{survey}.zip\")\n",
    "    try:\n",
    "        download_file(bathyinfo[survey], file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {bathyinfo[survey]}: {e}\")\n",
    "\n",
    "print('='*250)\n",
    "print(\"All files downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the Sentinel-2 imagery from GEE for download locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for survey in goodsurveys:\n",
    "    export_image_to_drive(geeinfo[survey][-1], survey, geeinfo[survey][0])\n",
    "\n",
    "print('='* 250)\n",
    "print('Finished uploading to Drive.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
