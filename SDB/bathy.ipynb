{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is going to serve as my workflow for estimating NCF bathymetries using historical eHydro sureys and EO multispectral data. I will train a NN on eHydro bathy surveys to estimate waterway bathymetries using corrected surface reflectances\n",
    "- get bathy surveys from https://services7.arcgis.com/n1YM8pTrFmm7L4hs/ArcGIS/rest/services/eHydro_Survey_Data/FeatureServer/0/query\n",
    "- S2 imagery from GEE\n",
    "- TF for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "import ee\n",
    "import geemap\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize(project = '') ##enter your project name here as a string to initialize exchanges with ee api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## collects sentinel-1 GRD (radar, no phase) and Sentinel-2 SR (multispectral, adjusted for top of atmosphere reflectance)\n",
    "def get_sentinel_imagery(aoi, start_date, end_date, s2_cloud_cov):\n",
    "    ## Sentinel-2 Surface Reflectance Harmonized ImageCollection\n",
    "    s2_10m = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "               .filterBounds(aoi)\n",
    "               .filterDate(ee.Date(start_date), ee.Date(end_date))\n",
    "               .map(lambda img: img.set('date', ee.Date(img.date()).format('YYYYMMdd')))\n",
    "               .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', s2_cloud_cov))\n",
    "               .sort('date')\n",
    "               .select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12'])\n",
    "    )\n",
    "    ## Clip all images in the collection to the AOI\n",
    "    s2_10m = s2_10m.map(lambda img: img.clip(aoi))\n",
    "\n",
    "    return s2_10m\n",
    "\n",
    "def add_rgb_to_map(image, map_object, num):\n",
    "    date = ee.Date(image.get('date')).format('YYYY-MM-dd').getInfo()\n",
    "    map_object.addLayer(image, {'min': 0, 'max': 2000, 'bands': ['B4', 'B3', 'B2']}, f'{num}_rgb')\n",
    "\n",
    "def get_gee_search_dates(time):\n",
    "    date_obj = datetime.utcfromtimestamp(time / 1000)\n",
    "    return ((date_obj - timedelta(days=1)).strftime('%Y-%m-%d'), (date_obj + timedelta(days=1)).strftime('%Y-%m-%d'))\n",
    "\n",
    "def ehydro_date_convert(time):\n",
    "    return datetime.utcfromtimestamp(time / 1000).strftime('%Y-%m-%d')\n",
    "\n",
    "def request_all_features(url, params):\n",
    "    # Initialize a list to store all features\n",
    "    all_features = []\n",
    "\n",
    "    # Iteratively fetch data\n",
    "    while True:\n",
    "        response = requests.get(url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            features = data.get('features', [])\n",
    "            if not features:\n",
    "                break\n",
    "            all_features.extend(features)\n",
    "            params['resultOffset'] += params['resultRecordCount']\n",
    "            time.sleep(QUERY_TIME_DELAY)  # Delay of 1 second\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}, {response.text}\")\n",
    "            break\n",
    "    \n",
    "    return all_features\n",
    "\n",
    "def request_subset_features(url, params):\n",
    "    # Initialize a list to store all features\n",
    "    all_features = []\n",
    "\n",
    "    # Iteratively fetch data\n",
    "    while True:\n",
    "        response = requests.get(url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            features = data.get('features', [])\n",
    "            if not features:\n",
    "                break\n",
    "            all_features.extend(features)\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}, {response.text}\")\n",
    "            break\n",
    "    \n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query bathy data\n",
    "AVAILABLE FIELD NAMES:\n",
    "- Field Name: OBJECTID, Type: esriFieldTypeOID\n",
    "- Field Name: surveyjobidpk, Type: esriFieldTypeString\n",
    "- Field Name: sdsid, Type: esriFieldTypeString\n",
    "- Field Name: sdsfeaturename, Type: esriFieldTypeString\n",
    "- Field Name: sdsmetadataid, Type: esriFieldTypeString\n",
    "- Field Name: surveytype, Type: esriFieldTypeString\n",
    "- Field Name: channelareaidfk, Type: esriFieldTypeString\n",
    "- Field Name: dateuploaded, Type: esriFieldTypeDate\n",
    "- Field Name: usacedistrictcode, Type: esriFieldTypeString\n",
    "- Field Name: surveydatestart, Type: esriFieldTypeDate\n",
    "- Field Name: surveydateend, Type: esriFieldTypeDate\n",
    "- Field Name: sourcedatalocation, Type: esriFieldTypeString\n",
    "- Field Name: sourceprojection, Type: esriFieldTypeString\n",
    "- Field Name: mediaidfk, Type: esriFieldTypeString\n",
    "- Field Name: projectedarea, Type: esriFieldTypeDouble\n",
    "- Field Name: sdsfeaturedescription, Type: esriFieldTypeString\n",
    "- Field Name: dateloadedenterprise, Type: esriFieldTypeDate\n",
    "- Field Name: datenotified, Type: esriFieldTypeDate\n",
    "- Field Name: sourcedatacontent, Type: esriFieldTypeString\n",
    "- Field Name: plotsheetlocation, Type: esriFieldTypeString\n",
    "- Field Name: sourceagency, Type: esriFieldTypeString\n",
    "- Field Name: globalid, Type: esriFieldTypeGlobalID\n",
    "- Field Name: Shape__Area, Type: esriFieldTypeDouble\n",
    "- Field Name: Shape__Length, Type: esriFieldTypeDouble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the model, will probably want to include options for with:\n",
    "- usace district\n",
    "- time of year (date and season)\n",
    "- NCF ID\n",
    "- survey type (single vs dual beam; XC, BD, AD, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate search parameters for eHydro\n",
    "\n",
    "s2_cloud_cov = 1 ## percentage of clouds in sentinel-2 multispectral imagery, less means you see more surface\n",
    "search_date = '2018-01-01'  # Date threshold, getting data from 2018 to present\n",
    "usace_code = \"CESWG\"        # Galveston District (for now)\n",
    "QUERY_TIME_DELAY = 5        # query time delay in seconds, used when requesting all features\n",
    "URL = \"https://services7.arcgis.com/n1YM8pTrFmm7L4hs/ArcGIS/rest/services/eHydro_Survey_Data/FeatureServer/0/query\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the initial query\n",
    "params = {\n",
    "    'where': f\"surveydatestart >= '{search_date}' AND usacedistrictcode='{usace_code}'\",\n",
    "    'outFields': '*',  # Retrieve all fields\n",
    "    'resultRecordCount': 2000,  # Maximum records per request\n",
    "    'resultOffset': 0,  # Starting offset\n",
    "    'f': 'json',  # Output format\n",
    "    'outSR': '4326',  # Spatial reference\n",
    "}\n",
    "\n",
    "all_features = []\n",
    "\n",
    "while True:\n",
    "    response = requests.get(URL, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        features = data.get('features', [])\n",
    "        if not features:\n",
    "            break\n",
    "        all_features.extend(features)\n",
    "        params['resultOffset'] += params['resultRecordCount']\n",
    "        print(f\"Retrieved {len(features)} features.\")\n",
    "        time.sleep(1)  # Delay of 1 second\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'where': f\"surveydatestart >= '{search_date}' AND usacedistrictcode='{usace_code}'\",\n",
    "    'outFields': '*',  # Retrieve all fields\n",
    "    'resultRecordCount': 50,\n",
    "    'f': 'json',  # Output format\n",
    "    'outSR': '4326',  # Spatial reference\n",
    "}\n",
    "\n",
    "# Send the request\n",
    "response = requests.get(URL, params=params)\n",
    "\n",
    "# Handle the response\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    features = data.get('features', [])\n",
    "    print(f\"Retrieved {len(features)} features.\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Save to a file for later use\n",
    "import json\n",
    "with open(\"all_features.json\", \"w\") as f:\n",
    "    json.dump(all_features, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extract date and aoi from the surveys for GEE\n",
    "- plan is to iterate through the queries (probably by district code) and check to see if GEE has a corresponding Sentinel-2 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geeinfo = {}\n",
    "dates = []\n",
    "for feature in features:\n",
    "    dates.append(ehydro_date_convert(feature['attributes']['surveydatestart']))\n",
    "    area = ee.Geometry.Polygon(feature['geometry']['rings'][0])\n",
    "\n",
    "    date_tuple = get_gee_search_dates(feature['attributes']['surveydatestart'])\n",
    "\n",
    "    geeinfo[feature['attributes']['surveyjobidpk']] = [area, date_tuple]\n",
    "surveykeys = list(geeinfo.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Iterate through responses and check if GEE has corresponding image(s)\n",
    "- if not, the response will be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for survey, items in geeinfo.items():\n",
    "    aoi = items[0]\n",
    "    dates = items[1]\n",
    "\n",
    "    coll = get_sentinel_imagery(aoi, dates[0], dates[1], s2_cloud_cov)\n",
    "\n",
    "    if coll.size().getInfo() > 0:\n",
    "        geeinfo[survey].append(coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodsurveys = []\n",
    "for survey, items in geeinfo.items():\n",
    "    if len(items) > 2:\n",
    "        goodsurveys.append(survey)\n",
    "\n",
    "len(goodsurveys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Extract and download the eHydro bathy data locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bathyinfo = {}\n",
    "for i, feature in enumerate(features):\n",
    "    bathyinfo[surveykeys[i]] = feature['attributes']['sourcedatalocation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get EE imagery for each survey\n",
    "- Sentinel-2 Surface Reflectance product, test multiple individual bands (red, blue, NIR may be best)\n",
    "- At some point, if S2 results good, try Planet 3m-daily imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map()\n",
    "Map.centerObject(geeinfo[goodsurveys[2]][0], 15)\n",
    "\n",
    "\n",
    "s2_images = geeinfo[goodsurveys[2]][-1].toList(geeinfo[goodsurveys[2]][-1].size())\n",
    "for i in range(geeinfo[goodsurveys[2]][-1].size().getInfo()):\n",
    "    image = ee.Image(s2_images.get(i))\n",
    "    add_rgb_to_map(image, Map, i)\n",
    "\n",
    "Map.addLayer(geeinfo[goodsurveys[2]][0])\n",
    "\n",
    "# Display the map.\n",
    "Map.addLayerControl(position = 'topright')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the Sentinel-2 imagery from GEE for download locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_image_to_drive(image, index):\n",
    "    # Define the description for the export, incorporating the index for uniqueness\n",
    "\n",
    "    description = f's2_10m_{index}'\n",
    "\n",
    "    # Setup the export task\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image=image,\n",
    "        description=description,\n",
    "        region=aoi,  # Make sure the geometry is defined earlier\n",
    "        fileFormat='GeoTIFF',\n",
    "        scale = 10\n",
    "    )\n",
    "    task.start()\n",
    "    print(f'Exporting {description} to Drive...')\n",
    "\n",
    "def export_all_images(collection, date_list):\n",
    "    image_list = collection.toList(collection.size())  # Convert ImageCollection to List\n",
    "\n",
    "    for i, date in enumerate(date_list):\n",
    "        image = ee.Image(image_list.get(i))\n",
    "        export_image_to_drive(image, date[:10])\n",
    "\n",
    "## fucntion to get the date of each image in the image collection\n",
    "def get_date(image):\n",
    "    return ee.Feature(None, {'date': image.date().format('YYYY-MM-dd')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_date_list = geeinfo['BR_02_JEC_20210630_AD_01'][-1].map(get_date).aggregate_array('date').getInfo()\n",
    "export_all_images(geeinfo['BR_02_JEC_20210630_AD_01'][-1], s2_date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_gis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
